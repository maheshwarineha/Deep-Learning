{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Phase - 1_Session-1 and 2_DL_with_Pytorch_MNIST_Classification_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xlkpF1m_4DBw",
        "mdd4kzZa4DBy",
        "BybjWD-B4DCg",
        "Gj48dSJg4DCm",
        "Hf9bGVDH4DCn",
        "TUVHsCvR4DCp",
        "R5TxccEk4DCq",
        "0c7XjTMH4DCs",
        "0ZOWCRtq4DCw",
        "_hGrdIVq4DCy",
        "wr91w0-X4DCz",
        "_vC0Y7z34DC1",
        "9zyso_in4DC4",
        "B-j6vcfk4DC9",
        "4ZwCEHs24DC_",
        "dMLPVy7c4DDB"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheshwarineha/Deep-Learning/blob/master/Phase_1_Session_1_and_2_DL_with_Pytorch_MNIST_Classification_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1a991e7f539673da033393d34767c7335318ab9a",
        "colab_type": "text",
        "id": "9Vvp6QLz4C9y"
      },
      "source": [
        "**Agenda:**\n",
        "<br>\n",
        "For this tutorial in  Deep Learning(DL) with Pytorch, we are going to explore Multi Layered Perceptron architecture and learn Pytorch by implementing  algorithms under a certain usecase.We will cover the following:\n",
        "1. Deep Learning basics with Pytorch\n",
        "2. Multilayered Perceptron (MLP) implemention on  MNIST\n",
        "<br>\n",
        "\n",
        "Lets get started !!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8f02da80b362a4233b75cb0f9e9656525e37befa",
        "colab_type": "text",
        "id": "L45gM0dy4C9z"
      },
      "source": [
        "![](images/mlp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6145a827010b47e713d5bcdb6f89d8042040d75f",
        "colab_type": "text",
        "id": "FtyNV4e_4C91"
      },
      "source": [
        "# **1. Deep Learning basics with Pytorch**\n",
        "<br>\n",
        "In this part we will cover the following:\n",
        "\n",
        "1. Learn to play with tensors on numpy and pytorch \n",
        "2. Learn to build a simple feed forward network from scratch with random data \n",
        "3. Learn to build an end to end MLP for MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vDr4q0SY4C93"
      },
      "source": [
        "##  Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-06-29T06:23:59.969638Z",
          "start_time": "2019-06-29T06:22:56.981582Z"
        },
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "FqzxX9Xy4C94",
        "outputId": "2abfe5c7-a408-40a7-e592-ab4ef7b17d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!pip3 install torch torchvision\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "#print(\"List of files\",os.listdir(\"../input\"))\n",
        "import torch\n",
        "import numpy as np\n",
        "print(\"Torch Version:\",torch.__version__)\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch Version: 1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1e8017c3ed94f083df4e2bf071f7f5f422c40ca1",
        "colab_type": "text",
        "id": "XZ1sqauc4C98"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f08b918b1e2513ad7c1f382cfba39b0205aba6e",
        "colab_type": "code",
        "id": "m4BiKJI74C99",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cc2337505994f4530913183436b9f4bf8a118599",
        "colab_type": "text",
        "id": "YAYW22Rh4C-B"
      },
      "source": [
        "## Tensors\n",
        "It turns out neural network computations are just a bunch of linear algebra operations on *tensors*, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
        "\n",
        "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "<img src=\"images/tensor_examples.svg\" width=600px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iB71Npbp4C-C"
      },
      "source": [
        "### Construct a randomly initialized 5x3 matrix:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:21:36.971841Z",
          "start_time": "2019-02-04T11:21:36.623384Z"
        },
        "colab_type": "code",
        "id": "oLdA8qkA4C-D",
        "outputId": "81006928-3527-4a42-8aa6-4ec5f14a6d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9851, 0.6832, 0.9869],\n",
            "        [0.1555, 0.4745, 0.9280],\n",
            "        [0.2278, 0.5239, 0.2541],\n",
            "        [0.8145, 0.5786, 0.3488],\n",
            "        [0.2095, 0.9761, 0.7823]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FdMjupDY4C-H"
      },
      "source": [
        "### Construct a tensor directly from data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:22:21.040158Z",
          "start_time": "2019-02-04T11:22:21.033606Z"
        },
        "colab_type": "code",
        "id": "7KjxFCsl4C-I",
        "outputId": "0f7b3ea8-72ba-40a3-86b5-5badd1e49533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1afe587702c9d925968dc34d4e7f515b700d9089",
        "colab_type": "text",
        "id": "N2_NMiwy4C-M"
      },
      "source": [
        "### Numpy to Torch and back\n",
        "\n",
        "PyTorch has a great feature for converting between Numpy arrays and Torch tensors. Let us see how easy it is to switch between the two\n",
        "\n",
        "### Ceate a tensor using numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "35d8b903e1564ee833e2d0ed2ea00d40b61aa16e",
        "colab_type": "code",
        "id": "lfm27TeL4C-M",
        "outputId": "a34dbdb2-0374-45a1-8b3a-fa0c164438eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "np_array=np.random.randn(5,3)\n",
        "print(f' Numpy array:\\n {np_array}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Numpy array:\n",
            " [[ 0.26660052 -0.22044432 -1.01680903]\n",
            " [-0.17214221 -1.3084805  -0.64798087]\n",
            " [ 0.4426491   0.46883342  0.66498608]\n",
            " [-0.1843081  -0.70312533 -0.53220558]\n",
            " [-0.07415495  0.11957473 -0.83134379]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1d82db999b723fa737510352cf47d96a62b8d63b",
        "colab_type": "text",
        "id": "Nq9cmqeH4C-S"
      },
      "source": [
        "### Convert to torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1cbd6fd48cf54645f924d354fc9fb5856bf1ddc1",
        "colab_type": "code",
        "id": "yTcHR5qk4C-U",
        "outputId": "02c90319-3e07-4da7-87d9-290b4e19a5a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "torch_tensor=torch.from_numpy(np_array)\n",
        "print(f'Torch tensor:\\n {torch_tensor}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch tensor:\n",
            " tensor([[ 0.2666, -0.2204, -1.0168],\n",
            "        [-0.1721, -1.3085, -0.6480],\n",
            "        [ 0.4426,  0.4688,  0.6650],\n",
            "        [-0.1843, -0.7031, -0.5322],\n",
            "        [-0.0742,  0.1196, -0.8313]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "31fe8979751ba061cc81055bbc5079bed1cb0124",
        "colab_type": "text",
        "id": "13IACWyu4C-Y"
      },
      "source": [
        "### Convert back to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e72bac0d8c4870f97b1d1724c0bce3fd84b50450",
        "colab_type": "code",
        "id": "403oY_8S4C-Z",
        "outputId": "211d5065-3ec4-494f-a07b-1e1a007fcae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "torch_tensor.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.26660052, -0.22044432, -1.01680903],\n",
              "       [-0.17214221, -1.3084805 , -0.64798087],\n",
              "       [ 0.4426491 ,  0.46883342,  0.66498608],\n",
              "       [-0.1843081 , -0.70312533, -0.53220558],\n",
              "       [-0.07415495,  0.11957473, -0.83134379]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "532f4e612d823389740276fdb2f1d0c9d69cb78d",
        "colab_type": "text",
        "id": "9JtXENQc4C-c"
      },
      "source": [
        "***An important thing to note here is memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well.*       \n",
        "Let see what does it mean**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7a08bc968bbb69b18d7d376748f7a5333f931efe",
        "colab_type": "code",
        "id": "OK9LEQa-4C-d",
        "outputId": "589e2c0d-cc35-447f-dfc6-816fb414f2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Add 2 to PyTorch Tensor, in place\n",
        "torch_tensor.add_(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.2666, 1.7796, 0.9832],\n",
              "        [1.8279, 0.6915, 1.3520],\n",
              "        [2.4426, 2.4688, 2.6650],\n",
              "        [1.8157, 1.2969, 1.4678],\n",
              "        [1.9258, 2.1196, 1.1687]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "15c233bd4f3539d1cf8c07878d01802607a6ab89",
        "colab_type": "text",
        "id": "a8gtGecL4C-h"
      },
      "source": [
        "###  Numpy array matches new values from Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3d4047f95de1ca8055e276de3246da2c6a01ccee",
        "colab_type": "code",
        "id": "H9FKs6dC4C-j",
        "outputId": "1782201e-17e0-45ac-a47b-bf09841351aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "np_array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.26660052, 1.77955568, 0.98319097],\n",
              "       [1.82785779, 0.6915195 , 1.35201913],\n",
              "       [2.4426491 , 2.46883342, 2.66498608],\n",
              "       [1.8156919 , 1.29687467, 1.46779442],\n",
              "       [1.92584505, 2.11957473, 1.16865621]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b183396c1d82a600e1c3b1848e94e3ce5a6fbe28",
        "colab_type": "text",
        "id": "MlIiUgFz4C-o"
      },
      "source": [
        " ## Simple Neural Network using Pytorch \n",
        " Let us see how we can use PyTorch to build a simple neural network.\n",
        "![](images/simple_neuron.PNG)\n",
        "\n",
        "Mathematically this looks like: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
        "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "With vectors this is the dot/inner product of two vectors:\n",
        "\n",
        "$$\n",
        "h = \\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots  x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_1 \\\\\n",
        "           w_2 \\\\\n",
        "           \\vdots \\\\\n",
        "           w_n\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "496c485f3e7f43a27bdce042df78fa11eb296631",
        "colab_type": "text",
        "id": "-YeLMTFM4C-p"
      },
      "source": [
        "With the basics covered, it's time to explore how we can use PyTorch to build a simple neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "93562b119ff2797b3660bb0968bc6c31e890b7e5",
        "colab_type": "text",
        "id": "08TbB9Sm4C-q"
      },
      "source": [
        "###  Generate some random data \n",
        " We will create a tensor with shape (1, 5), one row and five columns, that contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fd1ee538877f19c8a2cfac8ea123ecbdb2f4a94d",
        "colab_type": "code",
        "id": "NWB4MQuu4C-r",
        "outputId": "26f278dc-50bb-4234-b036-cc54c0b4ca42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features=torch.randn(1,3)\n",
        "print(f'Number of Inout features:{features.shape[1]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Inout features:3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b0673d28508dd5eed49da6731c4cc1408f1efd5c",
        "colab_type": "text",
        "id": "oABNl_OM4C-x"
      },
      "source": [
        "### Initialize Weights and Biases "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7f39730f8dbaff0834b223744d0bab6bfc516e2c",
        "colab_type": "text",
        "id": "rBChM5NH4C-y"
      },
      "source": [
        "Weights = torch.randn_like(features) creates another tensor with the same shape as features, again containing values from a normal distribution.\n",
        "\n",
        "Finally, bias = torch.randn((1, 1)) creates a single value from a normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3d2b5d527e0650f3d3c1942a5ee1da56bbbac7de",
        "colab_type": "code",
        "id": "i92IlQIC4C-z",
        "colab": {}
      },
      "source": [
        "n_input=features.shape[1]   #3 input neuron\n",
        "n_hidden=2     #two hidden neuron\n",
        "n_output=1     #one output neuron\n",
        "#Weights for input to hidden layer\n",
        "W1=torch.randn(n_input,n_hidden)\n",
        "W2=torch.randn(n_hidden,n_output)\n",
        "#Bias term for hidden and output layer\n",
        "B1=torch.randn(n_hidden)\n",
        "B2=torch.randn(n_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cd62c805fb7363693b56ec9dbcd00a8c404adcba",
        "colab_type": "code",
        "id": "hjlSRWiu4C-3",
        "colab": {}
      },
      "source": [
        "#Using a Sigmoid Activation Function\n",
        "def activation(x):\n",
        "    return(1/1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fbfeec62cfa4a35cb829897b71a4450b70ec8392",
        "colab_type": "text",
        "id": "DrWzkrnk4C-7"
      },
      "source": [
        "### Calculate Weight and Biases\n",
        "We will calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bd98acc8aa8bb1d2fe06cb77ffd4a5054c07a40b",
        "colab_type": "code",
        "id": "zC2QQjr24C-8",
        "outputId": "a0442f80-59e9-4eb2-bc96-9df1f949d29f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "h1=activation(torch.matmul(features,W1)+B1)\n",
        "print(f'Hidden Layer activations:{h1}')\n",
        "out=activation(torch.matmul(h1,W2)+B2)\n",
        "print(f'Output of the network:{out}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden Layer activations:tensor([[2.9791, 1.2008]])\n",
            "Output of the network:tensor([[1.1576]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "21b8946d94159fc86b191a82bbbb4e34d2289f53",
        "colab_type": "text",
        "id": "xe4vu51K4C_I"
      },
      "source": [
        "## Building our Network\n",
        "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image using MNIST data\n",
        "For now our goal will be to build a neural network that can take one of these images and predict the digit in the image.First, let's try to build this network for this dataset using weight matrices and matrix multiplications. Then, we'll see how to do it using PyTorch's `nn` module which provides a much more convenient and powerful method for defining network architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c4c2229e3f3534db73e8d22ba73485022765f3af",
        "colab_type": "text",
        "id": "rsLM8Yc14C_J"
      },
      "source": [
        "![](images/mnist.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d2974386321060bd66905127f3a48b9f1b177310",
        "colab_type": "code",
        "id": "uoGmSr6P4C_K",
        "colab": {}
      },
      "source": [
        "# Import necessary packages\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import helper\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "237092ef839e8201ecc710f53ed7154e0f865b2e",
        "colab_type": "text",
        "id": "jMGNnSoA4C_O"
      },
      "source": [
        "### Load Dataset \n",
        "First up, we need to get our dataset.Right now we will be using MNIST dataset which is already in`torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:27:05.872957Z",
          "start_time": "2019-02-04T11:26:45.305539Z"
        },
        "_uuid": "45cde9b49e2c0e1802ff640ebab0d766233e6abe",
        "colab_type": "code",
        "id": "Gt1AQ86c4C_P",
        "outputId": "7888366f-0185-4996-aeee-22b5d80608b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:29, 111191.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 28002406.01it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 451892.23it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 144448.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7125151.57it/s]                           \n",
            "8192it [00:00, 179623.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jExiHh8b4C_T"
      },
      "source": [
        "#### what is dataset ?\n",
        "Dataset contains two data methods `__getitem__` and `__len__` so using these methods. we can directly call a single data with index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:31:37.364338Z",
          "start_time": "2019-02-04T11:31:37.283418Z"
        },
        "colab_type": "code",
        "id": "_vzZQG7M4C_U",
        "outputId": "33596699-7b86-4ae5-f875-de89a5703d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# like this way\n",
        "trainset[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fx2u1ci_4C_X"
      },
      "source": [
        "#### what is dataloader?\n",
        "\n",
        "It simply uses the generator to provide data giving single- or multi-process iterators over the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "00ab24a0af33038559ec91ea83458558e4d574bf",
        "colab_type": "text",
        "id": "YKA5zpwB4C_X"
      },
      "source": [
        "We have the training data loaded into trainloader \n",
        "\n",
        "With dataloaded we make  an iterator with iter(trainloader). Later, we'll use this to loop through the dataset for training, like below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:38:04.781132Z",
          "start_time": "2019-02-04T11:38:04.633040Z"
        },
        "_uuid": "9808e8dab8f56248ae40759f20b1e59dad3ede7b",
        "colab_type": "code",
        "id": "kjMIXE_t4C_Y",
        "outputId": "e7c6550d-a4e7-4a7b-a299-e28c53edba65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "#Printing the size of one image\n",
        "print(images[1].numpy().squeeze().shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f544046855f3efd0eb1d88fb11f0e4e27318d5eb",
        "colab_type": "code",
        "id": "FIto5Wet4C_b",
        "outputId": "7cdd1e49-633c-4fde-8dc6-c52849710b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "#Look at the image\n",
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:38:08.273406Z",
          "start_time": "2019-02-04T11:38:08.264208Z"
        },
        "_uuid": "b11c0c543d20cfb96cbb0635eea5f93e37c58cb0",
        "colab_type": "code",
        "id": "UDqvWprf4C_d",
        "colab": {}
      },
      "source": [
        "#Sigmoid Activation Function\n",
        "def activation(x):\n",
        "    return (1/(1+torch.exp(-x)))\n",
        "\n",
        "#Input 64x784\n",
        "inputs=images.view(images.shape[0],-1)\n",
        "#Number of input features-784\n",
        "n_input=inputs.shape[1]\n",
        "#Number of neurons in hidden layer-256\n",
        "n_hidden=256\n",
        "#Number of output neuron-10\n",
        "n_out=10\n",
        "#Weight at hidden neuron-784x256\n",
        "W1=torch.randn(n_input,n_hidden)\n",
        "#Bias at hidden neuron-256\n",
        "B1=torch.randn(n_hidden)\n",
        "#Weight at output neuron-256x10\n",
        "W2=torch.randn(n_hidden,n_out)\n",
        "#Bias at output neuron-10\n",
        "B2=torch.randn(n_out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:38:13.520858Z",
          "start_time": "2019-02-04T11:38:13.510149Z"
        },
        "_uuid": "e494abcbcf8bf4e1210b1acdc0790ca77f826e21",
        "colab_type": "code",
        "id": "q0RLuvzt4C_h",
        "outputId": "fe7045ff-5eb4-4932-90ae-59494a4d6a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"Shape of a batch of an image:\",images.shape)\n",
        "print(\"Shape of the input to the network:\",inputs.shape)\n",
        "print(\"Shape of the input features:\",n_input)\n",
        "print(\"Shape of the Weight matrix of neurons in the hidden layer\",W1.shape)\n",
        "print(\"Shape of the Bias vector of neurons in the hidden layer\",B1.shape)\n",
        "print(\"Shape of the Weight matrix of neurons in the output layer\",W2.shape)\n",
        "print(\"Shape of the Bias vector of neurons in the output layer\",W2.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of a batch of an image: torch.Size([64, 1, 28, 28])\n",
            "Shape of the input to the network: torch.Size([64, 784])\n",
            "Shape of the input features: 784\n",
            "Shape of the Weight matrix of neurons in the hidden layer torch.Size([784, 256])\n",
            "Shape of the Bias vector of neurons in the hidden layer torch.Size([256])\n",
            "Shape of the Weight matrix of neurons in the output layer torch.Size([256, 10])\n",
            "Shape of the Bias vector of neurons in the output layer torch.Size([256, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:38:23.336380Z",
          "start_time": "2019-02-04T11:38:22.958331Z"
        },
        "_uuid": "e751026ecf95253bf33db0462ce8bc250c082bb7",
        "colab_type": "code",
        "id": "lFz3MRF04C_l",
        "colab": {}
      },
      "source": [
        "#Hidden layer activations\n",
        "h1=activation(torch.mm(inputs,W1)+B1)\n",
        "#Output layer activations\n",
        "out=activation(torch.mm(h1,W2)+B2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:38:26.658141Z",
          "start_time": "2019-02-04T11:38:26.649686Z"
        },
        "_uuid": "2cb2a0f4a6d9852da5d4811e89734c8906bbb878",
        "colab_type": "code",
        "id": "jkUmaAhH4C_o",
        "outputId": "d933c39a-2ac8-4127-a528-4a3306615044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f'Shape of the Hidden activation of the network{h1.shape}')\n",
        "print(f'Shape of the Output of the network{out.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the Hidden activation of the networktorch.Size([64, 256])\n",
            "Shape of the Output of the networktorch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:38:38.560819Z",
          "start_time": "2019-02-04T11:38:38.553507Z"
        },
        "_uuid": "66671445031ee39d4142f84c832b2ab097f6d14a",
        "colab_type": "code",
        "id": "VPibe5io4C_r",
        "outputId": "7af263e6-14ea-4db3-891c-fec17cf6d602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Let us see the network output to one of the feeded input image\n",
        "out[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.9998e-01, 6.2429e-05, 9.9995e-01, 1.0000e+00, 5.7602e-04, 6.3908e-02,\n",
              "        1.8892e-01, 1.0000e+00, 1.0000e+00, 9.9999e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8c7ab4cad2d8a2d619e0b376780e0d5b2dfa7be3",
        "colab_type": "text",
        "id": "XPPcsO9m4C_u"
      },
      "source": [
        "Now we have 10 outputs for our network. This raw output is usually called **logits or scores**.\n",
        "<br>\n",
        "However,We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1903f5520e57c8ca69b4252ed7a7c4d5e5beb51a",
        "colab_type": "text",
        "id": "DjJ4RkZZ4C_u"
      },
      "source": [
        "\n",
        "### Probability Distribution using Softmax\n",
        "To calculate this probability distribution, we often use the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
        "$$\n",
        "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
        "$$\n",
        "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:40:41.701155Z",
          "start_time": "2019-02-04T11:40:41.697492Z"
        },
        "_uuid": "f4d7ba5cc02acf1610fa113490099e51e84978aa",
        "colab_type": "code",
        "id": "S188ENAT4C_v",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    return(torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "bdf3ab4229b26432555148c0d1b67f6e857055e6",
        "colab_type": "text",
        "id": "3a7zi3F-4C_x"
      },
      "source": [
        "Let us understand what we are doing above by an example\n",
        "<br>\n",
        "Step 1:Calculating the numerator of the softmax function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:40:42.976206Z",
          "start_time": "2019-02-04T11:40:42.970484Z"
        },
        "_uuid": "d06ddfc05e73456929293906a0ee9672cf2f45a6",
        "colab_type": "code",
        "id": "eStL6dvV4C_y",
        "outputId": "e7377417-7d80-41e4-d313-ec5a7747d512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.exp(out[1:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5132, 1.0000, 2.7183, 2.7177, 2.1420, 1.0013, 2.7183, 1.0000, 1.0007,\n",
              "         2.7183],\n",
              "        [2.7082, 1.0000, 2.7157, 2.7183, 1.0645, 1.0001, 2.7183, 1.0054, 1.0000,\n",
              "         2.7181]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0fd149046af107a72d73208528b3a5cf1a6eb13e",
        "colab_type": "text",
        "id": "01A27TNB4C_1"
      },
      "source": [
        "Step 2:For every predicted image output, calculate the sum over the predicted values over all classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:40:45.248689Z",
          "start_time": "2019-02-04T11:40:45.236760Z"
        },
        "_uuid": "2277f07ce4566f91bf8ad70e3969f2c4790e676d",
        "colab_type": "code",
        "id": "52l7XpZ64C_2",
        "outputId": "4f3d8491-2261-413b-bf61-3eccfcac40ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#print(torch.sum(torch.exp(out[1:3])))\n",
        "#Dim=1 says, we want to take the sum across all columns\n",
        "torch.sum(torch.exp(out[1:3]),dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([19.5298, 18.6485])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e247c285cf5dfdd02702bc79ddc8e49383bc17c1",
        "colab_type": "text",
        "id": "SRB2MTph4C_6"
      },
      "source": [
        "Step3:Rearrange the sums in an order for broadcasting to work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:40:47.116271Z",
          "start_time": "2019-02-04T11:40:47.106860Z"
        },
        "_uuid": "8c226fe7a4a2e9f31f63ddca18ed71959d9a139d",
        "colab_type": "code",
        "id": "CGMlnjDl4C_6",
        "outputId": "e80a3d3c-980b-4527-98f6-19125a487c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19.5298],\n",
              "        [18.6485]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ecbcd104b966f3ae051d09048e7d708f992f1a41",
        "colab_type": "text",
        "id": "rM6w5dmi4C_9"
      },
      "source": [
        "Step 3:For every predicted image output, divide the predictions of each class with the sum over all classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T11:41:41.871814Z",
          "start_time": "2019-02-04T11:41:41.808608Z"
        },
        "_uuid": "fce3f0e89d812e35f44a46ee5eab0fc85bf05406",
        "colab_type": "code",
        "id": "aDOCWoIb4C__",
        "outputId": "c1f2c861-e946-480d-aeb7-59611908f1a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#print(torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1))\n",
        "temp=torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)\n",
        "print(temp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1287, 0.0512, 0.1392, 0.1392, 0.1097, 0.0513, 0.1392, 0.0512, 0.0512,\n",
            "         0.1392],\n",
            "        [0.1452, 0.0536, 0.1456, 0.1458, 0.0571, 0.0536, 0.1458, 0.0539, 0.0536,\n",
            "         0.1458]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0973f2a30eacf6d699df25a24ce00f9487f35559",
        "colab_type": "text",
        "id": "6l9keIdD4DAB"
      },
      "source": [
        "Voila!! We got the softmax output .One last thing to do is check whether the sum across all classes sum to 1 for understanding the predicted class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5f899daaaf970fbb7b821a9cf4f70af1b00a9773",
        "colab_type": "code",
        "id": "nalYGtoG4DAC",
        "outputId": "652ae82c-823a-41d1-ffa8-3682f6c45e0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "temp.sum(dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "da2f00d033b1ef41cf3941998ef34e24167a08cc",
        "colab_type": "code",
        "id": "QaVOzTEm4DAF",
        "outputId": "4ffeb7aa-2f9e-4c76-ef09-9c6cf1ed066e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probabilities = softmax(out)\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "#print(probabilities.sum(dim=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f9cd86feb1156d1a7ba69037197aabf876735be6",
        "colab_type": "text",
        "id": "Ecm_JHVC4DAL"
      },
      "source": [
        "## Building our Network with Pytorch\n",
        "\n",
        "![](images/mlp_mnist.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6b0737a96ecaa7d4bcd0f6bc4592961e5ffc8e42",
        "colab_type": "text",
        "id": "dWd6P2hG4DAM"
      },
      "source": [
        "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e82cac77674746147dc9dd5d9367b21c1e02d40c",
        "colab_type": "code",
        "id": "DVkq49YW4DAN",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "72a3786079aa4a387146ff066176d5af56b11b4b",
        "colab_type": "code",
        "id": "Tsob_Rb54DAR",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden=nn.Linear(784,256)\n",
        "        self.output=nn.Linear(256,10)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        self.softmax=nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x=self.hidden(x)\n",
        "        x=self.sigmoid(x)\n",
        "        x=self.output(x)\n",
        "        x=self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b1546fd3ac7e6ab35a81dfee3e704817627a5618",
        "colab_type": "text",
        "id": "NmsMC3m_4DAY"
      },
      "source": [
        "Let's go through this bit by bit.\n",
        "\n",
        "```python\n",
        "class Network(nn.Module):\n",
        "```\n",
        "\n",
        "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
        "\n",
        "```python\n",
        "self.hidden = nn.Linear(784, 256)\n",
        "```\n",
        "\n",
        "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network once it's create at `net.hidden.weight` and `net.hidden.bias`.\n",
        "\n",
        "```python\n",
        "self.output = nn.Linear(256, 10)\n",
        "```\n",
        "\n",
        "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
        "\n",
        "```python\n",
        "self.sigmoid = nn.Sigmoid()\n",
        "self.softmax = nn.Softmax(dim=1)\n",
        "```\n",
        "\n",
        "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
        "\n",
        "```python\n",
        "def forward(self, x):\n",
        "```\n",
        "\n",
        "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
        "\n",
        "```python\n",
        "x = self.hidden(x)\n",
        "x = self.sigmoid(x)\n",
        "x = self.output(x)\n",
        "x = self.softmax(x)\n",
        "```\n",
        "\n",
        "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n",
        "\n",
        "Now we can create a `Network` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "36bc9a286ffafd0a0b1ac7890906092965f5fee0",
        "colab_type": "code",
        "id": "5mUYbFw94DAZ",
        "outputId": "1e2723e3-3304-4cca-ae40-6d69e06061f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model=Network()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "aae8f6f5e7c42a3df7d79b6e3a20293f3a673b0a",
        "colab_type": "text",
        "id": "xvFaVwHN4DAf"
      },
      "source": [
        "We can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1ebea291b4d96d74d435885e60bc2a792c4abd12",
        "colab_type": "code",
        "id": "y1CX1qWJ4DAg",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "41e688fd7486e6ac4ea420cdc23e464a4e2c3432",
        "colab_type": "code",
        "id": "KJU1PQUE4DAi",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 128)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "30f4a6c129eb490f265d2570e16f86dc96534952",
        "colab_type": "code",
        "id": "zaUQd7194DAj",
        "outputId": "fa32c3a0-a18c-4a12-ca81-2e36715faac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model=Network()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8c3820bb60313a368c0a3d8322b21b7d8adeafeb",
        "colab_type": "text",
        "id": "lqLdKq2v4DAq"
      },
      "source": [
        "### Initializing weights and biases\n",
        "\n",
        "The weights and bias are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d148d7e2446d76d5ca6a8948d23ec513f103cdba",
        "colab_type": "code",
        "id": "BIEIlmhV4DAv",
        "outputId": "023f5445-67c5-41ac-c85f-b6a056afa3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "print(model.hidden.weight,model.hidden.weight.shape)\n",
        "print(model.hidden.bias,model.hidden.bias.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0094, -0.0321,  0.0317,  ...,  0.0060,  0.0215, -0.0294],\n",
            "        [-0.0198,  0.0351,  0.0213,  ..., -0.0089, -0.0297,  0.0034],\n",
            "        [ 0.0350,  0.0105,  0.0304,  ...,  0.0304, -0.0081,  0.0094],\n",
            "        ...,\n",
            "        [ 0.0061,  0.0312,  0.0347,  ..., -0.0232, -0.0153,  0.0039],\n",
            "        [ 0.0339, -0.0227,  0.0243,  ...,  0.0334, -0.0054, -0.0325],\n",
            "        [-0.0002,  0.0350, -0.0118,  ..., -0.0110,  0.0245, -0.0089]],\n",
            "       requires_grad=True) torch.Size([128, 784])\n",
            "Parameter containing:\n",
            "tensor([ 3.0184e-02, -3.3155e-02, -2.1110e-03, -1.7361e-02, -1.4367e-02,\n",
            "         3.3259e-02, -1.8731e-02,  2.6308e-02, -2.1619e-02, -2.9367e-02,\n",
            "        -1.8656e-02, -2.9273e-02, -1.0114e-02, -8.2450e-03, -3.2223e-03,\n",
            "        -5.7220e-03,  3.3290e-02,  2.4711e-02,  3.9513e-03,  9.0558e-03,\n",
            "        -3.0110e-02,  1.1570e-02, -3.5993e-03,  2.0162e-03,  3.3010e-02,\n",
            "        -3.2239e-02,  1.3533e-02,  6.5736e-03,  1.5783e-02, -3.0980e-02,\n",
            "         1.6267e-02, -2.4868e-02,  2.3409e-02, -2.7833e-02, -2.8823e-02,\n",
            "         3.3744e-02, -1.8794e-02,  5.8063e-03, -6.4547e-03, -3.1861e-03,\n",
            "        -6.5485e-03,  2.2418e-02, -3.3989e-02, -1.4722e-02, -1.3146e-02,\n",
            "         4.9385e-03,  2.0563e-02, -5.9989e-03,  2.7626e-02, -1.9919e-02,\n",
            "        -1.1617e-02,  2.9277e-02,  2.9418e-02, -1.6826e-02, -2.2159e-02,\n",
            "         2.3152e-02,  1.7359e-02, -1.2575e-02,  2.8086e-02,  2.6587e-02,\n",
            "        -2.7191e-02,  1.2699e-02,  3.2632e-03,  3.3537e-02,  2.8400e-02,\n",
            "         1.8912e-02, -1.8681e-02,  9.7644e-05,  3.2543e-02, -3.9153e-03,\n",
            "        -7.1321e-03, -1.1596e-02, -1.3179e-03,  4.5245e-03,  1.2594e-03,\n",
            "        -1.7501e-02,  3.2968e-02, -2.7981e-02,  8.1926e-03,  1.5501e-02,\n",
            "        -1.4408e-02,  2.5470e-02,  1.6988e-02, -2.0117e-02, -3.0206e-02,\n",
            "         1.8068e-02,  2.0254e-02, -2.0550e-02,  3.0950e-02, -2.5869e-03,\n",
            "         2.6072e-02, -2.4727e-02, -3.1581e-02,  2.3614e-02, -2.5009e-02,\n",
            "        -1.8805e-02,  2.5560e-02, -3.4563e-02,  3.4966e-02, -1.1730e-02,\n",
            "         1.2572e-02,  2.7495e-02,  3.2595e-02,  8.6234e-03,  2.0957e-03,\n",
            "         4.8739e-04, -7.1473e-03,  2.0680e-02, -2.5175e-02, -3.2904e-02,\n",
            "         3.3542e-02, -2.8888e-02,  2.0643e-02,  2.1208e-02,  2.0565e-02,\n",
            "         1.7478e-02, -2.6080e-02, -2.2256e-02,  1.1271e-02, -1.6755e-02,\n",
            "        -5.0183e-03, -1.5889e-03,  1.7369e-03,  1.6175e-02, -2.9982e-02,\n",
            "         3.5475e-02,  2.8421e-02, -1.9441e-02], requires_grad=True) torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1a1989c40df55dd4324cad2736e72481c148299d",
        "colab_type": "text",
        "id": "j3iwfmdl4DA2"
      },
      "source": [
        "For custom initialization, we can these tensors in place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dc98f7292fe8d6f40b1ea58b681acf522f500bb2",
        "colab_type": "code",
        "id": "Gut8xqfG4DA4",
        "outputId": "ad4ece78-a0a3-42de-bf96-aebd24826f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Set biases to all zeros\n",
        "model.hidden.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "354f3f9fbcf8b0c6808394ea97e794b9f43ffe60",
        "colab_type": "code",
        "id": "mP1_5vXd4DBA",
        "outputId": "d3a7a586-2784-4c0a-bef2-df5c7e61cbec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.hidden.weight.data.normal_(std=0.01)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0087, -0.0066,  0.0040,  ...,  0.0082, -0.0022, -0.0074],\n",
              "        [-0.0091,  0.0072, -0.0037,  ..., -0.0036, -0.0111,  0.0136],\n",
              "        [ 0.0055,  0.0038,  0.0046,  ...,  0.0038, -0.0039, -0.0082],\n",
              "        ...,\n",
              "        [ 0.0285,  0.0205, -0.0099,  ..., -0.0035,  0.0028,  0.0033],\n",
              "        [ 0.0073, -0.0072,  0.0006,  ...,  0.0061,  0.0179, -0.0123],\n",
              "        [-0.0026,  0.0061, -0.0005,  ...,  0.0097, -0.0202,  0.0062]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e3b948402fbcd6e8529fe5ebcd00347f1db63a1c",
        "colab_type": "code",
        "id": "0c1xeOjL4DBE",
        "colab": {}
      },
      "source": [
        "netowrk=Network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1eb03d730d47d46308e593ff4debbd6899280bbe",
        "colab_type": "text",
        "id": "e5Ked5Lw4DBJ"
      },
      "source": [
        "### Forward pass\n",
        "\n",
        "Now that we have a network, let's see what happens when we pass in an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "59df5bda3337698adad159777311294b7f8cfce4",
        "colab_type": "code",
        "id": "hvty_zDW4DBK",
        "outputId": "74971bca-adf3-4209-db74-d1c5cc2e4fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Grab some data \n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "\n",
        "# Forward pass through the network\n",
        "img_idx = 0\n",
        "ps = model.forward(images[img_idx,:])\n",
        "\n",
        "img = images[img_idx]\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHECAYAAAAOFHoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBghOAAAAA/4/S/rdna97QjUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 423,
              "height": 226
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2103e632ea834fcbd4741de8b9ee7edace23ba6b",
        "colab_type": "text",
        "id": "mBnOZK-84DBN"
      },
      "source": [
        "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, , all the weights are random!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6d611ac89023080d6ee0e42b9369376ed261a777",
        "colab_type": "text",
        "id": "Tlbgk3-D4DBN"
      },
      "source": [
        "## Add-on: People from the keras would love this!!!\n",
        "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential`.\n",
        "Lets try to build the above network using this method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e6f5405fe980380825786437c0aa8e94cb8cb92e",
        "colab_type": "code",
        "id": "hzQD5uAK4DBN",
        "outputId": "f633003c-9232-4e30-d30d-88ff273c0b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hyperparameters for our network\n",
        "input_size = 784\n",
        "hidden_sizes = [128]\n",
        "output_size = 10\n",
        "\n",
        "model=nn.Sequential(nn.Linear(input_size,hidden_sizes[0]),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_sizes[0],output_size),\n",
        "                   \n",
        "                    nn.Softmax(dim=1))\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Softmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d461b698ae5973918405c9120db6e94194347a27",
        "colab_type": "code",
        "id": "YTGl3o4q4DBQ",
        "outputId": "ada2397b-5edb-479a-ddff-421cfb9451cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Forward pass through the network and display output\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHECAYAAAAOFHoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 423,
              "height": 226
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d137ebac2a3367c41e6c001f2edf2a37b0b22211",
        "colab_type": "text",
        "id": "jjHQZNqX4DBS"
      },
      "source": [
        "### Access Layers of the network\n",
        "We can access layers  by integer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0cf54881f8e022928a962d1d83fd5614a97a039e",
        "colab_type": "code",
        "id": "Lm58z7bx4DBS",
        "outputId": "53e8b256-325f-4f73-8497-fcdfd503ab42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "print(model[0])\n",
        "model[0].weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=128, bias=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0193,  0.0175, -0.0097,  ..., -0.0264,  0.0135,  0.0245],\n",
              "        [ 0.0010, -0.0323, -0.0246,  ...,  0.0255, -0.0211, -0.0345],\n",
              "        [ 0.0170, -0.0030, -0.0328,  ...,  0.0156, -0.0089, -0.0116],\n",
              "        ...,\n",
              "        [ 0.0051, -0.0267, -0.0117,  ..., -0.0142,  0.0277,  0.0269],\n",
              "        [-0.0048,  0.0291, -0.0253,  ...,  0.0246,  0.0038,  0.0083],\n",
              "        [-0.0341, -0.0225, -0.0207,  ..., -0.0338,  0.0086,  0.0154]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0499ff7a787fc1885f5998f81f2395fc6bcc4108",
        "colab_type": "text",
        "id": "2csfs3nj4DBU"
      },
      "source": [
        "### Ordered Dict- Better way to create a network\n",
        "We can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ca7567562b0610e6ec4ec7d98f03032bbe32c061",
        "colab_type": "code",
        "id": "Fh7-9VfL4DBV",
        "outputId": "225f0c75-d213-43b9-8ca5-7ab77fd8ed3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from collections import OrderedDict\n",
        "model = nn.Sequential(OrderedDict([\n",
        "                      ('hidden', nn.Linear(input_size, hidden_sizes[0])),\n",
        "                      ('relu1', nn.ReLU()),\n",
        "                      ('output', nn.Linear(hidden_sizes[0], output_size)),\n",
        "                      ('softmax', nn.Softmax(dim=1))]))\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c67ffda9a2ace0093371017d9abf4bc02a8656dc",
        "colab_type": "text",
        "id": "fMg2ZNxD4DBX"
      },
      "source": [
        "### Access Layers using integer or name \n",
        "Now we can access layers  either by integer or name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6da7947d84c734eea2bf19acc3127bdf87ccce1c",
        "colab_type": "code",
        "id": "ypn65-Ep4DBY",
        "outputId": "89e79723-bfa0-44ed-eb24-ff48c2cb7f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "print(model[0])\n",
        "print(model.hidden)\n",
        "print(model.hidden.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=128, bias=True)\n",
            "Linear(in_features=784, out_features=128, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0213,  0.0055,  0.0044,  ...,  0.0216,  0.0212,  0.0184],\n",
            "        [-0.0282,  0.0110, -0.0335,  ..., -0.0296, -0.0002, -0.0258],\n",
            "        [-0.0075,  0.0346,  0.0275,  ...,  0.0115,  0.0269, -0.0081],\n",
            "        ...,\n",
            "        [-0.0204,  0.0250, -0.0245,  ...,  0.0287,  0.0189,  0.0337],\n",
            "        [-0.0119,  0.0049, -0.0011,  ..., -0.0234, -0.0316,  0.0198],\n",
            "        [ 0.0213, -0.0012, -0.0262,  ...,  0.0164,  0.0224,  0.0268]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "df59c9d06c7e7d2ec2b6582c6bb0934e2d49c58f",
        "colab_type": "text",
        "id": "6e3jVOgM4DBa"
      },
      "source": [
        "### Recollect everything \n",
        "Before we go ahead and train a neural network to accuractly predict the numbers appearing in the MNIST images,let us recollect the important modules that is necessary for any model training exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f0df7ddfb84bf00cee50f9b916a9c61f1a65aaa9",
        "colab_type": "text",
        "id": "f_Hs4w9J4DBb"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:03:17.978997Z",
          "start_time": "2019-02-04T13:03:17.973595Z"
        },
        "_uuid": "ff53d2bd4296f89b134eb961832043cce0e43e4d",
        "colab_type": "code",
        "id": "rekP8JB34DBb",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7a1f47e2928ea88a7c9b45edb08ea75016b6fca6",
        "colab_type": "text",
        "id": "fogM8L7P4DBg"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:07:13.687456Z",
          "start_time": "2019-02-04T13:06:40.910295Z"
        },
        "_uuid": "c2c9d59a82c6bce28a611e1f409ced8b4f8fdc39",
        "colab_type": "code",
        "id": "llRMkr-v4DBg",
        "outputId": "bd256cc2-8a0b-4d9f-a74d-b5e3397d92a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "transform=transforms.Compose([transforms.ToTensor()])\n",
        "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',train=True,transform=transform,download=True)\n",
        "testset=datasets.MNIST('~/.pytorch/MNIST_data/',train=False,transform=transform,download=True)\n",
        "\n",
        "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True,num_workers=0)\n",
        "#will explain later\n",
        "testloader=torch.utils.data.DataLoader(testset,batch_size=64,shuffle=True,num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:11, 138201.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 31253957.04it/s]                          \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 445049.83it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 140432.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 6967617.90it/s]                           \n",
            "8192it [00:00, 160376.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c7161f89857d013b0f837c620c0ed24657bed1b2",
        "colab_type": "text",
        "id": "OY4Xho394DBk"
      },
      "source": [
        "#### Build a feedforward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:03:47.741595Z",
          "start_time": "2019-02-04T13:03:47.735142Z"
        },
        "_uuid": "0e73fc284a626e4d7bbca629f817585aeb06fdd6",
        "colab_type": "code",
        "id": "qzKD0j684DBk",
        "colab": {}
      },
      "source": [
        "# TODO: Build a feed-forward network in one of the three ways mentioned above:\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dfdb486a01347095c7c8d75de1d5b74443bbfd4f",
        "colab_type": "text",
        "id": "XNVJKWay4DBo"
      },
      "source": [
        "#### Lets run one image through the network to check our work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:03:49.422306Z",
          "start_time": "2019-02-04T13:03:49.121144Z"
        },
        "_uuid": "0864af9a75655db17435ef4940945a7d9532c671",
        "colab_type": "code",
        "id": "50EvUnF34DBo",
        "outputId": "e9d2f2e7-87e0-4802-9d4d-4e97b0bd2b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "print(logits.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0d9976b19b6ca3910a3a4855754bdc1e3de1f52f",
        "colab_type": "text",
        "id": "kOqfHHNJ4DBs"
      },
      "source": [
        "#### Define a loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:03:52.643210Z",
          "start_time": "2019-02-04T13:03:52.638129Z"
        },
        "_uuid": "22466cb3a58aad481e903428de2642ff67e9bc1f",
        "colab_type": "code",
        "id": "k7KhsCL94DBt",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:03:55.680366Z",
          "start_time": "2019-02-04T13:03:55.547651Z"
        },
        "_uuid": "2e3bda9d30daf829a8e19537715860ff7c678329",
        "colab_type": "code",
        "id": "inh-tLMV4DBu",
        "outputId": "e8d550c3-9934-46eb-82f4-f234bee2572c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate the loss with the logits and the labels\n",
        "loss=criterion(logits,labels)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3049, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8a7dd6c45e94460f48dd048b35229f74a399a988",
        "colab_type": "text",
        "id": "xlkpF1m_4DBw"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way.\n",
        "\n",
        "PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d3361f46b9d9dbf06bc4a6b257f472129c2b01e1",
        "colab_type": "text",
        "id": "P6CQP81X4DBw"
      },
      "source": [
        "Let's see an example to understand it better.Then again we will head back to our modelling task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5ab21186791f7e319778106ca1ffb327d0847e16",
        "colab_type": "code",
        "id": "0ZYgrLYf4DBx",
        "outputId": "a22e2c03-6e10-4813-805d-1f0ea82329fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(\"x:\",x)\n",
        "y = x**2\n",
        "print(\"y:\",y)\n",
        "## grad_fn shows the function that generated this variable\n",
        "print(\"y.grad_fn:\",y.grad_fn)\n",
        "z = y.mean()\n",
        "print(\"z:\",z)\n",
        "print(\"x.grad:\",x.grad)\n",
        "z.backward()\n",
        "print(\"x.grad:\",x.grad)\n",
        "print(\"x/2:\",x/2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: tensor([[ 0.5090, -0.1186],\n",
            "        [-0.6671, -0.0789]], requires_grad=True)\n",
            "y: tensor([[0.2591, 0.0141],\n",
            "        [0.4450, 0.0062]], grad_fn=<PowBackward0>)\n",
            "y.grad_fn: <PowBackward0 object at 0x7f3d1d46e6a0>\n",
            "z: tensor(0.1811, grad_fn=<MeanBackward0>)\n",
            "x.grad: None\n",
            "x.grad: tensor([[ 0.2545, -0.0593],\n",
            "        [-0.3335, -0.0394]])\n",
            "x/2: tensor([[ 0.2545, -0.0593],\n",
            "        [-0.3335, -0.0394]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "94d46a1835ad4987ff28365b28ee304d366336dc",
        "colab_type": "text",
        "id": "mdd4kzZa4DBy"
      },
      "source": [
        "## Loss and Autograd together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:04:00.684688Z",
          "start_time": "2019-02-04T13:04:00.535643Z"
        },
        "_uuid": "b0c5e229539704b93a5991c27849bd7b41abae80",
        "colab_type": "code",
        "id": "x2Bp2C_14DBz",
        "outputId": "d5b04102-2af4-4b25-b16e-cde6230f562e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logits = model(images)\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "\n",
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d184b346f9ed4194de74a29675da09076e52e0c4",
        "colab_type": "text",
        "id": "iHu0ac6Z4DB1"
      },
      "source": [
        "## Defining the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:04:04.271653Z",
          "start_time": "2019-02-04T13:04:04.266694Z"
        },
        "_uuid": "efadf9e312ec51f9f36d25f043d011c27f4f8fe2",
        "colab_type": "code",
        "id": "uclj7uN44DB2",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "91c0777ba686873bd972d96e384c090c9baae3d8",
        "colab_type": "text",
        "id": "YMzGLiTq4DB3"
      },
      "source": [
        "## Training for real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:05:20.593146Z",
          "start_time": "2019-02-04T13:04:05.998666Z"
        },
        "_uuid": "6b6ac5071aad8b3232596ed1d4807d73aab09df3",
        "colab_type": "code",
        "id": "SG_yue954DB3",
        "outputId": "50a52f08-a800-4e7a-bcb6-ee9cb11f2995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output=model.forward(images)\n",
        "        # TODO: Training pass\n",
        "        \n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*images.shape[0]\n",
        "    else:\n",
        "        print(f\"Epoch:{e} Training loss: {running_loss/len(trainloader.dataset)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Training loss: 1.1391830668767293\n",
            "Epoch:1 Training loss: 1.2300454666773477\n",
            "Epoch:2 Training loss: 1.4402017743428548\n",
            "Epoch:3 Training loss: 1.687267345937093\n",
            "Epoch:4 Training loss: 1.6394379685719809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:06:05.063846Z",
          "start_time": "2019-02-04T13:06:04.983101Z"
        },
        "_uuid": "6d837662f725dc7196ba3d24130aa23090dc1616",
        "colab_type": "code",
        "id": "nAsqu-lu4DB6",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logits = model.forward(img)\n",
        "\n",
        "# Output of the network are logits, need to take softmax for probabilities\n",
        "ps = F.softmax(logits, dim=1)\n",
        "#helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "37a44994683bfe1fee884125d2e58ed08b62720b",
        "colab_type": "text",
        "id": "g4hUTb6u4DB9"
      },
      "source": [
        "## Inference and Validation\n",
        "\n",
        "The goal of validation is to measure the model's performance on data that isn't part of the training set. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are precision and recall and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e94326ca7cdc742c2c575294d260c257a97cab87",
        "colab_type": "text",
        "id": "KjLRoPhS4DB-"
      },
      "source": [
        "### Inference on a batch of images\n",
        "Let us try to do this for a batch of images.Before that we will make some changes in our architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:08:55.536357Z",
          "start_time": "2019-02-04T13:08:55.509217Z"
        },
        "_uuid": "e4ec78de08b2f24f5032ba181ec7a7d79428261a",
        "colab_type": "code",
        "id": "JmXSm5P64DB-",
        "outputId": "d77d894c-a3d8-4c26-bc4b-be538ee69df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images, labels = next(iter(testloader))\n",
        "images.shape,labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:09:03.958533Z",
          "start_time": "2019-02-04T13:09:03.928394Z"
        },
        "_uuid": "3f2244405b587c87c9347abd1ed4ab150f8d80aa",
        "colab_type": "code",
        "id": "g85IuZKD4DCC",
        "outputId": "bed95d0b-1dc1-44d8-cc97-c9eca7287809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images, labels = next(iter(testloader))\n",
        "img = images.view(images.shape[0], 784)\n",
        "# Get the class probabilities\n",
        "ps = torch.exp(model(img))\n",
        "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
        "print(ps.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:09:06.432988Z",
          "start_time": "2019-02-04T13:09:06.341035Z"
        },
        "_uuid": "72a2ebdd77e3380b972e24e1565bc7744beedd27",
        "colab_type": "code",
        "id": "YLRbwojf4DCH",
        "outputId": "0f4bc9ae-a938-4233-dc1e-73ceb7b043b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "top_prob,top_class=ps.topk(1,dim=1)\n",
        "top_prob.shape,top_class.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1]), torch.Size([64, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:10:21.313112Z",
          "start_time": "2019-02-04T13:10:21.305216Z"
        },
        "_uuid": "9f6368720bf311e1ee9977f0f2562a02b1afc12f",
        "colab_type": "code",
        "id": "BJ4d8SbF4DCO",
        "outputId": "41fe7554-c4ec-45fe-bec9-bb919e4ef633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "top_class.view(64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 1, 3, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3,\n",
              "        6, 1, 6, 6, 3, 6, 6, 3, 1, 6, 3, 3, 3, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 3,\n",
              "        6, 3, 6, 1, 6, 6, 6, 6, 3, 0, 3, 3, 6, 6, 6, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a9a05d7571a12641d0da644ae00b1608346faf6a",
        "colab_type": "code",
        "id": "sScTfQeQ4DCR",
        "outputId": "ac69ec43-4c4f-4c6b-dc55-bf5ee0ba391e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame({\"Predicted\":top_class.view(top_class.shape[0]),\"Actual\":labels})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Predicted  Actual\n",
              "0           6       2\n",
              "1           1       1\n",
              "2           3       5\n",
              "3           6       1\n",
              "4           3       9\n",
              "5           6       6\n",
              "6           6       5\n",
              "7           6       0\n",
              "8           6       8\n",
              "9           6       0\n",
              "10          6       7\n",
              "11          3       8\n",
              "12          6       3\n",
              "13          3       9\n",
              "14          6       6\n",
              "15          6       6\n",
              "16          6       6\n",
              "17          6       2\n",
              "18          6       7\n",
              "19          6       7\n",
              "20          6       8\n",
              "21          3       1\n",
              "22          6       8\n",
              "23          3       5\n",
              "24          6       7\n",
              "25          1       1\n",
              "26          6       7\n",
              "27          6       9\n",
              "28          3       4\n",
              "29          6       0\n",
              "..        ...     ...\n",
              "34          3       8\n",
              "35          3       5\n",
              "36          3       5\n",
              "37          6       6\n",
              "38          6       2\n",
              "39          6       7\n",
              "40          3       3\n",
              "41          6       2\n",
              "42          6       9\n",
              "43          6       4\n",
              "44          6       8\n",
              "45          1       1\n",
              "46          6       2\n",
              "47          3       5\n",
              "48          6       2\n",
              "49          3       3\n",
              "50          6       6\n",
              "51          1       1\n",
              "52          6       7\n",
              "53          6       5\n",
              "54          6       6\n",
              "55          6       4\n",
              "56          3       3\n",
              "57          0       0\n",
              "58          3       8\n",
              "59          3       5\n",
              "60          6       7\n",
              "61          6       4\n",
              "62          6       6\n",
              "63          3       4\n",
              "\n",
              "[64 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3f958e5da0aed9b404c743c8798b64e0d4341fdd",
        "colab_type": "code",
        "id": "QPgumHuE4DCV",
        "outputId": "bb3999a7-5b1c-4310-e142-9fc32f11be03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "equals=top_class == labels.view(*top_class.shape)\n",
        "accuracy=torch.mean(equals.type(torch.FloatTensor))\n",
        "accuracy.item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.265625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:27:29.556056Z",
          "start_time": "2019-02-04T13:27:29.541115Z"
        },
        "_uuid": "352673a9d93a8f6b52165952364a7793ff43b8f0",
        "colab_type": "code",
        "id": "QecOZ7Bt4DCZ",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Now with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "\n",
        "        # output so no dropout here\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "\n",
        "        return x\n",
        "        \n",
        "model=Network()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
        "criterion=nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:29:20.825396Z",
          "start_time": "2019-02-04T13:27:30.220213Z"
        },
        "_uuid": "d7ef3898265ce167202ee321100129a95e3b748e",
        "colab_type": "code",
        "id": "ZJvxs4ib4DCa",
        "outputId": "d8d7eb58-15ee-4c46-ebab-cbd24bb46d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "epochs=5\n",
        "train_losses,test_losses=[],[]\n",
        "for e in range(epochs):\n",
        "    running_loss=0\n",
        "    for images,labels in trainloader:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        #images=images.view(images.shape[0],-1)\n",
        "        log_ps=model(images)\n",
        "        loss=criterion(log_ps,labels) # a single value for ex 2.33\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.shape[0] ## (2.33*64 + 2.22*64 + 2.12*33) / 138 \n",
        "        \n",
        "    else:\n",
        "        test_loss=0\n",
        "        accuracy=0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images,labels in testloader:\n",
        "                log_ps=model(images)\n",
        "                test_loss+=criterion(log_ps,labels) *images.shape[0]\n",
        "                ps=torch.exp(log_ps)\n",
        "                top_p,top_class=ps.topk(1,dim=1)\n",
        "                equals=top_class==labels.view(*top_class.shape)\n",
        "                accuracy+=torch.sum(equals).item()\n",
        "        model.train()\n",
        "        train_losses.append(running_loss/len(trainloader.dataset))\n",
        "        test_losses.append(test_loss.item()/len(testloader.dataset))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader.dataset)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader.dataset)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader.dataset)))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5..  Training Loss: 0.402..  Test Loss: 0.204..  Test Accuracy: 0.947\n",
            "Epoch: 2/5..  Training Loss: 0.300..  Test Loss: 0.193..  Test Accuracy: 0.952\n",
            "Epoch: 3/5..  Training Loss: 0.319..  Test Loss: 0.197..  Test Accuracy: 0.955\n",
            "Epoch: 4/5..  Training Loss: 0.276..  Test Loss: 0.190..  Test Accuracy: 0.954\n",
            "Epoch: 5/5..  Training Loss: 0.279..  Test Loss: 0.190..  Test Accuracy: 0.960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-04T13:24:46.424543Z",
          "start_time": "2019-02-04T13:24:46.420315Z"
        },
        "colab_type": "code",
        "id": "sDXM694d4DCc",
        "outputId": "b53b8261-bc54-4e85-8814-1ad95da33689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "running_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16732.30222570896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "086d29056a5322e8c76820fcdc87ddc5424539ff",
        "colab_type": "code",
        "id": "n_iWSBVm4DCe",
        "outputId": "928ff11f-a9d1-4968-dce8-02f35cb708a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3d1d5c3fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAH0CAYAAABICFkFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xdc1uX+x/HXBQiCIDLcKLj3AtQy\nt6kNV9syT3UqWzYc1emk7XPqZ+rR0sqyo6adTBtolqW5NU0BNTXFFbgnCLiQ8f39ccMtCCgKcsPN\n+/l48Lgf93d+cL753tfnuoxlWYiIiIiIiHNwcXQBIiIiIiJSdBTwRURERESciAK+iIiIiIgTUcAX\nEREREXEiCvgiIiIiIk5EAV9ERERExIko4IuIiIiIOBEFfBERERERJ6KALyIiIiLiRBTwRURERESc\niAK+iIiIiIgTUcAXEREREXEiCvgiIiIiIk5EAV9ERERExIko4IuIiIiIOBEFfBERERERJ+Lm6AJK\nOmPMX0BFINbBpYiIiIiIcwsBkizLqlOYiyjgX1lFT09P/yZNmvg7uhARERERcV7bt2/n3Llzhb6O\nAv6VxTZp0sQ/KirK0XWIiIiIiBMLCwsjOjo6trDX0Rh8EREREREnooAvIiIiIuJEFPBFRERERJyI\nAr6IiIiIiBNRwBcRERERcSIK+CIiIiIiTkQBX0RERETEiSjgi4iIiIg4EQV8EREREREnooAvIiIi\nIuJEFPBFRERERJyIAr6IiIiIiBNRwBcRERERcSIK+CIiIiIiTkQBX0RERETEiRRZwDfGBBlj/muM\nOWSMSTHGxBpjJhhj/Apxzc7GmHRjjGWMeecyx3UwxvxkjIk3xpwzxvxhjHnBGON6rfcuCRb8cYjE\ns6mOLkNERERESpEiCfjGmHpAFPAIsB74D7AXeB5Ya4wJuIZr+gAzgLNXOK4/sBLoDHwPTALcM2uY\nfbX3LQlS0zN4Y/42hv5vI89/vZH0DMvRJYmIiMh1dvr0aYwx9OnTp9DXCg8Px9vbuwiqKjqTJk3C\nGMM333zj6FKcXlE9wf8IqAI8Z1nWAMuy/mFZVndsIbsR8K9ruOZEwBd4N78DjDEVgc+AdKCrZVmP\nWpb1ItAaWAvcbYwZeA33dqjf98Yz/bdYAJbHHGf84hjHFiQiIuLEjDFX9TV9+nRHlyxyWW6FvUDm\n0/teQCww+ZLdrwNDgMHGmBGWZZ0p4DX7Y/s0YPAVarwbqAx8YVlWZNZGy7LOG2NGAUuApyhlT/I7\nNgjkqa71+Hj5HgAmL9tD8xq+3NqiuoMrExERcT6vv/56rm0TJkwgMTGR559/nkqVKuXY17p16+tS\nR4UKFdi+fXuRPHn/9ttvSUlJKYKqpDQqdMAHumW+LrIsKyP7Dsuyko0xa7D9AHADtsB9WcaYKtie\nykdYljXLGPPwZQ7vnvn6cx77VmIb3tPBGONhWVap+lM+slcj/jyUxIqdxwEYMXczdSt706iaj4Mr\nExERcS5vvPFGrm3Tp08nMTGRF154gZCQkGKpwxhD48aNi+RawcHBRXIdKZ2KYohOo8zXnfns35X5\n2rCA1/sMW11PFubelmWlAX9h+yGm7pUuZIyJyusLKJq/aVfJ1cXwwcA2BAd4AXD2QjpDZkaq6VZE\nRKSEyBrnfu7cOUaNGkX9+vVxd3dn6NChAJw8eZL33nuPLl26UKNGDdzd3alatSp33XUXUVFRua6X\n3xj8kSNHYowhMjKSL7/8krCwMDw9PQkMDGTw4MEcO3Ys39qyW7BgAcYYxo4dy/r16+nduzcVK1bE\n29ubm2++Oc+aAPbt28eDDz5IYGAgXl5ehIWF8fXXX+e4XmGtXbuW/v37ExgYiIeHB3Xr1uWFF17g\n+PHjuY49dOgQzz//PA0bNsTLyws/Pz+aNGnCo48+yv79++3HZWRk8Nlnn9G+fXsCAwPx9PSkdu3a\n3HbbbURERBS65pKsKJ7g+2a+JuazP2t7pXz22xlj/g70A+6zLOtocd67JPL1Kseng8O546M1nL2Q\nTtzJszw7eyPTHm6Lq4txdHkiIiJlXkZGBn369CEmJobevXsTEBBgf3q+ceNGXn/9dbp27Ur//v3x\n9fXlr7/+Yv78+SxYsIDFixfTuXPnAt9rzJgxLFiwgP79+9OtWzfWrFnDrFmz2Lp1K5GRkbi6Fmzy\nwNWrVzNq1Ci6du3KkCFD2Lt3LxEREXTt2pWtW7fmePp/4MABbrzxRg4dOkSPHj1o27YtBw8e5KGH\nHuLWW2+9ul+sfMyZM4dBgwbh6urKPffcQ1BQEOvWrWPixInMmzePNWvWUKNGDQCSkpJo3749hw4d\nolevXgwYMIDU1FTi4uL45ptvGDx4MLVq1QLghRde4MMPP6RBgwbcf//9eHt7c+jQIX7//XciIiIY\nMGBAkdRfEhVFwC8SxpgQYAIw17KsOcV9f8uywvLanvkUP7SYy7FrVM2Hsfe04ukvowFYufM4YxfF\n8PItDvlgQURERLI5d+4cycnJbN26NddY/dDQUI4cOYKfX84Zw/fs2UP79u0ZMWIEGzZsKPC9lixZ\nwqZNm2jY0DYowrIsBgwYwPz58/nll1+47bbbCnSdefPmMXfuXO6++277tnHjxjFy5EgmT57MmDFj\n7NtHjBjBoUOHeOuttxg9erR9+9NPP03Hjh0LXHt+4uPjeeyxxzDGsHr1asLDw+37Ro8ezTvvvMPQ\noUP57rvvAPjxxx85cOAAo0aN4u23385xrfPnz5OWlgZcfHpfr149tmzZgoeHR45jT5w4UejaS7Ki\nCPhZT8l989mftf3UFa7zX+Ac8LQD7l2i3daiOk93rcdHmU23Hy+3Nd3e3lJNtyIicn2F/ONHR5dQ\nYLHv3e6Q+7777ru5wj2Av79/nsfXq1ePfv36MW3aNOLj4/M97lIvvviiPdyDbcz+Y489xvz581m/\nfn2BA37v3r1zhHuAIUOGMHLkSNavX2/flpyczHfffUeVKlV48cUXcxx/ww03cM899zB7duHmMZk7\ndy7Jyck8/vjjOcI9wKuvvsrUqVOZN28eJ06cIDAw0L7P09Mz17XKly+f470xBnd39zw/2ch+LWdU\nFGPws+ZwzG+MfYPM1/zG6GcJxTbV5vHMha0sY4wFTMvc/2rmtuyDpvK9tzHGDagDpGGbk79UG9Gr\nEV0bVba/Hzl3MzuOJDmwIhEREQFo165dvvuWLVvGnXfeSVBQEO7u7vapNqdNs8WbgwcPFvg+lwZg\nwD4cJSEhoVDX8fHxwdfXN8d1tm7dSlpaGmFhYbnCM1AkT/Cjo20jFLp3755rX/ny5enQoQMZGRls\n3rwZgJ49e1K5cmVGjx5Nnz59mDx5Mps2bSIjI8c8L7i4uDBw4EC2b99O8+bNGT16NIsWLSI5ObnQ\nNZcGRfEEf1nmay9jjEv2mXQyF6u6CdtsNuuucJ0vAK88tjfAtojVJmyLaW3Mtm8pMAi4BfjqkvM6\nZ15vZWmbQScvri6Gife1of/k1cSePMu51HSGfBHF/KE3UcnL3dHliYiIlEleXl74+OQ9w92sWbP4\n29/+hre3Nz179qROnTpUqFABYwyLFi1i7dq1VzWVZV6fEri52aJcenp6oa6Tda3s10lMtA2UqFq1\nap7H57f9amTdo3r1vEclZG0/dco2GCMwMJDff/+dN954gwULFvDjjz/aa3nuued4+eWX7U/sp0yZ\nQuPGjZkxYwbvvPMOAOXKlaNfv36MGzfOqWcaKnTAtyxrjzFmEbapMJ8BPsy2+02gAjAl+xz4xpjG\nmefuyHad5/K6fuY0mZ2BHy3LGnXJ7m+A/wMGGmM+zJoL3xhTHngn85iPr/27K1l8vcrx6d/CuWPy\nGs5cSGdf/Fme/Woj0x9pp6ZbERG5Lhw17KW0MCb//39HjRqFj48PGzdupG7dnBP67dq1i7Vr117v\n8gqlYsWKABw9mve8J/ltvxq+vrbR1EeOHMlz/+HDh3McB1CnTh1mzJhBRkYGW7duZcmSJUyaNIlX\nX30VV1dXXn75ZcAW5l966SVeeukljhw5wqpVq5g1axbffvstO3bsYPPmzQVuTC5timol26eBY8AH\nxpgIY8y7xpilwDBsQ3NeveT47ZlfhWJZVhLwOOAKLDfGTDXGjMH2tP9GbD8AfF3Y+5QkDav6MO7e\nVvb3q3ad4P1ftNKtiIhISZKWlkZcXBytW7fOFe5TU1NLfLgHaNGiBW5ubkRFRXH+/Plc+1evXl3o\ne7Rp0waA5cuX59qXkpLC2rVrMcbkubiYi4sLLVu2ZNiwYSxYsAAg3+kvq1Wrxj333MO8efNo164d\n27ZtY/fu3YWuv6QqkoBvWdYeIByYDrQHRgD1gInADZZlnSyK++Rz7wigC7aFre4CngVSgeHAQMuy\nrOt1b0e5pXl1hnarb3//yYo9LPjjkAMrEhERkezc3NyoWbMm27ZtyzFjS0ZGBq+88gp//fWXA6sr\nGB8fHwYMGMCxY8d4//33c+z7/fffmTt3bqHvce+99+Lt7c20adPs4+yzvPvuuxw+fNg+Pz7AH3/8\nkecMOFmfJnh52UZ7nz59OkfDcJaUlBT7sKC8GnWdRZFNk2lZ1n7gkQIeW+DxJJZlTcf2g8PljlkD\nFKx13EkM69mQbYcSWRZjWwDixbl/UDfQm6Y1Kjq4MhEREQEYNmwYI0eOpGXLltx55524uLiwYsUK\nYmNjufXWW1m4cKGjS7yicePGsXr1al577TVWrlxJ27ZtOXDgAHPmzKFv375ERETg4nLtz4v9/f35\n9NNPGTx4MDfeeCP33HMPNWvWZN26dSxbtozatWszadIk+/Hz58/nrbfe4qabbqJBgwYEBgYSFxfH\nvHnzcHV1ZeTIkYBtzH779u1p3Lgxbdq0oXbt2pw9e5aff/6ZXbt28cADD1C7du1C//qUVEU1REeK\nmauLYcLANtQJrADAudR0npgVScKZCw6uTERERACGDx/OJ598QkBAAP/973/56quvaNiwIevXr6dp\n06aOLq9Aateuzbp167j//vuJjo7mP//5D9u2bWPGjBn0798fuDhW/1rdf//9rFixgh49erBgwQLG\njh3L3r17efbZZ9mwYQM1a9a0H9uvXz+eeuopEhMT+e677xg/fjy//fYbffv2Zd26dfbFtwICAvj3\nv/9NrVq1WLVqFRMmTGD27NlUrlyZqVOnMmPGjELVXNIZJxzBUqSMMVGhoaGh+S3f7Gi7jiYzILPp\nFqBTg0CmPdwWN1f97CYiIiLXz/PPP88HH3zA6tWruemmmxxdjlMICwsjOjo6Or8FWAtKKbCUa1DV\nh3H3Xmw8UdOtiIiIFKVDh3L3+W3YsIFPP/2UGjVq0L59ewdUJZdTZGPwxXFuaV6N57rX54Oltm7w\nKSv30qymL/1a1XBwZSIiIlLaNWnShNDQUJo1a0b58uWJiYmx9w9MnjzZPhe/lBx6gu8kXri5IT0a\nV7G/f+mbzfx5SCvdioiISOE8/fTTxMfH8+WXXzJx4kR+//13+vTpw8qVKxkwYICjy5M8aAz+FZT0\nMfjZJZ1PZcCkNew9YVtTLMjPkx+GdsSvgla6FRERESnpNAZfcqlYvhyf/i0Mbw/bR2UHEs7x7Fcb\nSUvPcHBlIiIiIlJcFPCdTP0qPozPttLt6t0n+L+fdziwIhEREREpTgr4TqhXs2o816OB/f1nq/5i\n3qaDDqxIRERERIqLAr6TeqFHA25ucrHp9uVv/2DboUQHViQiIiIixUEB30m5uBjG39eaupVtK92e\nT81gyBdRxGulWxERERGnpoDvxCqWL8eng8PtTbcHT51j6P+i1XQrIiIi4sQU8J1c/Sre/Oe+iyvd\n/rbnJO8tVNOtiIiIiLNSwC8Dejatygs3X2y6nbpaTbciIiIizkoBv4x4rnsDejatan//0jd/sPWg\nmm5FREREnI0Cfhnh4mIYf28r6mU23aakZfDEzChOnk5xcGUiIiJlx+7duzHG8Nhjj+XY/uCDD2KM\n4cCBAwW+VlBQEPXr1y/qEnPIr15H+vXXXzHG8M477zi6lBJLAb8M8Slfjk//Fo5PjqZbrXQrIiJl\n26BBgzDG8NFHH13x2F69emGM4fvvvy+Gyq6/tLQ0jDHcfPPNji5FipACfhlTr3LOptu1e0/y75/U\ndCsiImXX448/DsDUqVMve1xsbCy//vor1atXp2/fvkVaw/vvv8/27dupVq1akV63sIKDg9m+fbue\nlpcyCvhl0M1NqzK8Z0P7+/+u+Yvvogv+kaCIiIgz6dq1Kw0bNmTjxo1ER0fne9znn3+OZVk88sgj\nuLm5FWkN1atXp3HjxkV+3cIqV64cjRs3LnE/eMjlKeCXUUO71adXtqbbV77boqZbEREps7Ke4n/2\n2Wd57k9PT2fatGm5xqMfPHiQN998kw4dOlCtWjXc3d2pWbMmgwYNYseOgn9Cnt8YfMuy+OCDD2ja\ntCkeHh7UrFmT5557jqSkpDyvc+rUKcaMGUO3bt2oWbMm7u7uVKlShQEDBvD777/nOHbq1KmUK1cO\ngCVLlmCMsX9lPbG/3Bj8Q4cO8dRTTxEcHIyHhwdVqlThrrvuYuPGjbmOnTp1KsYYZs2axZIlS+jS\npQve3t74+vrSt29fYmJiCvxrdTkxMTEMHjyYGjVq4O7uTo0aNXjooYfYs2dPrmOTkpJ48803ad68\nOT4+Pvj4+FC/fn0GDhyY63uIiIige/fuVKtWzf770LVrVz755JMiqbuoKeCXUVkr3dav4g2o6VZE\nRMq2hx56CHd3d7766ivOnj2ba//ChQs5ePAgN998M3Xq1LFvX7ZsGWPGjMHf35+77rqLF154gXbt\n2jFnzhzatWvH1q1bC1XX0KFDef7550lMTOSJJ55g4MCB/Pjjj/Tq1YvU1NRcx2/dupVRo0bh5uZG\n3759GT58OD169GDx4sV06tSJX3/91X5saGgoo0ePBqBOnTq8/vrr9q/OnTtftq49e/YQFhbGJ598\nQsOGDRk+fDg9e/bkhx9+4MYbb2ThwoV5nhcREcEtt9xCpUqVeOqpp+jQoQMLFiygS5cuxMfHF+JX\nCtatW0fbtm358ssvad++PSNGjKB9+/bMnDmT8PDwHJ/OWJZFr169eOONN/D19eXxxx/nySefpG3b\ntixfvjzHD0MfffQRd9xxBzt27KBfv36MGDGCW2+9lTNnzjBjxoxC1XzdWJalr8t8AVGhoaGWs9pz\nLNlq/vrPVvDLC6zglxdY9035zbqQlu7oskRERIrdvffeawHWtGnTcu3r16+fBVhz587Nsf3IkSNW\ncnJyruOjo6MtLy8vq0+fPjm279q1ywKsRx99NMf2QYMGWYC1f/9++7YVK1ZYgNWgQQMrPj7evv3s\n2bNW27ZtLcCqV69ejuskJCRYJ06cyFVPbGysVbVqVat58+Y5tqemplqA1aNHj1znXK7e7t27W4D1\n3nvv5di+cuVKy8XFxQoMDLTOnDlj3/7ZZ59ZgOXm5mYtW7YsxzkjR460AGvcuHF51nCpxYsXW4D1\n9ttv27elp6dbDRo0sABr9uzZOY6fNWuWBVjNmjWzMjIyLMuy/f4A1t13353r+mlpaTl+vVu2bGmV\nL1/eOn78eK5j89pWGKGhoRYQZRUyv5asgV5S7OpW9mbiwNY8OiMSy4J1e+P590/beb1vM0eXJiIi\nJcEbvo6uoODeKNxQ0yFDhjBnzhymTp3Kww8/bN9++PBhfvrpJ6pUqUL//v1znFO1alXy0qZNG7p0\n6cKSJUtIT0/H1dX1quuZNm0aAKNHj8bPz8++3dPTk3//+9/07Nkz1zmVKlXK81rBwcHceeedfPzx\nxxw6dIgaNWpcdT1ZYmNjWbp0KXXq1GHEiBE59nXq1Il7772X2bNnExERwQMPPJBj/6BBg+jatWuO\nbUOGDGHs2LGsX7/+mmtatWoVu3btolOnTtx333257jlp0iTWrVvH2rVr6dChg32fp6dnrmu5urrm\n+PUGWy9C1nCm7AIDA6+55utJQ3SE7o2rMvzmi02309bE8m2Umm5FRKRs6d69O/Xq1WPNmjVs377d\nvn3atGmkpaXx8MMP5xny5s+fz+233061atUoV66cfRz7woULOXfu3DUPPckaUtKlS5dc+zp37oyL\nS94xbtWqVdxzzz3UqlULDw8Pez0ff/wxYOsbKIys8emdO3fOsym4e/fuOY7LLjw8PNe2WrVqAZCQ\nkHDNNWX9WmXd+0o1tWjRghYtWjBz5kw6derE+++/z9q1a/Mc9jRo0CCSk5Np2rQpw4cPZ968eZw4\nceKaay0OCvgCwDPd6tO7Wbam2++38MeBUw6sSEREpHhlbybNmjLTsiw+//xzjDH2Rtzsxo0bR//+\n/Vm3bh1dunRh2LBhvPbaa7z++uu0aNECgJSUa+tvS0y0fSKR16cE7u7uuZ4yA8ydO5euXbuycOFC\nwsPDGTp0KKNHj+b111+nU6dOharn0rqqV6+e5/6s7adO5c4ReX3CkPVDQnp6erHV5ObmxrJly3ju\nuef466+/eOmll+jQoQOBgYE8//zznDlzxn7uSy+9xLRp0wgKCmLChAkMGDCAKlWq0KNHj8vOuuRI\nGqIjgK3pdty9rdk7eQ27jp3mQmbT7Q/PdiTQ28PR5YmIiKMUcthLafPII4/w2muv8cUXX/Duu++y\natUq9u7dS/fu3XOtGpuamsqbb75JjRo1iI6OzhXEV61aVahafH1tw6OOHj1K7dq1c+y7cOECCQkJ\nuQLz6NGjKV++PFFRUTRq1CjHvv379xe6pux1HTlyJM/9hw8fznFccbiWmgICApg4cSITJ05k165d\nLF++nClTpvDBBx+QlJRkHyIF8PDDD/Pwww9z6tQp1qxZw3fffce0adPo3bs3O3bsICAg4Dp+d1dP\nT/DFztvDzbbSbXnbz32HE8/z9JfRpGqlWxERKSOqVq1Kv379OHHiBBEREfYn+UOGDMl17NGjR0lO\nTqZjx465wn1SUlKeQ1SuRmhoKAArVqzItW/lypVkZOT+/3nPnj00b948V7hPT09nzZo1uY7PGuZz\nNU/P27RpA9h+gMnrvGXLluWovzhk1bR8+fI891+ppgYNGvD444+zYsUKPD09iYiIyPO4SpUqcfvt\nt/P5558zePBgTpw4werVqwv/DRQxBXzJoU5gBT64vw3G2N6v/yuef/24/fIniYiIOJGsoTjjxo3j\n+++/JzAwkDvuuCPXcdWrV8fDw4MNGzbkGNJx4cIFnn322UKNKQfbpwkAb7/9do7hLufOneOf//xn\nnucEBwcTExOT40m2ZVm89tprec417+Ligp+fH/v27StwXSEhIXTr1o09e/bw4Ycf5ti3Zs0avv76\nawICAnI1JF9PnTt3pn79+ixfvjxXOJ89ezZr166lSZMm3HjjjQDs3buX2NjYXNdJSEggNTUVLy8v\n+7Zly5ZlzaxoZ1kWx44dA8hxbEmhITqSS7dGVRjZqxHv/2L7h2D6b7E0q1GRe8JrObgyERGR669X\nr16EhITYZ3UZOnQo7u7uuY5zdXXl2WefZezYsbRo0YJ+/fqRkpLC0qVLSUxMpEuXLnk+fS+ozp07\n89RTT/Hxxx/TrFkz7r77btzc3IiIiKBy5cpUqVIl1znDhg1j6NChtG7dmrvuugs3NzdWrVrFzp07\n6dOnDwsWLMh1To8ePfjmm2/o378/bdq0wc3Nja5du9KxY8d8a5syZQodO3Zk2LBhLFy4kLCwMPbt\n28fcuXNxc3Nj+vTpVKhQ4Zq/96vl4uLCjBkz6NWrF3fddRcDBgygUaNG7Nixg3nz5lGxYkW++OIL\nTOYTzOjoaO69917atWtHkyZNqF69OseOHWPevHmkpaXx8ssv26/dt29f/Pz8uOGGGwgJCSE9PZ1V\nq1YRGRlJu3bt6NatW7F9nwWlJ/iSp6e71uPW5heXpX41Yiub96vpVkREnN+lK7fm1Vyb5d1332XM\nmDF4eHgwZcoUIiIiaN++PRs2bCAoKKjQtUyaNIkJEyZQsWJFPvnkE2bPns1tt93GokWL8pzR55ln\nnuHzzz+natWqTJs2jS+//JKQkBB+//13WrVqlec9PvzwQwYOHMjatWt5++23GT16dL5DXbI0aNCA\nqKgonnjiCbZv387YsWP5+eefuf3221mzZg19+vQp9Pd+tTp06MCGDRsYOHAgv/32m31mnAceeIDI\nyMgcM/i0b9+el19+GRcXFxYuXMi4ceP45ZdfaNeuHT///DPPPfec/dgxY8YQFhZGVFQUkydPZvr0\n6aSnpzNmzBiWLFmS50xCjmYu/chBcjLGRIWGhoZGRUU5upRidyYljTs+WsPOo6cBqO5bnvlDO1LZ\nR023IiIiIkUtLCyM6OjoaMuywgpzHT3Bl3xV8HDj08HhVMzWdPvMl9FcSFPTrYiIiEhJpYAvlxVy\nadNtbDzv/PinY4sSERERkXwp4MsVdW1UhRd7X5xu64u1ccyJ3O/AikREREQkPwr4UiBPdanH7S0u\nrg436vutbFLTrYiIiEiJo4AvBWKMYczdLWlczQeAC+kZPDkzimPJ5x1cmYiIiIhkp4AvBVbBw40p\ng8Pw9bRNy3UkSU23IiIiIiWNAr5cleAAW9OtS2bT7YbYBN5eoKZbERERkZJCAV+uWpeGlXmxd2P7\n+5nr4vh6Q8GXuBYRERGR60cBX67Jk13qcnvLi023oyO2Eb0vwYEViYiIiAgo4Ms1Msbw/iVNt0/N\nUtOtiIiIiKMp4Ms183K3rXSb1XR7NCmFp2ep6VZERETEkRTwpVBqB3gx6YGLTbeRcQm8+cM2xxYl\nIiIiUoYp4EuhdWpQmZdvudh0++Xv+5i9Xk23IiIiIo6ggC9FYkjnuvRtVcP+/rV5aroVERERcQQF\nfCkSxhj+764WuVe6TVLTrYiIiEhxUsCXIuPl7sZnfwunkpet6fZYcgpPzooiJS3dwZWJiIiIlB0K\n+FKkavl7Men+UHvTbfS+U7wxXyvdioiIiBQXBXwpch0bBPKPWy823X61fh//+11NtyIiIiLFQQFf\nrovHO9WlX7am29fnbyUqLt6BFYmIiIiUDQr4cl3Ymm5b0rR6RQBS0y2enBXNUTXdioiIiFxXCvhy\n3Xi6uzJlcBh+mU23x9V0KyI2aMRfAAAgAElEQVQiInLdKeDLdVXL34tJD1xsut247xRvzNdKtyIi\nIiLXiwK+XHc31Q/kn7c1sb//av1+vvw9zoEViYiIiDgvBXwpFo92rMOA1hebbt+Yv43IWDXdioiI\niBQ1BXwpFsYY3r0zd9PtkUQ13YqIiIgUJQV8KTaXNt2eOK2mWxEREZGipoAvxaqWvxeTHwjFNbPr\ndtP+U7wWsQ3LshxcmYiIiIhzUMCXYtfhkqbbryP3M0sr3YqIiIgUCQV8cYi/3xTCHW1q2t+/OX8b\nG9R0KyIiIlJoCvjiELam2xY0r2lruk3LsHhqVjSHE885uDIRERGR0k0BXxymfDlXpgwOx7+CO5DV\ndBvN+VQ13YqIiIhcKwV8caialTxzNN1u3n+K0RFb1XQrIiIico0U8MXhbqwXwKvZmm7nRh1g5jqt\ndCsiIiJyLRTwpUR45KYQ7gy92HT71g9/8vvekw6sSERERKR0UsCXEsEYw7/vaEGLmr6Aren2mf9F\nc+iUmm5FREREroYCvpQYtqbbMALsTbcXeGpWlJpuRURERK6CAr6UKDUqeTJ5UChuWU23BxIZpaZb\nERERkQJTwJcS54a6AYy6/WLT7TdRB/hirZpuRURERApCAV9KpIc6hHBXaJD9/dsL/mSdmm5FRERE\nrkgBX0okYwz/uqM5LYOyNd1+Gc1BNd2KiIiIXJYCvpRY5cu58smDYQR625puT565wJMz1XQrIiIi\ncjkK+FKi1chc6Tar6XbLwUT++f0WNd2KiIiI5EMBX0q89nUDeK1vU/v776IPMv23WMcVJCIiIlKC\nKeBLqTD4hmDuCbvYdPvOj9tZu0dNtyIiIiKXUsCXUsEYw9sDmtOqViUA0jNXulXTrYiIiEhOCvhS\natiabkPtTbfxZy7wxMxINd2KiIiIZKOAL6VKdV9PPhoUZm+63XowiVe+U9OtiIiISJYiC/jGmCBj\nzH+NMYeMMSnGmFhjzARjjN9VXONFY8xPmeeeNsYkGWO2GGPGG2OC8jnHuszXuqL6/qTkaFfHn9ez\nNd1+v/Eg/10T67iCREREREoQt6K4iDGmHvAbUAWYB+wA2gHPA7cYY26yLKsgHZFPAKeBFcBRoBzQ\nBhgGPGqM6WpZ1sY8zosDpuex/cBVfitSSjx4QzBbDiYyJ9L2W/zvn7bTpLoPHeoFOrgyEREREccq\nkoAPfIQt3D9nWdaHWRuNMeOxhfN/AU8W4DrNLcs6f+lGY8zjwKeZ17ktj/NiLct64xrqllLKGMNb\n/Zuz8+hpNu0/RXqGxdD/bWT+0JsI8vNydHkiIiIiDlPoITqZT+97AbHA5Et2vw6cAQYbYypc6Vp5\nhftMczJfG1xjmeKEsla6rezjAWQ13UZx7oKabkVERKTsKoox+N0yXxdZlpWRfYdlWcnAGsALuKEQ\n9+ib+fpHPvsrGWP+boz5pzHmGWNMYe4lpUg13/J8PCiUcq62pttth5J45bs/1HQrIiIiZVZRDNFp\nlPm6M5/9u7A94W8ILCnIBY0xjwFBgDfQArgZ2zj7f+RzSivg80uusRkYbFnWlgLeMyqfXY0Lcr44\nTniIP6/3bcaoiK0ARGw6RPOavjzWqa6DKxMREREpfkXxBN838zUxn/1Z2ytdxTUfwza8ZwS2Hw6i\ngJsty9qVx7HjgZuAyoAP0Bb4BlvoX2qMqXkV95VSalD72gxsW8v+/t2FO/ht9wkHViQiIiLiGCVy\nHnzLsm6wLMsAgdgCPkCUMaZ3HseOsCzrN8uyTliWddqyrEjLsu4Bvs08f2QB7xmW1xe2GYGkhDPG\n8Gb/ZrSpnXOl2/3xZx1cmYiIiEjxKoqAn/WE3jef/VnbT13thS3LOmlZ1mJsIf8cMNMY41nA0z/J\nfO18tfeV0snDLWfTbcLZVDXdioiISJlTFAE/JvO1YT77s2a+yW+M/hVZlnUKWIttGE6zAp52PPP1\nirP3iPOoWrE8nzx4sen2z8NJvPytmm5FRESk7CiKgL8s87WXMSbH9YwxPtjGx58FCruqbNZY+rQC\nHp81k87eQt5XSpmwYH/e7Nfc/n7+5kNMXfWXAysSERERKT6FDviWZe0BFgEhwDOX7H4T2xP0mZZl\nncnaaIxpbIzJMTuNMaa2MaZqXvcwxjyBrXl2P7Al2/aWxphyeRzfEtuiWACzrvZ7ktLvgfa1ub9d\nbfv7dxduZ/UuNd2KiIiI8yuqlWyfBn4DPjDG9AC2A+2xzZG/E3j1kuO3Z76abNtCgbnGmLXAbuAo\nEIDtSXwL4DS2aS+zD6geDvQ1xqzCFv5TsE1reQvgCnwGfFVE36OUMm/0a0rMkSSi950iw4KhX0Xz\nw9CO1PLXSrciIiLivIpkFp3Mp/jhwHRswX4EUA+YCNxgWdbJAlwmOvN4D+B2bLPf3A9YwDigqWVZ\nKy45JwJYATQHHgKeA8KAhUB/y7KGWBp8XWZlNd1WyWy6PXU2lSFquhUREREnV1RP8LEsaz/wSAGP\nNXls20cBp7TMdk4EtpAvkqcqFcvz8YNhDPx0LanpFtsPJ/HSt3/wwcDWGJPrj6GIiIhIqVci58EX\nKUphwX681f9i0+0Pmw/x2Sr1XouIiIhzUsCXMuH+drV5oP3Fptv3Fu5g1a7jlzlDREREpHRSwJcy\n442+zQgP9gOwNd3+byP7TmqlWxEREXEuCvhSZri7ufDRg6FUrWhruk08l8qQmZGcvVDQpRVERERE\nSj4FfClTqviU55MHw3B3tf3R33EkmRe/0Uq3IiIi4jwU8KXMaVPbj7cHNLO///GPw0xZqaZbERER\ncQ4K+FIm3de2Ng/ecLHpdszPO1i5U023IiIiUvop4EuZ9VqfZrQNudh0++xXG4k7ecbBVYmIiIgU\njgK+lFnubi5MHhRKtYrlAVvT7RMzoziToqZbERERKb0U8KVMq+JTno8fDL2k6Xazmm5FRESk1FLA\nlzKvTW0/3rnj4kq3P205wscr9jiwIhEREZFrp4AvAtwbXou/3Rhsf//+LzEsjznmwIpEREREro0C\nvkim0X2a0i7EHwDLgue+2kjsCTXdioiISOmigC+SqZyrrem2uq+t6TbpfBpDZkaq6VZERERKFQV8\nkWwq+3jYVrp1s/3V2Hn0tJpuRUREpFRRwBe5RKtalfjXgJxNtx8tV9OtiIiIlA4K+CJ5uCe8Fg9l\na7oduyiGZWq6FRERkVJAAV8kH6P6NKVdnZxNt3+p6VZERERKOAV8kXyUc3Xho2xNt8nn0xjyRSSn\n1XQrIiIiJZgCvshlBHp7MGXwxabbXcdOM3KOmm5FRESk5FLAF7mClkGVePeOFvb3P287wuRlux1Y\nkYiIiEj+FPBFCuCusCAe7hBifz9u8U6W7jjquIJERERE8qGAL1JAr97ehPbZmm6fn71JTbciIiJS\n4ijgixRQ1kq3NbI13T6uplsREREpYRTwRa6Crek2HI/Mptvdx04z/OtNZGSo6VZERERKBgV8kavU\nIsiXd++82HS76M+jTFLTrYiIiJQQCvgi1+DO0CD+flMd+/v//LqTJdvVdCsiIiKOp4Avco3+eVtj\nbqwbANiabl+YvYk9x087uCoREREp6xTwRa6Rm6sLkx5oQ81KngAkp9hWuk0+n+rgykRERKQsU8AX\nKYSAzJVus5pu9xw/w/A5m9V0KyIiIg6jgC9SSM1r+vJ/d7W0v1/851E+XKqmWxEREXEMBXyRIjCg\nTU0e7Ziz6Xbxn2q6FRERkeKngC9SRF65tTEd6gXY3w/7ehO7j6npVkRERIqXAr5IEbE13Ybam25P\np6QxZGYkSWq6FRERkWKkgC9ShPwruPPp38IoX872V2vv8TNa6VZERESKlQK+SBFrViNn0+2v248x\ncckuB1YkIiIiZYkCvsh10L91TR7vdLHpduKSXSzadsSBFYmIiEhZoYAvcp28fEtjbqp/sel2+JzN\naroVERGR604BX+Q6cXN1YdL9oQT5ZWu6/UJNtyIiInJ9KeCLXEd+Fdz5dHD4xabbE2cYNltNtyIi\nInL9KOCLXGdNa1RkzN2t7O+X7DjGhF93OrAiERERcWYK+CLFoF+rGjzRua79/QdLd/PzVjXdioiI\nSNFTwBcpJi/d0phODQLt70fM2cSuo8kOrEhERESckQK+SDFxdTF8eH8bavnbmm7PXEhnyMwoEs+p\n6VZERESKjgK+SDGq5GVruvUs5wrAXyfOMEwr3YqIiEgRUsAXKWZNqlfk/XsurnS7dMcx/qOmWxER\nESkiCvgiDtCnZQ2e6HKx6fbDpbv5eethB1YkIiIizsLN0QWIlFUv9W7Mn4eSWLXrBAAj5mymbmVv\nGlb1cXBlItfGsiz2x58jMi6ePw4k4l/BnYHtalHFp7yjSxMRKVMU8EUcJKvptt+kNeyLP2truv0i\nknnPdMTXq5yjyxO5orT0DHYcSWZDbDyRsQlsiI3nWHJKjmM+Xr6Hh28K4YnOdank5e6gSkVEyhYF\nfBEHquTlzqd/C+POj37j7IV0Yk+e5fmvN/L5Q21xdTGOLk8khzMpaWzaf4oNsfFExSUQHZfAmQvp\nlz3nXGo6Hy/fw6x1cQzpVJdHOtbB20P/9YiIXE/6V1bEwRpXq8j7d7fimf9FA7A85jjjF8fwYu/G\nDq5MyrpjyeeJik1gQ2wCkXHxbDuURPoVZnzy8XAjNNiPVkG+LN5+jO2HkwBIPp/GuMU7mf5bLE93\nq8+g9rUpnzmblIiIFC0FfJES4PaW1dl6qB4fL98DwORle2hew5dbW1R3cGVSVliWxZ7jZ4iMjbcH\n+riTZ694XnXf8oSH+NM2xI/wYH8aVfOxf/r0ws0N+XHLYf6zeCd7T5wB4OSZC7y94E+mrtrLcz0a\ncHdYEOVcNd+DiEhRMpal+bcvxxgTFRoaGhoVFeXoUsTJpWdY/H36BlbsPA6Al7sr3z99E42qqelW\nit6FtAy2HEy0B/qouHgSzl5+0TVjoFFVH8JD/Ggb4k94iD81K3le8V5p6Rl8F32QiUt2cfDUuRz7\nggO8GN6zIX1b1sBFw9JEpIwLCwsjOjo62rKssMJcRwH/ChTwpTglnk2l3+TV9ienwQFezFfTrRSB\nxHOpRMfZnsxviE1g8/5TpKRlXPYcdzcXWteqZHs6H+JPaG0/fD2v/c9iSlo6X/2+j0nL9nDidM5m\n3EZVfRjRqyE9m1bFGAV9ESmbFPCLiQK+FLeYI8nc8dEazmY2L3ZpWJn/PqymW7k6B0+dy3w6b5vh\nJuZoMlf6597Pqxxhwf72QN+8ZkU83Ip+nPzZC2lM/y2WT5bvIel8Wo59rWpVYmSvhnSsH6igLyJl\njgJ+MVHAF0f4acthnv4y2v7+6a71eOkWNd1K3tIzLGKOJNufzkfFxnMo8fwVzwsO8CI8W6CvV7lC\nsYbqxHOpTF21l89X/2X/gTbLDXX9ebF3I8KC/YutHhERR1PALyYK+OIo7/+yg8nL9tjfT34glNtb\nqulW4NyFdDbtP0VkbDyRmdNVJqekXfYcVxdDsxoV7YE+LMSvxCxAdeJ0Ch8v38PMdXFcuGTYUPfG\nVRjRqyHNavg6qDoRkeJTVAFfs+iIlFDDezZi26EklsfYmm5Hzt1MvSoVaFytooMrk+J28nQKkXEJ\n9obYrQcTSbvCdJUV3F0JDfYjLNjWENu6ViUqlND55wO9PRjdpymPdarDB0t2Mydyv306zqU7jrF0\nxzFub1md4T0bUq+yt4OrFREp+fQE/wr0BF8cKfFcKv0nrSY2s+m2tr8X84fepBVBnZhlWcSePJs5\ndt42fj5risnLqeLjkTmzjS3QN67mg1spnX4y9sQZJvy6k3mbD+XoG3AxcFdoEM/f3IAgPy/HFSgi\ncp1oiE4xUcAXR9t5NJk7Jq+xrxjaqUEg0x9pp6ZbJ5GansG2Q0n2MB8ZF8+J0xeueF6DKt72+efb\nhvgT5OfpdE2pMUeSGbcohkV/Hs2xvZyr4YF2tXmme/0SM8xIRKQoKOAXEwV8KQl+3nqYJ2ddbLp9\nsks9/nGrmm5Lo+TzqWzcd8o+3Gbj/gTOp15hukpXF1oG+RIW4kfbYH/Cgv3wq1B2PsXZtP8U4xbF\nsGrXiRzby5dz4ZGb6vBE57r6VEtEnIICfjFRwJeSYuwvMUxattv+ftIDbejTsoYDK5KCOJJ43j7c\nZkNsAjuOJHGF4fP4epYjLNjPPtymRU1fypcr+ukqS5u1e04ydlEMUXEJObb7eLgxpHNdHulYB+8S\n2mcgIlIQCvjFRAFfSor0DIvHZmxgWWbTrWc5V757ugNNqqvptqTIyLDYdez0xfHzcQkcSDh3xfOC\n/DxzjJ+vX9lbq7rmw7IslsUcY+wvO/nzcFKOff4V3Hm6az0evCFYPxCJSKmkgF9MFPClJEk8l8qA\nyWv4K7Ppspa/Jz8M7ajhCQ5yPjWdPw4kEhmXOX4+Nj7Xwk2XcjHQpHpF2ob425/SV/f1LKaKnUdG\nhsVPWw8zfvFO9h7P2YRcrWJ5nuvRgHvCgyhXShuNRaRsUsAvJgr4UtLsOprMgEuabqc93LbUzphS\nmiScuUBUXAIbMgP9lgOJXEi//Ph5z3KutK5Vyb6YVJvalfApX66YKnZ+aekZfLfxIBN/3cXBUzk/\nLQkO8GLYzQ3p26qGmtJFpFRQwC8mCvhSEv2y7QhPzLz4Z/KJznV55bYmDqzI+ViWxf74c7bhNpkr\nxO4+dvqK5wV6uxMefHG4TdMaFfUUuRikpKUze/1+Ply6mxOnU3Lsa1TVh+G9GtKraVWnm2lIRJyL\nAn4xUcCXkmr8ohg+WHqx6faD+9vQr5Wabq9VWnoG2w8n24fbbIiN51hyyhXPq1u5Am0zA314iD8h\nAV4KkQ509kIaM36L45MVe0g8l5pjX6sgX0b2bkTH+oH6PRKREkkr2YqUcS/c3JBth5JYsuMYAC99\ns5n6lb1pWkNNtwVxJiWNTftPZTbEJhC9L4GzmcOe8uPmYmgR5Et4sC3Mhwf7EeDtUUwVS0F4ubvx\nVNd6PNC+Np+v2svnq/+yD2fbfCCRwZ+vp30df17s3YjwEH8HVysicn3oCf4V6Am+lGRJ51MZMGmN\nfaXTID9b021ZmiO9oI4lnScyLsEe6P88nET6Fear9PFwIzTYzz5+vlVQJTzdNTtLaXLydAofL9/D\nF+viuJCWs1+iW6PKjOjViOY1fR1UnYhIThqiU0wU8KWk230smQGTf+N0im32lo71A5n+SNluurUs\niz3HT7MhNsG+OmzcybNXPK+6b3naZq4OGxbsT6NqPmrOdBKHE8/x4dLdzNmwn7RLfrC7vWV1hvds\nSL3K3g6qTkTERgG/mCjgS2mwaNsRhmRruh3SuS7/LENNtylp6Ww9mGRfTCoqLp6Es6mXPccYW/Nl\nVjNseIg/NStpukpnF3fyDBN+3UXEpoNk/+/PxcBdoUE8f3MDgvy8HFegiJRpCvjFRAFfSovxi3fy\nwZJd9vcTB7amf+uaDqzo+kk8m0r0vovDbTYdOJVr+MWlPNxcaJVtusrQ2n74emq6yrIq5kgy4xfH\n8Mu2ozm2l3M1PNCuNs90r08Vn/IOqk5Eyio12YpIDi/0aMCfhxL5dbut6fblb/+gfhVvmtUo3eOL\nLcvi4Klz9pltImMT2HksmSs9m/DzKkd45nCb8BB/mtfwxd2t7A5bkpwaVfNhyuBwNu8/xdhFMaza\ndQKA1HSLGWvj+DpyPw93qMOTXepqITkRKXX0BP8K9ARfSpPk86n0n7zGvrJnzUqe/PBsR/xLUdNt\neobFjiNJtgWlMleHPZx4/ornhQR42We2CQ/xp17lCpoKUQps3d6TjP0lhsi4hBzbfTzceLxzXf7e\nsQ7eHnomJiLXl4boFBMFfCltdh87zYDJa+xNtx3qBfDF39uV2KbbcxfS2bT/lG38fFwCG+MSSM6s\nPT+uLoZmNSoSHpzZEBvip+EUUmiWZbE85jjv/xLDn4eTcuzzr+DO013r8eANwZQvp5mUROT6UMAv\nJgr4Uhot/vMoj38RaX//WMc6jOrT1IEVXXTidIptZpvMQL/tYGKuWU0uVcHdldBgP3ugb1WrEhX0\nNFWuk4wMi4VbjzBucYz907As1SqW59ke9bk3vJZWKBaRIqeAX0wU8KW0mvDrTib86timW8uy+OvE\nGftUlZGxCfY5+y+nio8Hbev40zZzuE3jaj4l9hMIcV5p6Rl8v/EgE37dxcFT53Lsq+3vxbCeDejX\nqqamUhWRIqOAX0wU8KW0ysiweGJWFIv/tM0S4uHmwrdPdbiui/qkpmew7VDWdJW2QH/yzIUrnteg\nire9IbZtiD9Bfp4aPy8lRkpaOl9v2M+HS3dzPDklx76GVb0Z3rMRvZtV1Z9ZESm0EhfwjTFBwFvA\nLUAAcBiIAN60LCvhcudmu8aLQDegKRAIZABxwGJgvGVZB/I5rynwBtAVqJh5zmzgPcuyzuV1TkEp\n4Etplnw+lQGT17DnOjXdJp9PJXrfKXug37T/FOdTLz9dpburCy2DfO2BPizYT7OUSKlw7kI6M9bG\n8vHyPSSey7nOQssgX0b2akSnBoEK+iJyzUpUwDfG1AN+A6oA84AdQDtsYT0GuMmyrJMFuM5u4DSw\nGTgKlAPaAF2AJKCrZVkbLzmnPbA089hvgP1AdyAcWAP0sCwr5yOXq/veFPClVNtz/DQDJq2xN67e\nWDeAmY9eW9Pt4cRz9pltImMT2HEkiSsMn8fXsxzhwbZG2LYh/rSo6asmRSnVks6nMnXlXj5f/Rdn\nLqTn2Ne+jj8v9m5EeIi/g6oTkdKspAX8X4BewHOWZX2Ybft4YBgwxbKsJwtwnfKWZeWaD88Y8zjw\nKbDQsqzbsm13BbYATYD+lmXNz9zuAswB7gJesSzrvUJ8bwr4Uuot2X6Ux76ItM8d//eb6vBa38s3\n3WZkWOw8lnyxITY2Idc45LzU8vckPNjfvkJs/creuGiMsjihk6dT+Hj5Hr5YF5drobVujSozolej\n6zokTkScT4kJ+JlP73cDsUA9y7Iysu3zwTZUxwBVLMu6cndd3vfwBU4Buy3LapBte3dgCbDSsqwu\nl5xTF9iDbbhOHesav1EFfHEWHyzZxfjFO+3vx9/bijtDg+zvz6em88eBxMyx8/FExSWQdP7y01W6\nGGhSvSJtQ2yBPjzYn2q+mq5SypYjief5cOkuvt6wP9eMULe3qM6wng2pX8XbQdWJSGlSklay7Zb5\nuih7uAewLCvZGLMG29P9G7CF8WvRN/P1j0u2d898/fnSEyzL2muM2Qk0BLLCvkiZNbRbfbYeTGRR\nZtPtK99tISUtg9gTZ4iMS2DLgUQupF9+/LxnOVfa1K5kHz/fulYlfMqXK47yRUqsar7l+dcdLRjS\nuS4Tf93F95sO2j8t+3HLYRZuPcydoUE836MBtfy9HFusiJQJRRHwG2W+7sxn/y5sAb8hBQz4xpjH\ngCDAG2gB3IztSfw/ruHeDTO/LhvwjTH5PaJvXICSRUo8FxfD+PtaM2DyGnYfO01KWgavfLflsucE\nervnGG7TtEZFzf0tko/ggAqMv681T3atx7hFMfyyzfbDdIYF30QdYN6mg9zfrjZDu9WnSkV90iUi\n109RBPysAYaJ+ezP2l7pKq75GNA+2/sNwAOWZe0uhnuLOC1vDzc+HRxG/8lrSM5j+E3dyhVomy3Q\nBwd4aUYQkavUsKoPUwaHs3n/KcYuimHVrhMApKZbfLE2jjmR+3moQwhPdq6HXxHNaCUikl2JXArS\nsqwbAIwxAUAo8C8gyhhzr2VZv1yne+Y51inzyX7o9biniCPUrezNZ38L54352/B0d6VtiD9hwX6E\nB/sR4O3h6PJEnEarWpWY+Wh71u09ydhfYoiMs80YfT41gykr9vK/dft4rFNdHu1UB2+tzCwiRago\n/kXJekqe31QBWdtPXe2FM6fWXGyM2YBt6s2ZxpjgbHPbX7d7izizG+oG8PMLnR1dhkiZcEPdAOY+\neSPLdx5n7C8xbDuUBEByShr/+XUnM9bG8lSXegy+MVhTyIpIkSiKwbQxma8N89mfNetNfuPkr8iy\nrFPAWqAy0Kw47y0iIlJYxhi6NarCD0M78tGgUOpVrmDfF3/mAv/6aTtd3l/GrDym3BQRuVpFEfCX\nZb72ypx/3i5zmsybgLPAukLep2bma/aBw0szX2+59ODMaTIbYmvO3VvIe4uIiBSai4vhthbV+eWF\nzoy9pxU1K3na9x1NSmFUxFZuHr+C76IPkH6lVeRERPJR6IBvWdYeYBEQAjxzye43gQrAzOxz4Btj\nGhtjcsxOY4ypbYypmtc9jDFPAG2xrVKbfdqPFcB2oLMxpl+2412A/8t8+8m1zoEvIiJyPbi5unB3\nWBBLR3bhrf7NqOxzsf9lX/xZhs/ZzC0TVvLz1sPovzARuVpFtZJtPeA3oAowD1vobo9tjvydQIfM\n8fRZx1sAlmWZbNsGAHOxDcXZDRwFArDNn98COA30sSxrxSX3bo/tSX454BtgH9ADCAfWAD0sy0op\nxPemha5EROS6OnchnRlrY/lkxR5OnU3Nsa9lkC8jejWic4NAzWol4uRKzEq29gsZUwt4C9twmQBs\nK9h+D7xpWVbCJcfmFfBrA88BnbB9GuAPnMc2vGYxMNGyrP353Lsptk8LugE+2IblfAW8l60h91q/\nLwV8EREpFknnU5m66i8+X7WXMxfSc+xrV8efF3s3om2Iv4OqE5HrrcQFfGelgC8iIsUt/swFPlmx\nhxm/xZJySdNt10aVGdmrEc1r5jeBnIiUVkUV8LUkpYiISAnjX8Gdf97WhBUvdmNQ+9q4uVwcmrM8\n5jh9PlzN019GsftYsgOrFJGSSgFfRESkhKrmW55/3dGCpSO6cmebmmQfgv/TliP0+s9KRszZzP74\ns44rUkRKHAV8ERGREq52gBfj72vNLy905pZm1ezbMyz4NvoA3cctZ3TEVo4lnXdglSJSUijgi4iI\nlBINq/rwyeAw5g+9iUxAo+YAACAASURBVM4NK9u3p6ZbzFwXR+f3l/HuT9tJOHPBgVWKiKMp4IuI\niJQyLYMq8cXf2/H1kBtoG+Jn334+NYMpK/fSacwyJvy6k+TzqZe5iog4KwV8ERGRUqp93QDmPHEj\n0x9pS7MaFe3bT6ekMeHXXXQes4zPVu7lfGr6Za4iIs5GAV9ERKQUM8bQtVEVfhjakY8GhVKvcgX7\nvoSzqfzrp+10eX8ZM9fFceGSKTdFxDkp4IuIiDgBFxfDbS2qs2hYF8be04ogP0/7vqNJKYyO2EqP\n8cv5NuoA6RlaA0fEmSngi4iIOBFXF8PdYUEsHdGVt/s3o4qPh33f/vhzjJi7mVsmrGThlsNosUsR\n56SALyIi4oTc3VwYfGMIK17sxiu3NqaSVzn7vl3HTvPUl9H0m7SGFTuPK+iLOBkFfBERESfm6e7K\nE13qseqlbjzfowHeHm72fVsOJvLQf9dz35R1rP8r3oFVikhRUsAXEREpA3zKl2NYz4asfKkbQzrX\nxcPtYgRYHxvPvVPW8tB/17PlQKIDqxSRoqCALyIiUob4V3Dnn7c1YeVL3Xjwhtq4uRj7vhU7j9N3\n0mqemhXFrqPJDqxSRApDAV9ERKQMqlqxPO8MaMHSEV25M7Qm2XI+C7ceofeElQyfs4n98WcdV6SI\nXBMFfBERkTKsdoAX4+9tzS8vdObW5tXs2zMs+C76IN3HLWdUxBaO/n979x5nSVnfefzz6+7pud8Z\nQBlgGGQAgxpBuYgZGDAEzWoIRLOvVWM0ZtV4VzYXs0Yx62KMGlyMgTUSjJiomI0keXkhcr/IqhBc\nSICBGWa4MzD3a1+f/eOpnj5z+py+nunTXefzfr3qVd1VdZ5T9fA0862qp+rZsa+JeylpLAz4kiSJ\n4w6bz1+95RT++X2v5qxVy/Yv7+lLXHPXY6z+7E1c+r0H2Lq7u4l7KWk0DPiSJGm/lyxfyNfecSrf\nftcZvHLF4v3Lu3r7ufLW9fzSZ2/ish+tZee+nibupaThGPAlSdIQpx6zhG+/6wyufvsrOemIBfuX\n7+rq5bIfPczqz97ElbesY293XxP3UlItBnxJklRTRHD28Yfyz+97NX/15pN50aHz9q/buqeHS7//\nIGf9+U18/a6NdPf2N3FPJVUy4EuSpGFFBK99yQv44YdW8/k3vowjl8zev27Tzi4+/t37OfcLN/MP\ndz9BX7+j4krNZsCXJEmj0t4WXHTKcm74yNn86QUncej8mfvXPb5lLx+99uf8ymW38v37niYlg77U\nLAZ8SZI0Jp0dbbz19KO55b+t4WOvO4FFc2bsX/fIpl285xv38Pov3c7ND20y6EtNYMCXJEnjMruz\nnf+6+lhu+/01fOg1xzFvZsf+dfc/uYPf/puf8qYrf8xPHt3SxL2UWo8BX5IkTcj8WTP40GtWcdvv\nr+Fdq1cys2MwXvx0w1bedOWPedtVP+G+J7Y3cS+l1mHAlyRJDbF4bid/9LoTufX31/DW04+moy32\nr7tl7XO8/ku3855r7ubhZ3c2cS+l8jPgS5KkhjpswSz+9IKTuOnis7no5OVU5Hy+f/8z/Mplt/KR\nb9/LY5v3NG8npRIz4EuSpIPiyCVz+PybXsb1H17N615y+P7l/Qn+zz1Pcs7nb+a/f/c+nt2xr4l7\nKZWPAV+SJB1ULzp0Pl9+8yn8y/tfzdnHL9u/vLc/cc1dj7H6szfxP7/3AFt2dzdxL6XyMOBLkqRJ\ncdIRC7n67ady7bvP4NQVS/Yv7+rt53/fup7Vn72Jv/jXtezc19PEvZSmv46RN5EkSWqcV65Ywrfe\ndTq3Pvw8n/vhQ9z3ZH67zq6uXr54w8N87ccbeM9Zx/JbZ6xgdmd7c3dWU0pvXz/dff109QzOu3r7\n6Ortp6u3n+7e/Hv3Ab/30z2Kbbp6B8vq7u1n5bK5fOFNv9jsQx4XA74kSZp0EcFZq5ax+rhD+OG/\nP8Pnrl/LI5t2AbBtTw+Xfv9Bvnr7o7z/nBfxm688is4OOx00U19/2h+MK0Ny15AgXSzfH8D7Dgzk\nVdt0HRDWq7ftOyDId/f109c/eQOn9fT1T9p3NZoBX5IkNU1EcP5JL+CXX3w41937JH/xo7U8vmUv\nAJt2dvHx6/6dK29dz4des4pff/kRtFe+kqcFDATr2oG674Crz7WvTPdVXaEeeZta5fROYrCeKrp6\nDfiSJEnj1t4WXHjycv7TS1/It3/2OJff+DDP7ugC4Imte7n42p9zxS3r+Mgvr+L8XzictoMc9Pv7\n0/4rzgcE4GGuNtfapquqO8n+5ZVBus423X399PS1XrAeTgTM7GhjZkc7nR1txc9tdHa0F/PBZZXb\ndNZdNnSbgeXzZ03fmDx991ySJJVOZ0cbbzn9aH7jlOV8/ccb+fLNj7B1T37o9pFNu/i9b9zDSUcs\n4HdefQyzOtqHBvBhr0xXBuvhr14brA80EKw729uYOaO9mA/+PvOAsF0E5wO2aaOzvZ2ZM4YP1wMh\nvN42HW1BRGvdxRkPA74kSZpyZs1o53dXr+Q/n3okV92+ga/ctp5dXb0A3P/kDj78rZ83eQ8nRwQ5\nIFdcpa53RXp/mB7FVerKkD6zKoDvX17xOYP19GLAlyRJU9b8WTP44GuO47fOOJorbl3H1+7cwL6e\nyekb3Vl1RblWN47xdAEZWl79biIz2g3WGjsDviRJmvIWz+3kj157Ir9z5jF89Y5HefjZXWPqAlId\nqEcK153tbQZrTVsGfEmSNG0cumAWf/TaE5u9G9KU5ktlJUmSpBIx4EuSJEklYsCXJEmSSsSAL0mS\nJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuSJEklYsCXJEmSSsSAL0mS\nJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuSJEklYsCXJEmSSsSAL0mS\nJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuSJEklYsCXJEmSSsSAL0mS\nJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuSJEklYsCXJEmSSsSAL0mS\nJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiTQs4EfE8oi4KiKeioiuiNgQEZdFxOJRfn5u\nRLw5Iv4uIh6MiN0RsTMifhYRH42IzjqfS8NMdzXq+CRJkqTpoKMRhUTEscCdwKHAdcCDwKnAB4Hz\nI+LMlNLmEYr5JeAaYAtwE/BdYDHwBuBzwIURcW5KaV+Nz24Erq6x/ImxH40kSZI0fTUk4ANfJof7\nD6SULh9YGBFfAD4MfBp49whlPAO8Bbg2pdRdUcbFwM3Aq4D3Ap+v8dkNKaVPTmD/JUmSpFKYcBed\n4ur9ecAG4C+rVn8C2A28NSLmDldOSunelNI3KsN9sXwng6H+7InuryRJklRmjbiCv6aYX59S6q9c\nkVLaGRF3kE8ATgduGOd39BTz3jrrF0XEO4DDge3A3Skl+99LkiSp5TQi4B9fzNfWWf8wOeCvYvwB\n/x3F/Ad11r8M+Grlgoj4OfDWlNJ94/xOSZIkadppRMBfWMy311k/sHzReAqPiPcB5wP3AlfV2OQL\nwD+QTzD2AScAfwD8BnBjRPxiSunJUXzP3XVWnTCe/ZYkSZKaYUq/Bz8iLgQuIz+Ae1FKqad6m5TS\nR1NKd6aUnk8p7Uop/Syl9EZy6D8EuHhy91qSJElqnkZcwR+4Qr+wzvqB5dvGUmhEXAB8E9gErEkp\nrR/jfl0BXASsHs3GKaVT6uzH3cDJY/xuSZIkqSkacQX/oWK+qs7644p5vT76Q0TEG4FrgWeBs1JK\nD43wkVqeK+bDvr1HkiRJKpNGBPybivl5EXFAeRExHzgT2AOM6q02EfFm4O+Bp8jh/uFx7tfpxXys\nV/4lSZKkaWvCAT+ltA64HlhBHoiq0iXkK+hfTyntHlgYESdExJCHVyPibcDfAo8Bq0fqlhMRL42I\nGbWWkwfXgjw6riRJktQSGjWS7e8BdwL/KyLOBR4ATiO/I38t8MdV2z9QzGNgQUSsIb8lp418V+Dt\nEVH1MballC6r+P0jwOsj4jbgcaCL/Nab84F24CvkuwGSJElSS2hIwE8prYuIVwCfIofr1wFPA18E\nLkkpbR1FMUczeEfhHXW22Uh+q86A7wILgJcC5wCzgM3A94GvpJT+aYyHIkmSJE1rjbqCT0rpceDt\no9x2yKX5lNLVwNVj/M7vkkO+JEmSJKb4e/AlSZIkjY0BX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIgZ8SZIkqUQM+JIk\nSVKJGPAlSZKkEjHgS5IkSSViwJckSZJKxIAvSZIklYgBX5IkSSoRA74kSZJUIh3N3gHVsfZ6aGuD\nJcfCwiOh3f9UkiRJGpmpcar60Sdg03/kn9s6YNHRsGTl0GnRUdDR2dx9lSRJ0pRhwJ+K+vthy6MV\nv/fClnV5qhZt+Qp/rfC/eAXMmDVpuy1JkqTma1jAj4jlwKeA84GlwNPAd4FLUkpbR/H5ucAFwK8C\nJwNHAv3AQ8DfA5enlLrrfPbFwCeBs4EFwEbgm8BnUkp7J3JcTdG7D066CLasz9OuZ+pvm/ph28Y8\nrb+pamXAgiNgyTGDoX/psYPhv3PuwTwKSZIkNUFDAn5EHAvcCRwKXAc8CJwKfBA4PyLOTCltHqGY\nXwKuAbYAN5FPDhYDbwA+B1wYEeemlPZVffdpwI3ADOA7wOPAOcCfAOcWn+lqxHFOms45cMFfDv7e\nvTtf0R8I/PunR2HHE8MUlPL6HU/AhtuGrp7/giL4H1N15f8YmLWg4YclSZKkg69RV/C/TA73H0gp\nXT6wMCK+AHwY+DTw7hHKeAZ4C3Bt5ZX6iLgYuBl4FfBe4PMV69qBvwHmAL+WUvqnYnkb8G3gouL7\nPzOxw2uyzrlw+El5qtazF7ZurBH+18P2x/MV/np2Pp2njXcMXTd3WY1uP8WJwOzFjTs2SZIkNVSk\nlCZWQL56/wiwATg2pcFEGRHzyV11Ajg0pbR7nN/xX4BvAP+SUnp9xfJzgBuAW1NKZ1V9ZiWwjtxd\n55g0zgONiLtPPvnkk+++++7xfLy5erth22MVoX/d4M9bN0LqG1+5sxfX7vO/5FiYswQiGnsckiRJ\nLeCUU07hnnvuuSeldMpEymnEFfw1xfz6ynAPkFLaGRF3AOcBp5PD+Hj0FPPequXnFPMfVH8gpbQ+\nItYCq4CBsN9aOjrhkBflqVpfT77CP9DVp/LK/9YN0FfzcYds71Z48u48VZu5cGiXn4Fp3qGGf0mS\npIOsEQH/+GK+ts76h8kBfxXjD/jvKObVQX40372qmFov4A+nfcZg8K7W3wc7nhza33/g5959Qz8z\noGs7PH1vnqrNmFu7z/+Slfl5gDbHXZMkSZqoRgT8hcV8e531A8sXjafwiHgf+c089wJXHazvjoh6\nfXBOGOmzpdPWnt+vv+goWHn2gev6+/Nbfar7+28u5j3D9MLq2Q3P3penah2z8sO9tU4AFi7P+yRJ\nkqQRTen34EfEhcBl5AdwL0op9YzwER1sbW2w4IV5WvHqA9elBLs21X7gd8t66NpRv9zeffDcA3mq\n1t6ZX+tZ64HfhUc5yq8kSVKFRiSjgavkC+usH1i+bSyFRsQF5HfZbwLWpJTWH8zvrvcwQ3Fl/+SR\nPi9y//r5h+Xp6DMOXJcS7NlSP/zv3VK/3L5ueH5tnqq1deQ7DTVH+T3aUX4lSVLLaUTAf6iYr6qz\n/rhiXq+f/BAR8Ubg78hX7s9JKT08Wd+tgyQC5i7N05GvHLp+79aKfv4D8+KtP7ufq19uf+/gScKQ\n72zL3Xtqve3HUX4lSVJJNSLgDwyfel5EtNV4TeaZwB7grtEUFhFvBr4GPEn9K/cDbgT+mNxH/9Kq\nclaSg/9GYLgyNBXMXgxHLIYjatws2bcDtlYP9FX8vvPp+mWm/vya0G2Pwfqbq1bWGOW3svuPo/xK\ntfX3Q/dO6NqZ/za7dgzOD/h5J7TNgHnLYN5hMPfQ/CateYfCnEPsWidJB9GE/w+bUloXEdeT35Tz\nXuDyitWXAHOBKyvfgR8RJxSffbCyrIh4G/lB2o3kcL9xhK+/BXgAWB0Rb6ga6OrPim2uGO878DVF\nzFoAL3hZnqp1786v9aw1yu/2J4B6/+lHGOV33uFD+/sPTI7yq+mqr6d+GN+3I78Fa8iyge12Di6v\n+3c1WgFzlg4G/srwP++wPNDewM9zlvqQvSSN0YQHuoL9g13dSR7N9jpy6D6N/I78tcCrUkqbK7ZP\nACmlqFi2BvgR0EYO+Y/X+KptKaXLqr77NPKV/BnAd4DHgHOBVwB3AOemlLomcGzTd6CrVtezD7bV\nGeV322PDj/I7nDmHDL3qv3Slo/zq4Ekpj1pdM4zvrH8VvTqs9+5t9pGMXbTlv7kDTgZq3BWYdxjM\nXuLrdiVNa1NpoKuBq/ivAD5F7i7zOvIItl8ELkkpbR1FMUeTwz0Mvve+2kbyW3Uqv/v/RsQryXcL\nzgPmF9t9CvjMRMK9prkZs2DZ8XmqNmSU38rwvzH37a9nz/N5euInQ9fVHeV3Zb4S6UBfrWegS8uo\nwnjl+qoAP1ybnGyd82DmApg5P9/RmrlgcD5zPsxamOd93fnNWrs2wa5n8/M0uzbBns2M+i5A6ofd\nm/L07AjbRjvMPaTiROCwqpOBip9nL/ZkQFJpNeQKfpl5Bb8F9fVWjPJbNcjX1keHH+V3ODMXDDPK\n72GG/6lof5eW7XW6rExWl5YGibaqMF4dzCuXLayxbH7+eaJdZvp680nyrmdh13NF+N80eDJQ+fNw\nb9iaiLaOwa5AlXcCanUXmr3Yv09Jk2JKXcGXSqW9owjix5B7e1Xo74MdT9Xu879l/fBdILp2wNM/\nz1O1GXOGGeX3hV5pHKthu7TUCuPToEtL+8w6YXzhYPAesn7hgcs6506NoNreAfMPz9NIersPPBnY\nvanqxKCY79oE+8bwNub+3vyQ/nAP6g9om1GE/2XD3xWYd2j+7zEV6lhSSzPgS2PR1g6LjszTyrMO\nXFdvlN+BE4DuXfXL7dkDz96fp2qtNsrvcF1a9m2v0c2lTp/0adelpeoqefVV9o6ZzT6K5ujoHBxc\nbyS9XYPdgPbfCag+GSjWddUbAL2G/h7Y8WSeRtLeWfWg8DDdhWYu8GRA0kFhwJcaZaRRfnc/Vzv8\nb14/fNgYbpTfthk1RvktTgQWHQXtMxp6iCMaS5eWmn3Sd9qlRePXMTOf9C5cPvK2PfuKE4DKLkI1\nugvt2pRPOEerrzt38dte6z0R1fs7q6pL0DDdhTrneTIgadQM+NJkiBj8h/qo0w9cl1Ix0FedUX73\nbK5dJuQri5sfztOQ72yvP8rv4qMPvCJc2aVlVP3L6zwgapcWTRczZuW/j0VHjbxt957BE4AhdwWq\nTgZ6do9c3oDefbD9sTyNuL9zKroI1esuNHAy4DgeUqsz4EvNFgFzluRp+SuGrt+7LT/cu3ndgQ/8\nblmfw0U9qS9/buujsO6Gqu9sgwXL83cPBHi7tEi1dc6BzhX5btlIunePootQ8czAWE6Ie/bkN3xt\nG2l4GGDG3Bp3BYqTgeqfO+eMfh8kTRsGfGmqm70IZr8cXvjyoeu6dg4N/ftH+X2qfpmpf3RXDcfK\nLi1qdZ1zKx7SH0ZK+bmcWm8Oqr4rsHtTvto/Wj27B0/uR9zf+RUnAhV3CGqdGMyYNfp9kNRUBnxp\nOps5H17w0jxV694zzCi/jzOkn7tdWqTJE1H8Xc2HpccOv21K+U7bSF2EBt4oNJZX+XbvhC07Ycu6\nkbedubCiS9Cy2ncFBtZ5B01qKgO+VFadc+CwF+epWs8+2P5EETLs0iJNaRH5RHvWQjjkRcNvm1J+\n21TNLkKbhnYX6u8Z/X50bc/T5kdG3nbWohrjCtS4KzB3WX5TkqSGMuBLrWjGrJGDgqTpJ6Lo1rcI\nlq0aftuBB/yH7SJUnAzsfm5sz+ns25an59eOvO3sxVV3Bep0F5q7LI+hoKkvpTxRMR9YTvU6aiyr\ntT3DbD/aMmptT/3tO2aO3N1uivIvRZKkVlT5gD8nDL9tf38+GRi2i1BFV6HUP/r92Ls1T889ONIO\n532tHFTsgMDGBAPkcGWNp4zKZYxx+5G+c6zbD7eM8ZVRa/uyOewl8J7bm70X42LAlyRJw2trg7lL\n83ToicNv298He7YceDJQbwTi3c8z+mCY8muD92yuPS6I1HDT96TFgC9Jkhqnrb144HYZHPYLw2/b\n35cD+8CrQ+t1Edq1qRgTZPoGrtYUxYsXouIFDNXLiuXVyw7YnpG3H7GMOLCs0Wy/6OiG1sZkMuBL\nkqTmaGsf7Gc/kr5e2PP84MlA9y5GHRZrLdv/wq/xBM4GBchR73f1ukbt92jragzf6ZvUpgQDviRJ\nmvraO2D+4XmSNKy2Zu+AJEmSpMYx4EuSJEklYsCXJEmSSsSAL0mSJJWIAV+SJEkqEQO+JEmSVCIG\nfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuSJEklYsCXJEmSSsSAL0mSJJWIAV+SJEkqEQO+JEmSVCIG\nfEmSJKlEDPiSJElSiURKqdn7MKVFxObZs2cvOfHEE5u9K5IkSSqxBx54gL17925JKS2dSDkG/BFE\nxKPAAmBDE77+hGL+YBO+ezqyvsbG+hob62tsrK+xsb7GxvoaG+trbJpZXyuAHSmlYyZSiAF/CouI\nuwFSSqc0e1+mA+trbKyvsbG+xsb6Ghvra2ysr7GxvsamDPVlH3xJkiSpRAz4kiRJUokY8CVJkqQS\nMeBLkiRJJWLAlyRJkkrEt+hIkiRJJeIVfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuSJEklYsCXJEmS\nSsSAL0mSJJWIAV+SJEkqEQP+JIqI5RFxVUQ8FRFdEbEhIi6LiMVjLGdJ8bkNRTlPFeUuP1j73gyN\nqK+IuDki0jDTrIN5DJMlIn4jIi6PiNsiYkdxbNeMs6yGtNOprFH1VdRNvbb1zMHY92aIiKUR8c6I\n+MeIeCQi9kbE9oi4PSJ+JyLG9G9J2dtYI+urhdrYn0XEDRHxeFFfWyLi3yLiExGxdIxllbp9QePq\nq1XaV7WIeEvFcb5zjJ99cUR8OyI2RcS+iHgoIi6JiNkHa3/Hw4GuJklEHAvcCRwKXAc8CJwKrAEe\nAs5MKW0eRTlLi3JWATcCPwVOAH4N2ASckVJafzCOYTI1sL5uBs4CLqmzyf9IKfU2Yp+bKSLuBV4G\n7AKeILeJb6SU3jLGchpS71NdA+trA7AIuKzG6l0ppc9NcFenhIh4N/BXwNPATcBjwGHAhcBC4B+A\nN6ZR/IPSCm2swfW1gdZoY93APcB/kP8tmwucDrwCeAo4PaX0+CjKKX37gobW1wZaoH1ViogjgfuA\ndmAe8Lsppb8e5WdPI2evGcB3gMeBc8j1fgdwbkqp62Ds95illJwmYQJ+CCTg/VXLv1Asv2KU5VxZ\nbP/5quUfKJb/oNnHOsXq6+bczJt/TAe5vtYAxwEBnF3U0TXNqvepPjWwvjYAG5p9PJNQX+cArwfa\nqpYfTg6vCbholGWVvo01uL5apY3NqrP800V9fXmU5ZS+fTW4vlqifVUcbwA/AtYBf17U1TtH+dl2\n8glVAt5QsbyNHPYT8IfNPsb9+9XsHWiFCTi2+A//aI3/4c8nX0XcDcwdoZx5wJ5i+/lV69qKP9QE\nrGz2MU+F+iq2v5kWCPhVxzyuwNrIep9O03jrq/hsS/3jWKcOPlbU3+Wj2LYl29h466vYvqXbGPlO\nWwL+dRTb2r7GUF/F9i3VvoAPAv3AauCTYwz45xTb31Jj3cpi3QaK3jHNnuyDPznWFPPrU0r9lStS\nSjvJt3XmkG+vDed0YDZwR/G5ynL6yVcuKr9vumpUfe0XEb8ZEX8YER+JiNdGxMzG7W5pNLzeW8TM\noj/nxyLigxGxJiLam71Tk6inmI+mq5ttbGz1NaCV29jri/n/G8W2tq+x1deAlmhfEXEi8Bngiyml\nW8dRxDnF/AfVK1LuGr0WOJoc9puuo9k70CKOL+Zr66x/GDiP3K/+hgmWQ1HOdNao+qr0zarfN0XE\ne1NK3xnH/pXVwaj3VnA48PWqZY9GxNtTSrc0Y4cmS0R0AL9V/DrkH70aWrqNjaO+BrRMG4uIi8l3\nqxeS+zW/mhxWPzOKj7dc+5pgfQ0offsq/va+Tu4i97FxFjOa9rWqmNaN8zsaxiv4k2NhMd9eZ/3A\n8kWTVM5U18jjvI58RWM5+e7HCcClxWe/FRHnT2A/y6ZV2lcj/Q1wLvkfyLnAS8jPyawAvh8RL2ve\nrk2KzwAnAd9Lpo5cigAABVtJREFUKf1wpI2xjY21vqD12tjFwCeAD5HD6g+A81JKz43is63YviZS\nX9A67etPgJcDv51S2jvOMqZV+zLgq9RSSn+RUvqXlNKTKaV9KaWHUkofAz5Kbv+XNnkXNY2llC5J\nKd2YUno2pbQnpXR/Sund5Af6ZpP7eJZSRHyA/Hf0IPDWJu/OlDfe+mq1NpZSOjylFOTAeSG5u8O/\nRcTJzd2zqWmi9dUK7at4883HyC8n+XGz92eyGPAnx8BZ3cI66weWb5ukcqa6yTjOvyb3gf3FiJg/\ngXLKpFXa12S4opivbupeHCQR8T7gi+Q3SqxJKW0Z5Udbso1NoL6GU+o2VgTOfyR3qVkK/O0oPtaS\n7QvGXV/DKUX7Krrm/C25W83HJ1jctGpfBvzJ8VAxr9c3/rhiXq9fV6PLmeoO+nGmlPYBAw8qzx1v\nOSXTKu1rMgzcHi9d24qIDwGXA/eTw+pYBsNpuTY2wfoaTmnbWKWU0kbyidEvRMQhI2zecu2r2hjr\nazhlaV/zyO3hRGBf5UBe5K5NAF8pltUaC6DStGpfPmQ7OW4q5udFRFvl0/3F1eMzya+/vGuEcu4C\n9gJnRsT8yjfpFCMjnlf1fdNVo+qrrog4HlhMDvnPT2Bfy+Sg13sLGXhLx7QfdK5SRPwBuR/5vcAv\np5TG+rfTUm2sAfU1nFK2sTpeWMz7RtiupdrXMEZbX8MpS/vqAr5aZ93J5H75t5PD+0jdd24E/hg4\nn6ruvRGxkhz8NzJF6swr+JMgpbQOuJ780Mp7q1ZfQj5D/npKaffAwog4ISJOqCpnF/kp8LkM7Rf3\nvqL8H6ZpPpJto+orIo6JiCXV5UfEMvKDRQDfTCUYyXYsImJGUV/HVi4fT723gnr1FREnRsSQq1sR\nsQL4UvHrNQd/DydHRHycHFbvJo/WWDes2sYaU1+t0sYiYlVEDOn2EBFtEfFp8qi0d6aUthbLW7p9\nNaq+WqF9pZT2ppTeWWsC/qnY7GvFsm8BRMScor6OqiruFuABYHVEvGFgYXGB9c+KX69IKY04QvVk\niCmyH6VXY/jsB4DTyO/tXQu8KlUMn13cPqJ4eKaynKVFOavIZ5M/Id96+jXycNWvKv4nN601or4i\n4rfJ/QhvJ59RbwGOAl5H7iv3M/JVtSnRX24iIuIC4ILi18OBXyEf823FsudTShcX264gDwSzMaW0\noqqcMdX7dNWI+oqIT5IfmryVfNVmJ3mgnV8FZgHfA349pdR9UA9mEkTE24CryVcEL6f2WyQ2pJSu\nLrZfQQu3sUbVV6u0saIb06Xk/1c/CmwGDgPOIj80+gz5JOk/iu1X0NrtqyH11Srtq57i+D8B/G5K\n6a8rlp9Nvht0S0rp7KrPnEbOXjPIo9c+Rn4L0SvI4yycm1LqmoTdH1maAqNttcoEHEm+cvw00E3+\ng7oMWFxj20SdEViBJeQHtjYW5TwNXAUsb/YxTqX6Ir/u62rgPvL/AHvIIf824P1AZ7OPsYF19cmB\nOqgzbajYdkX1svHW+3SdGlFf5H9M/578VpRtRft6DvhX8rvOp8RohpNUXwm42TbW2PpqlTZGfnXo\nl8hdmZ4nvwBhO/DToi6XVG3f6u2rIfXVKu1rmHoc+Dt9Z9Xys6v/RqvWvxi4tqj7LvKJ4yXA7GYf\nU+XkFXxJkiSpROyDL0mSJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuS\nJEklYsCXJEmSSsSAL0mSJJWIAV+SJEkqEQO+JEmSVCIGfEmSJKlEDPiSJElSiRjwJUmSpBIx4EuS\nJEklYsCXJEmSSsSAL0mSJJXI/wd75Hy9/+4tgQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 250,
              "width": 380
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5612d928a89de850888b2caa3251617ff1ebc9fc",
        "colab_type": "text",
        "id": "BybjWD-B4DCg"
      },
      "source": [
        "## Inference time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e908e92d92cf3f2634fa665acbca4012bacdb3bf",
        "colab_type": "code",
        "id": "l--FFj6x4DCg",
        "outputId": "57dbd226-9bf3-4268-9ced-8ac5c1d32784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.eval()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[0]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.view(1, 784)\n",
        "\n",
        "# Calculate the class probabilities (softmax) for img\n",
        "with torch.no_grad():\n",
        "    output = model.forward(img)\n",
        "\n",
        "ps = torch.exp(output)\n",
        "top_prob,top_class=ps.topk(1,dim=1)\n",
        "top_class.item(),labels[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, tensor(8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "086a197d3e597422ee8b592832f811444577b876",
        "colab_type": "text",
        "id": "HLqWHCBM4DCh"
      },
      "source": [
        "The parameters for PyTorch networks are stored in a model's state_dict\n",
        " Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizerâ€™s state, as well as the hyperparameters used.\n",
        "\n",
        "Because state_dict objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2dbde41ca47a505766ec29ad2c89443f9a4d8d7a",
        "colab_type": "code",
        "id": "ZtBvFdei4DCi",
        "outputId": "cf437a7b-2c5e-438a-86f8-90eed4369a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "fc1.weight \t torch.Size([256, 784])\n",
            "fc1.bias \t torch.Size([256])\n",
            "fc2.weight \t torch.Size([128, 256])\n",
            "fc2.bias \t torch.Size([128])\n",
            "fc3.weight \t torch.Size([64, 128])\n",
            "fc3.bias \t torch.Size([64])\n",
            "fc4.weight \t torch.Size([10, 64])\n",
            "fc4.bias \t torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "67e383a0385379d68f1c4f0d38143504b098a8d5",
        "colab_type": "code",
        "id": "FjWuuhJq4DCj",
        "outputId": "3d8f7fba-4e0d-47df-b333-42c3b4b879b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer's state_dict:\n",
            "state \t {139900461526256: {'step': 4690, 'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])}, 139900461526328: {'step': 4690, 'exp_avg': tensor([ 5.6052e-45, -9.0633e-05, -2.0838e-18,  5.6052e-45,  5.6052e-45,\n",
            "        -2.1870e-05, -1.6081e-04, -1.2594e-03, -1.9198e-04,  3.1295e-38,\n",
            "        -4.9848e-04,  2.1075e-03, -1.6403e-23, -4.4465e-04,  2.8305e-04,\n",
            "        -6.0509e-41,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "         5.7103e-04, -4.9331e-04, -1.4567e-03,  5.6052e-45, -9.3776e-07,\n",
            "         4.8159e-04, -1.2833e-03,  2.9540e-11, -1.3162e-04,  5.6052e-45,\n",
            "         5.6052e-45,  5.6052e-45,  5.6052e-45, -1.6582e-04, -1.9093e-04,\n",
            "        -2.7883e-03, -6.7744e-04,  5.6052e-45, -3.7190e-04,  5.6052e-45,\n",
            "        -9.4714e-05,  5.6052e-45,  5.6052e-45,  5.1016e-26,  5.6052e-45,\n",
            "        -1.4458e-03, -7.5890e-06, -3.3384e-07,  5.6052e-45, -4.6484e-04,\n",
            "        -3.9815e-24,  5.0237e-07,  1.0383e-04, -1.4806e-04, -1.3148e-03,\n",
            "        -5.6060e-06,  1.4278e-03,  5.6052e-45,  5.6052e-45, -1.8632e-06,\n",
            "         5.6052e-45,  5.6052e-45, -1.8906e-04,  1.6491e-04,  5.6052e-45,\n",
            "        -6.2496e-05, -3.7904e-05,  5.6052e-45,  1.0470e-03,  5.6052e-45,\n",
            "         5.5002e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45, -3.3427e-04,\n",
            "        -7.0477e-05,  5.6052e-45,  5.6052e-45, -1.1798e-03, -1.4826e-04,\n",
            "         2.2910e-34, -2.2005e-04,  1.5249e-03, -4.2334e-10,  5.0154e-04,\n",
            "        -6.2739e-04,  5.6052e-45, -1.9690e-03, -5.6052e-45, -4.7854e-04,\n",
            "         5.6052e-45,  5.6052e-45, -3.1894e-04,  2.7461e-03, -5.2178e-04,\n",
            "        -2.8835e-04, -3.6933e-04, -1.4136e-07,  1.8333e-05,  1.9115e-04,\n",
            "        -9.9939e-05,  5.6052e-45,  5.6052e-45,  5.6052e-45,  3.3981e-04,\n",
            "        -1.8277e-04,  7.2033e-04,  5.6052e-45,  3.9305e-17,  5.6052e-45,\n",
            "        -7.5574e-33,  1.9815e-04,  5.6052e-45,  3.8151e-04,  1.2540e-04,\n",
            "         5.6052e-45,  8.0551e-04,  1.3884e-03, -2.5297e-04, -1.6292e-04,\n",
            "         5.6052e-45,  5.1199e-04,  9.6204e-07,  5.6052e-45,  5.6052e-45,\n",
            "        -6.0065e-04, -1.3282e-03,  4.7743e-19, -7.5781e-08,  6.1700e-04,\n",
            "         5.4625e-04, -2.2623e-06, -2.2372e-06,  3.6068e-04, -2.5489e-04,\n",
            "         1.1144e-05,  5.6052e-45,  5.6052e-45,  5.1736e-04,  5.6052e-45,\n",
            "         5.6052e-45, -5.1086e-05,  5.6052e-45, -1.2228e-03, -8.9460e-16,\n",
            "        -2.4032e-07,  5.6052e-45,  5.6052e-45, -3.8343e-07,  5.6052e-45,\n",
            "         5.6052e-45,  5.6052e-45, -4.0377e-04, -1.6527e-04, -7.4107e-04,\n",
            "        -2.5274e-04,  1.3999e-03,  5.6052e-45,  5.6052e-45,  2.2554e-04,\n",
            "         5.6052e-45,  5.6052e-45, -2.1454e-18,  5.6052e-45,  5.6052e-45,\n",
            "         5.6052e-45,  5.6052e-45,  5.6052e-45,  4.8885e-11, -1.1367e-04,\n",
            "         5.6052e-45,  5.6052e-45, -5.6052e-45, -2.6906e-04,  3.3655e-04,\n",
            "         6.2474e-04,  2.1049e-04,  5.6052e-45,  6.8644e-04, -5.0611e-04,\n",
            "        -4.8471e-04, -1.3922e-03,  5.6052e-45, -5.0407e-04,  6.8073e-04,\n",
            "         5.6052e-45,  4.0440e-05,  5.6052e-45,  5.6052e-45,  4.1358e-04,\n",
            "         3.2968e-04, -4.0805e-04,  4.0927e-05,  5.6052e-45,  5.6052e-45,\n",
            "         5.6052e-45,  4.3170e-28, -3.0520e-04,  5.6052e-45,  1.7056e-03,\n",
            "         5.6052e-45,  8.5415e-07,  5.6052e-45,  1.4115e-03,  7.3234e-04,\n",
            "         5.6052e-45, -3.1110e-05,  5.6052e-45,  5.6052e-45, -5.0643e-05,\n",
            "         5.6052e-45,  4.6739e-06, -3.0619e-12,  5.6052e-45, -5.6052e-45,\n",
            "         3.9847e-04,  5.6052e-45,  5.6052e-45,  1.2318e-03, -2.2216e-03,\n",
            "         5.6052e-45, -4.9994e-04, -1.0524e-08,  5.6052e-45,  1.1751e-04,\n",
            "        -7.9131e-04, -2.4598e-04, -1.5322e-04, -8.4084e-07, -4.0460e-04,\n",
            "         5.6052e-45,  5.6052e-45,  1.2803e-16,  5.6052e-45, -1.1575e-03,\n",
            "        -2.4894e-04, -1.0898e-12,  1.1172e-03, -7.2015e-06, -7.3483e-05,\n",
            "        -1.4377e-04,  5.6052e-45, -2.0602e-05,  1.1014e-17,  5.6052e-45,\n",
            "        -2.6173e-05,  3.4547e-04, -8.5269e-04,  2.3448e-24, -1.7872e-05,\n",
            "         6.9672e-05,  5.6052e-45, -9.6096e-04,  3.7348e-04, -2.4987e-04,\n",
            "         1.5859e-03]), 'exp_avg_sq': tensor([2.0160e-11, 2.1008e-06, 1.2720e-07, 8.1500e-12, 7.7864e-11, 6.0178e-06,\n",
            "        2.5515e-06, 3.0802e-05, 7.8533e-06, 6.0529e-08, 1.0237e-05, 2.6508e-05,\n",
            "        5.3380e-08, 1.1060e-05, 2.3833e-05, 2.8277e-08, 2.1225e-12, 6.3951e-12,\n",
            "        1.9235e-11, 1.2461e-10, 1.9305e-05, 9.7068e-06, 2.0388e-05, 7.6511e-13,\n",
            "        1.2754e-06, 7.6364e-06, 1.4660e-05, 8.6858e-08, 1.3502e-05, 4.6380e-12,\n",
            "        1.3879e-11, 1.5353e-09, 1.8678e-11, 6.9552e-07, 9.7127e-06, 3.0020e-05,\n",
            "        5.7284e-06, 4.3043e-11, 1.4089e-05, 6.8081e-12, 1.0286e-06, 7.7298e-14,\n",
            "        5.0995e-08, 7.3316e-07, 2.8563e-11, 2.0212e-05, 3.1870e-06, 1.9183e-06,\n",
            "        8.6649e-12, 1.1835e-05, 1.6193e-07, 1.6386e-05, 2.3852e-05, 1.3492e-06,\n",
            "        1.9181e-05, 4.1632e-06, 2.3369e-05, 7.9263e-13, 1.5977e-11, 1.3816e-06,\n",
            "        5.0661e-12, 6.0988e-12, 1.1294e-05, 1.5424e-05, 1.0193e-12, 4.2645e-06,\n",
            "        1.9336e-05, 6.4664e-12, 1.1046e-05, 8.1666e-11, 1.2267e-05, 1.2778e-10,\n",
            "        3.8073e-08, 1.8938e-13, 6.6783e-06, 2.7694e-05, 1.9329e-12, 2.1069e-07,\n",
            "        6.5967e-06, 2.3123e-05, 1.1079e-07, 2.0135e-05, 1.1243e-05, 9.4523e-08,\n",
            "        4.4590e-06, 7.9489e-06, 1.0393e-11, 2.7172e-05, 6.8948e-08, 8.8119e-06,\n",
            "        1.0062e-10, 5.3416e-10, 5.1183e-06, 1.9165e-05, 1.1489e-05, 1.2823e-05,\n",
            "        2.1543e-05, 3.0763e-06, 1.5846e-05, 3.0736e-05, 2.7274e-05, 1.1226e-11,\n",
            "        8.0351e-12, 1.6604e-11, 1.7078e-05, 1.1072e-05, 1.0692e-05, 3.9794e-08,\n",
            "        1.0354e-08, 2.2004e-08, 1.5030e-08, 1.6517e-06, 3.4152e-12, 3.4401e-05,\n",
            "        1.1921e-05, 2.5089e-11, 2.3087e-05, 1.1648e-05, 1.4296e-05, 2.0518e-06,\n",
            "        2.1707e-07, 1.5897e-05, 1.3711e-05, 6.6077e-12, 4.2163e-12, 1.3388e-05,\n",
            "        1.1029e-05, 6.3954e-07, 4.5353e-06, 2.8117e-05, 2.0157e-05, 3.5936e-06,\n",
            "        5.7601e-06, 2.5753e-05, 2.8817e-05, 1.0194e-05, 7.6028e-12, 8.0913e-11,\n",
            "        1.0208e-05, 6.8632e-12, 3.5391e-12, 6.2860e-06, 7.1457e-11, 6.1707e-06,\n",
            "        3.5247e-08, 5.4233e-06, 1.7449e-11, 3.3822e-07, 6.5717e-06, 7.5350e-12,\n",
            "        9.1023e-09, 1.5383e-08, 3.3088e-05, 8.6880e-07, 7.1587e-06, 1.0490e-05,\n",
            "        2.2026e-05, 8.9084e-12, 3.1643e-11, 1.0487e-05, 3.5097e-09, 2.2138e-11,\n",
            "        1.0931e-06, 1.1192e-09, 5.8274e-11, 3.3750e-12, 7.1008e-12, 7.5826e-12,\n",
            "        1.7436e-06, 1.6265e-05, 3.0266e-12, 3.2127e-12, 2.2556e-08, 1.2205e-05,\n",
            "        1.2238e-05, 7.5882e-06, 2.7635e-05, 5.8003e-11, 2.2000e-05, 1.8573e-05,\n",
            "        6.4704e-06, 2.3237e-05, 4.5839e-09, 1.2010e-05, 3.1836e-05, 6.4275e-12,\n",
            "        9.3727e-06, 1.5362e-15, 5.8506e-08, 1.4453e-05, 2.0889e-05, 1.3129e-05,\n",
            "        3.2019e-06, 1.4059e-11, 2.8743e-11, 3.5082e-10, 5.6549e-08, 7.5633e-06,\n",
            "        2.9774e-11, 2.7921e-05, 5.1786e-12, 6.7535e-07, 1.0596e-11, 1.5241e-05,\n",
            "        5.0772e-06, 4.5000e-12, 4.4615e-06, 6.0049e-11, 2.2792e-10, 1.7014e-05,\n",
            "        6.7951e-08, 9.5301e-07, 2.1374e-07, 5.7570e-12, 6.9692e-09, 8.8905e-06,\n",
            "        1.4452e-11, 3.7032e-08, 1.4276e-05, 2.1252e-05, 3.8762e-12, 7.0415e-06,\n",
            "        3.4788e-07, 1.0391e-11, 1.6392e-06, 2.1311e-05, 1.4133e-05, 1.7716e-06,\n",
            "        1.8970e-05, 1.2725e-05, 1.2128e-11, 1.9355e-11, 3.7479e-12, 3.6879e-08,\n",
            "        1.5979e-05, 5.8590e-06, 5.7794e-08, 1.0580e-05, 8.3609e-06, 1.1806e-05,\n",
            "        6.4650e-06, 5.5602e-08, 1.2513e-06, 4.5440e-08, 1.5930e-11, 7.5485e-06,\n",
            "        1.5942e-05, 1.0589e-05, 4.1900e-07, 1.9761e-05, 2.1407e-05, 2.5238e-11,\n",
            "        2.2480e-05, 7.5331e-06, 1.8760e-05, 1.4502e-05])}, 139900461525392: {'step': 4690, 'exp_avg': tensor([[ 5.6052e-45,  5.9859e-10, -5.6052e-45,  ..., -7.5535e-23,\n",
            "         -8.2570e-22, -1.4431e-24],\n",
            "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -9.4061e-06,\n",
            "         -6.5321e-04, -1.9733e-03],\n",
            "        [-5.6052e-45,  4.9055e-07, -5.6052e-45,  ...,  5.4969e-06,\n",
            "         -4.9657e-05, -5.3686e-06],\n",
            "        ...,\n",
            "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  8.9802e-07,\n",
            "          1.7440e-05,  3.9829e-05],\n",
            "        [-5.6052e-45,  8.4629e-07,  5.6052e-45,  ...,  3.0286e-21,\n",
            "         -1.1601e-07, -1.0881e-09],\n",
            "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
            "          6.1732e-06,  7.2658e-05]]), 'exp_avg_sq': tensor([[3.3201e-13, 5.3940e-07, 3.7244e-08,  ..., 2.8396e-08, 2.9961e-06,\n",
            "         6.8652e-07],\n",
            "        [6.6013e-12, 4.0142e-08, 2.2513e-08,  ..., 2.0858e-06, 9.8170e-05,\n",
            "         4.5702e-05],\n",
            "        [1.3497e-12, 1.2152e-06, 1.1506e-08,  ..., 6.8172e-08, 2.0846e-05,\n",
            "         3.8204e-05],\n",
            "        ...,\n",
            "        [1.8454e-12, 4.7357e-10, 7.1464e-08,  ..., 4.1053e-08, 1.8037e-06,\n",
            "         1.4767e-06],\n",
            "        [1.3383e-13, 3.9913e-09, 4.3661e-08,  ..., 1.3015e-08, 1.8022e-06,\n",
            "         7.7080e-07],\n",
            "        [8.0929e-13, 1.0355e-07, 6.2716e-08,  ..., 3.7291e-09, 1.6681e-06,\n",
            "         2.5748e-06]])}, 139900461526112: {'step': 4690, 'exp_avg': tensor([-1.2909e-04,  2.4660e-04,  1.5988e-04,  7.3528e-05,  1.8472e-06,\n",
            "        -1.9826e-05, -2.0145e-04, -3.3048e-05, -5.6509e-04, -1.9983e-04,\n",
            "        -1.5285e-04, -4.6748e-05,  8.3083e-04, -4.4042e-06,  8.9194e-06,\n",
            "         4.8256e-04, -1.1667e-04, -1.1729e-04, -1.4312e-04,  5.7649e-04,\n",
            "         1.0127e-04, -1.6241e-06, -3.4087e-04,  2.3752e-04, -3.0360e-05,\n",
            "         3.3750e-07, -5.4022e-04, -1.5422e-05,  5.6052e-45,  3.6990e-04,\n",
            "         3.6851e-04, -4.8492e-04, -3.4300e-05, -1.4492e-05, -5.2315e-04,\n",
            "        -1.7087e-07, -1.8778e-04, -1.1772e-04,  7.2602e-04,  8.2353e-05,\n",
            "         1.1801e-04, -7.6495e-05, -6.1823e-04, -1.9737e-10, -1.3041e-04,\n",
            "        -1.8452e-03, -6.7736e-06, -5.3150e-05, -2.4154e-04,  1.1406e-04,\n",
            "         3.3539e-04, -4.8865e-04, -2.3958e-05, -4.2819e-05, -3.1120e-04,\n",
            "        -1.2215e-05, -1.8287e-04,  1.6531e-04,  9.1417e-05, -4.5539e-04,\n",
            "         1.3994e-04,  4.5136e-05,  9.5200e-06,  3.8422e-05, -1.9843e-04,\n",
            "         1.8433e-04, -9.6962e-04, -1.0862e-04,  5.6458e-04,  2.3610e-04,\n",
            "        -3.7210e-04, -6.0189e-05,  1.0946e-03, -1.0759e-05,  6.2165e-04,\n",
            "        -3.3889e-04, -1.6923e-03,  5.9440e-05,  1.8638e-05,  1.1267e-04,\n",
            "         2.4674e-04,  9.2008e-07,  1.2399e-04,  2.5901e-04, -2.0639e-04,\n",
            "        -6.7167e-04,  5.2466e-04, -2.4921e-04,  2.1985e-04,  4.2930e-04,\n",
            "        -5.4526e-05, -7.0575e-06, -1.0473e-05,  4.1598e-05,  5.5857e-05,\n",
            "        -3.4982e-05,  2.9785e-05,  1.0195e-05, -8.1172e-05, -9.5797e-05,\n",
            "         1.7819e-04,  5.3293e-04,  1.6696e-04,  3.5086e-05,  4.0574e-04,\n",
            "         4.1801e-04,  1.4045e-05,  1.3502e-04,  3.3930e-04,  5.3970e-04,\n",
            "         4.8366e-06, -2.2800e-05,  1.7637e-04, -1.3367e-04,  6.6134e-07,\n",
            "        -7.6568e-05,  2.6509e-05, -1.7254e-04,  5.7555e-04, -4.1443e-05,\n",
            "         8.4460e-05,  7.0156e-04, -2.0258e-05, -6.5623e-04, -9.8701e-05,\n",
            "        -8.1752e-05,  4.7091e-06, -1.0151e-06]), 'exp_avg_sq': tensor([7.6907e-07, 5.6437e-06, 3.1294e-06, 4.6518e-06, 6.0130e-06, 1.5373e-06,\n",
            "        1.0934e-06, 6.7901e-06, 4.5485e-06, 1.8672e-06, 5.1357e-06, 3.7233e-06,\n",
            "        1.5402e-06, 1.8828e-06, 9.2130e-07, 4.2199e-06, 5.5776e-06, 1.1961e-06,\n",
            "        6.4486e-06, 5.2119e-06, 5.0504e-06, 6.1551e-07, 5.6928e-06, 4.0122e-06,\n",
            "        3.5543e-06, 2.7474e-06, 6.1314e-06, 1.0417e-06, 9.0383e-11, 3.3043e-06,\n",
            "        5.8399e-06, 3.6004e-06, 5.0794e-07, 2.6088e-06, 4.9966e-06, 5.0437e-07,\n",
            "        4.2044e-06, 3.0332e-06, 8.4421e-06, 8.7030e-07, 4.9481e-06, 3.1368e-08,\n",
            "        5.8931e-06, 4.3666e-09, 5.1971e-06, 9.2423e-06, 6.4350e-07, 2.8997e-06,\n",
            "        2.5190e-06, 3.8955e-07, 2.1700e-06, 4.1142e-06, 3.0168e-07, 3.9488e-06,\n",
            "        1.2919e-06, 6.6820e-07, 2.9851e-06, 1.9923e-06, 1.5860e-06, 5.5307e-06,\n",
            "        5.0241e-07, 7.1609e-06, 1.2631e-06, 3.4589e-06, 3.9030e-06, 1.2609e-06,\n",
            "        6.8581e-06, 1.1345e-06, 5.5086e-06, 5.2100e-07, 3.1832e-06, 3.3962e-06,\n",
            "        3.9177e-06, 6.0988e-07, 4.0214e-06, 3.9222e-06, 4.3557e-06, 1.6606e-06,\n",
            "        9.7263e-07, 8.2460e-06, 3.2286e-06, 5.8069e-07, 2.3252e-06, 5.9235e-06,\n",
            "        4.2597e-07, 6.0506e-06, 5.4456e-06, 5.8790e-06, 2.0797e-06, 4.8118e-06,\n",
            "        6.4540e-07, 5.6915e-07, 1.6480e-07, 4.4769e-06, 1.2334e-07, 6.0121e-07,\n",
            "        1.1480e-06, 9.6727e-07, 2.4759e-06, 1.1378e-05, 2.1714e-06, 7.4186e-07,\n",
            "        4.1942e-06, 1.1270e-06, 9.1601e-07, 6.8907e-06, 4.8703e-07, 1.9495e-06,\n",
            "        2.0869e-06, 5.0826e-06, 7.2962e-07, 2.1816e-07, 4.7466e-06, 4.6380e-06,\n",
            "        1.2959e-06, 2.4143e-06, 1.1162e-06, 1.8269e-06, 4.9407e-06, 1.3954e-06,\n",
            "        7.0093e-06, 6.1579e-06, 1.3861e-06, 6.8897e-06, 1.0757e-06, 1.7799e-06,\n",
            "        3.2545e-07, 8.2589e-07])}, 139900461526040: {'step': 4690, 'exp_avg': tensor([[-3.0439e-08, -1.2409e-08,  3.4250e-04,  ..., -5.5884e-12,\n",
            "         -8.4041e-07, -5.6052e-45],\n",
            "        [ 4.3944e-40,  3.4023e-05, -1.9848e-04,  ...,  1.1912e-06,\n",
            "          3.4964e-08,  4.7000e-07],\n",
            "        [ 1.1539e-38, -4.2105e-08,  1.0535e-03,  ..., -2.6653e-07,\n",
            "         -5.0220e-07, -3.4162e-05],\n",
            "        ...,\n",
            "        [ 5.6052e-45, -3.8936e-33,  1.7960e-03,  ...,  3.6836e-08,\n",
            "          3.6358e-10, -1.0499e-06],\n",
            "        [-6.7221e-37,  5.6052e-45, -6.8850e-07,  ..., -4.7001e-26,\n",
            "          5.6052e-45, -1.4941e-31],\n",
            "        [-1.3073e-19,  3.9909e-16, -3.0864e-06,  ...,  4.5565e-09,\n",
            "         -1.1513e-06, -3.4462e-05]]), 'exp_avg_sq': tensor([[5.5368e-06, 1.3295e-06, 3.6648e-05,  ..., 4.4462e-07, 4.1638e-06,\n",
            "         3.2714e-06],\n",
            "        [1.6893e-08, 3.1863e-07, 1.0157e-04,  ..., 2.0351e-06, 9.8976e-06,\n",
            "         8.9255e-06],\n",
            "        [2.3075e-07, 7.5221e-06, 1.1583e-04,  ..., 1.7064e-06, 4.6344e-06,\n",
            "         9.6035e-06],\n",
            "        ...,\n",
            "        [8.4200e-08, 1.6446e-06, 6.8540e-05,  ..., 1.3699e-06, 8.0277e-07,\n",
            "         1.1968e-06],\n",
            "        [2.1728e-10, 3.1512e-08, 1.0583e-05,  ..., 1.3092e-06, 1.2653e-08,\n",
            "         1.5370e-09],\n",
            "        [1.7704e-06, 6.0989e-07, 1.3985e-05,  ..., 1.5147e-07, 4.0570e-07,\n",
            "         1.7411e-06]])}, 139900461525248: {'step': 4690, 'exp_avg': tensor([-2.2409e-04, -1.0514e-04, -2.2531e-05,  1.1361e-04,  2.1007e-05,\n",
            "        -7.5251e-05, -1.6207e-04, -2.6700e-05, -5.5658e-04, -3.2277e-04,\n",
            "        -4.9651e-16, -3.2694e-04,  2.3576e-04,  2.2112e-04, -6.9036e-04,\n",
            "        -3.5538e-06, -1.1465e-04,  1.7443e-04,  4.8515e-04, -6.5063e-04,\n",
            "        -3.7166e-04,  1.1352e-11,  2.0714e-07, -4.5680e-05, -5.8665e-04,\n",
            "        -1.0959e-06,  1.3370e-03, -7.2549e-04,  5.1173e-05,  5.9709e-04,\n",
            "        -9.6832e-04,  6.1406e-04, -4.4309e-04, -6.8583e-06, -6.7363e-04,\n",
            "         1.0745e-39,  6.8978e-05, -2.8864e-04, -6.5218e-07, -4.4942e-05,\n",
            "        -8.8874e-05, -2.6537e-04,  2.1660e-08, -3.9327e-04,  4.3083e-18,\n",
            "        -6.9570e-05,  1.8185e-04,  6.1726e-05,  8.5478e-10,  4.1923e-07,\n",
            "         2.6255e-04,  7.3841e-06,  1.7282e-05,  1.2687e-08,  1.2880e-04,\n",
            "        -3.3075e-05, -9.1281e-04,  7.3394e-04,  1.1153e-10,  4.5372e-04,\n",
            "         1.5997e-03,  4.6362e-04, -1.8101e-05, -8.4351e-04]), 'exp_avg_sq': tensor([4.0402e-06, 3.5730e-06, 6.8574e-06, 7.6486e-07, 1.6507e-06, 3.3100e-06,\n",
            "        6.2310e-06, 5.0227e-06, 8.1812e-06, 3.7582e-06, 2.7292e-07, 3.3632e-06,\n",
            "        3.7643e-06, 1.1877e-06, 6.9635e-06, 5.0682e-06, 2.3374e-06, 5.3952e-06,\n",
            "        1.2488e-06, 9.0824e-06, 3.4307e-06, 2.0671e-07, 6.5342e-07, 4.5825e-06,\n",
            "        3.4935e-06, 2.0613e-07, 8.4145e-06, 6.0097e-06, 2.6297e-06, 7.9023e-06,\n",
            "        1.1026e-05, 5.2180e-06, 3.0439e-06, 1.0718e-06, 4.8543e-06, 3.6846e-09,\n",
            "        4.3594e-06, 7.5386e-06, 4.8594e-07, 4.6684e-06, 6.2848e-07, 7.2960e-06,\n",
            "        5.4032e-07, 3.3385e-06, 4.4825e-07, 3.0315e-06, 6.7744e-06, 4.7726e-07,\n",
            "        6.9378e-07, 8.7345e-08, 2.4895e-06, 1.3262e-06, 1.1211e-06, 4.1199e-07,\n",
            "        3.7932e-06, 3.8700e-06, 6.2931e-06, 4.7584e-06, 1.1123e-07, 5.7224e-06,\n",
            "        7.9200e-06, 4.3516e-06, 7.1062e-07, 4.8290e-06])}, 139900461525680: {'step': 4690, 'exp_avg': tensor([[ 6.0655e-05, -1.2791e-02, -9.2147e-04,  2.1673e-05, -4.1058e-04,\n",
            "          2.2092e-04,  9.3630e-04, -8.4244e-04,  1.1652e-03, -2.9285e-02,\n",
            "          3.1146e-20,  2.5363e-05, -2.6613e-03,  7.2318e-05,  4.5017e-04,\n",
            "         -4.3325e-04,  4.0996e-07, -2.2132e-03,  6.3804e-05,  3.9406e-03,\n",
            "         -8.2670e-03,  7.2933e-12,  1.5404e-10, -4.9675e-03,  3.6926e-04,\n",
            "          2.1772e-08, -2.3323e-03,  3.3699e-04,  1.5331e-05,  1.0594e-03,\n",
            "          2.3482e-03, -2.7367e-03,  3.2953e-04,  1.3379e-06,  2.6193e-04,\n",
            "          6.3114e-42,  1.3882e-04,  9.2218e-04,  8.5543e-09,  1.8975e-03,\n",
            "          3.7938e-05, -1.7319e-03,  4.5561e-07, -3.8550e-03,  2.8505e-20,\n",
            "          6.2950e-02, -9.5540e-05,  9.2063e-06,  4.8318e-12,  2.0646e-09,\n",
            "          3.6704e-04, -1.2727e-03,  1.1521e-10,  2.3292e-08, -8.8260e-03,\n",
            "         -6.6115e-05,  4.3013e-04, -4.1527e-03,  1.2339e-20, -1.0495e-02,\n",
            "          7.0002e-04, -3.3688e-03,  2.8396e-06,  1.6550e-04],\n",
            "        [ 6.4342e-04, -7.0615e-04, -1.7810e-03,  3.9195e-05,  1.8642e-04,\n",
            "          3.3421e-04,  2.8177e-04, -1.4400e-02,  3.6164e-05,  1.5856e-04,\n",
            "          2.2252e-21,  2.1819e-04,  3.7965e-04,  1.6275e-03,  8.4986e-04,\n",
            "          3.5819e-03, -4.8866e-04,  2.3106e-03,  3.1386e-05,  1.4170e-03,\n",
            "         -4.9496e-04,  9.1555e-13,  3.0923e-09,  1.5971e-03, -1.3562e-02,\n",
            "          2.4855e-08,  1.0632e-02,  8.3045e-04, -2.3467e-04,  1.0786e-03,\n",
            "          2.4902e-03,  6.2346e-04,  4.5365e-04,  1.3266e-06,  3.2794e-04,\n",
            "          6.1097e-42, -2.6325e-03,  1.1108e-03,  2.8952e-08,  1.4671e-02,\n",
            "          2.4318e-05, -2.0775e-04,  1.5423e-06,  2.2969e-04,  4.5046e-21,\n",
            "          2.8734e-04, -9.6467e-03,  7.2479e-05,  6.7430e-11,  2.7392e-06,\n",
            "          4.4603e-02,  3.7826e-05,  9.4647e-10,  5.6905e-12, -3.3269e-03,\n",
            "          3.9343e-03,  2.8985e-03, -5.2099e-03,  6.3759e-11, -3.5141e-03,\n",
            "          1.1085e-03, -2.1191e-03,  8.5595e-06, -6.2178e-03],\n",
            "        [-1.1279e-03,  1.0543e-04,  1.6612e-03,  3.4101e-05,  2.0064e-05,\n",
            "          3.1949e-03,  1.2260e-03,  3.9997e-03,  2.9635e-03,  4.1801e-03,\n",
            "          3.0246e-18,  6.1391e-04,  1.8425e-04,  9.9576e-06, -9.1689e-04,\n",
            "          7.2249e-05,  1.9875e-05,  1.2135e-03,  1.2557e-04,  4.0164e-03,\n",
            "          5.7576e-03, -6.3479e-10, -9.9287e-07, -1.8478e-03,  1.7606e-03,\n",
            "          4.1317e-07, -1.0264e-02,  3.6387e-03, -1.1257e-02,  2.7415e-04,\n",
            "         -2.1603e-03,  1.0014e-02,  3.1992e-04,  2.4815e-06, -7.5049e-04,\n",
            "          5.8587e-41,  7.6634e-04,  4.6535e-04,  5.2662e-08,  2.2997e-03,\n",
            "          2.3940e-05,  1.5604e-03,  2.8048e-06,  2.3474e-03,  3.3118e-20,\n",
            "         -7.3655e-02,  1.3692e-03,  1.2989e-05,  7.3255e-12, -7.9618e-06,\n",
            "          2.5449e-04, -3.6612e-04,  6.9422e-10,  1.9942e-10,  7.1586e-04,\n",
            "          1.0598e-02,  2.2502e-02, -3.0736e-03,  5.1294e-11,  8.0015e-04,\n",
            "          3.7301e-03,  3.4588e-04,  4.6960e-05,  5.2406e-03],\n",
            "        [ 9.7803e-04, -5.7591e-03,  2.8518e-03, -7.3398e-05,  2.5469e-05,\n",
            "          1.7901e-03,  2.4835e-03,  3.5200e-04,  3.3197e-03, -1.0286e-03,\n",
            "          5.8132e-20,  1.9056e-04,  1.8554e-04,  3.3539e-05,  3.4421e-03,\n",
            "         -1.6499e-02,  4.6298e-05,  3.6397e-03,  2.0179e-05, -2.4890e-03,\n",
            "          2.0947e-04,  7.2090e-12,  1.2930e-08,  4.4958e-03,  2.3325e-04,\n",
            "          7.2660e-07, -5.8211e-03,  7.4462e-04,  3.0254e-02, -1.2488e-03,\n",
            "          3.8391e-03,  1.3244e-04,  1.8818e-03,  6.5810e-06,  5.2162e-04,\n",
            "          2.2190e-41, -1.9189e-03,  3.3726e-03,  1.9136e-07,  1.9461e-03,\n",
            "          5.6933e-06,  3.4045e-04,  1.0193e-05,  9.9102e-04,  2.0472e-20,\n",
            "         -1.7063e-04,  6.7598e-03,  9.5516e-05, -2.4221e-09,  4.9838e-06,\n",
            "         -4.8239e-04, -1.6009e-03,  2.7525e-10,  1.0924e-10,  3.1977e-04,\n",
            "         -1.6310e-02, -3.8442e-02,  3.0997e-02,  1.2784e-10,  6.0948e-03,\n",
            "          1.9830e-03, -1.9069e-03,  2.3035e-05,  7.5605e-04],\n",
            "        [-4.5912e-05,  4.8757e-04,  1.2643e-04,  5.5841e-05,  1.1495e-05,\n",
            "          1.3659e-04, -4.0086e-03,  1.6297e-03,  5.6420e-04,  8.8125e-04,\n",
            "          3.0042e-16,  1.9286e-04, -1.4206e-02,  3.5235e-03,  4.1370e-02,\n",
            "          2.1637e-03,  8.2001e-05,  2.1773e-03,  3.8327e-03,  6.3733e-03,\n",
            "         -1.8607e-03,  2.4579e-13,  3.5993e-08,  3.1144e-04, -1.2892e-02,\n",
            "          1.5482e-07, -9.1971e-04,  2.5765e-02,  1.8947e-05,  3.6488e-04,\n",
            "          2.5485e-02,  8.4330e-04,  1.3146e-03, -2.0034e-05, -6.5345e-03,\n",
            "          2.3262e-41,  3.1501e-03, -2.3027e-02, -7.7443e-07,  6.3521e-04,\n",
            "         -4.2126e-04, -1.5364e-02, -4.2412e-05, -1.6689e-03, -1.2324e-17,\n",
            "          3.5199e-04,  3.9292e-02, -6.4763e-04,  1.5920e-10,  1.0208e-07,\n",
            "         -2.6229e-03,  2.8661e-05,  1.1051e-08,  5.4056e-12, -1.3071e-02,\n",
            "         -3.2830e-04,  6.1126e-03,  4.1686e-04,  1.8591e-10,  4.6347e-04,\n",
            "          1.2427e-02,  1.2250e-04,  3.1720e-06,  7.9513e-03],\n",
            "        [ 8.6165e-04,  1.1891e-02, -5.9651e-03,  6.7274e-05, -1.2139e-04,\n",
            "          5.6340e-04, -1.7675e-02,  1.5725e-03, -1.5175e-02,  2.0766e-02,\n",
            "          4.0862e-14,  1.1383e-04, -8.0797e-03,  1.2325e-05,  6.3148e-03,\n",
            "          3.5843e-03,  4.1690e-06,  8.0564e-04, -3.6879e-03,  8.4207e-03,\n",
            "          2.3316e-04,  1.0453e-13,  1.6824e-09,  5.8055e-04,  1.8235e-03,\n",
            "         -7.2947e-06, -6.8145e-04, -5.1994e-03, -1.8644e-02, -4.0514e-03,\n",
            "         -1.8055e-04,  1.0952e-03, -1.9157e-04,  2.1720e-06,  6.6323e-04,\n",
            "          4.0198e-41,  5.6886e-04, -6.1873e-03,  6.8599e-08,  1.6068e-03,\n",
            "          1.8089e-05,  3.1182e-04,  3.8937e-06,  1.5155e-03,  2.0718e-20,\n",
            "          1.2753e-02, -1.5339e-02,  6.1533e-05,  2.4695e-09,  4.0058e-09,\n",
            "          5.7953e-04,  1.7506e-03, -2.6567e-05, -2.5048e-08,  3.4162e-03,\n",
            "          5.8968e-04,  6.1135e-04, -2.0262e-02,  3.2702e-15, -9.9731e-05,\n",
            "          1.3353e-03,  6.3181e-03,  4.5248e-06,  3.0445e-04],\n",
            "        [ 8.3590e-05,  1.5211e-03,  8.4773e-04,  1.7138e-05,  6.4443e-04,\n",
            "         -9.4895e-03,  7.9392e-03,  2.7951e-03,  3.9809e-03,  5.4222e-03,\n",
            "          2.7446e-20,  2.6707e-05,  2.2772e-02,  1.2406e-06,  1.4238e-04,\n",
            "          2.3956e-03,  2.8610e-07,  7.5274e-04,  4.0841e-05,  9.5999e-04,\n",
            "          3.0001e-03,  3.2045e-14,  1.5596e-11,  1.4300e-04,  1.6838e-02,\n",
            "          1.4031e-07, -2.4844e-03,  5.2618e-04,  9.2018e-07, -1.6985e-04,\n",
            "          8.8030e-04, -1.3556e-03, -5.0838e-03,  6.1005e-08,  5.1764e-03,\n",
            "          3.7975e-43,  2.9285e-05,  1.1486e-04,  2.3927e-10, -1.8018e-02,\n",
            "          5.3103e-06,  1.8788e-02,  9.3153e-07, -1.5259e-03,  7.4597e-25,\n",
            "         -5.0114e-03,  4.8150e-04,  1.1210e-06, -2.8871e-10,  3.5563e-09,\n",
            "         -4.3094e-02,  7.8910e-05,  2.6555e-05,  1.5047e-10,  1.9773e-02,\n",
            "          2.1260e-04,  2.6984e-04,  2.5723e-04,  3.0052e-22,  9.8502e-05,\n",
            "         -9.6666e-04,  4.8448e-05,  3.6815e-07,  6.8641e-05],\n",
            "        [-3.0544e-03,  3.7554e-04,  1.9600e-04, -2.3234e-04,  5.2573e-07,\n",
            "          2.4601e-04,  3.1509e-05,  1.3949e-03,  3.9377e-04, -6.7361e-03,\n",
            "          2.6346e-21, -1.2944e-03,  9.5232e-05,  9.0406e-06,  7.2170e-03,\n",
            "          2.8510e-03, -2.4961e-04,  1.4493e-03,  5.4571e-05,  7.2805e-03,\n",
            "          3.2949e-04,  6.1733e-10,  4.8037e-07,  1.5017e-02,  4.9188e-03,\n",
            "          5.0866e-07, -9.1993e-03,  4.7141e-03, -2.8186e-04,  3.5682e-04,\n",
            "          4.1818e-03, -9.4393e-03,  1.5570e-04, -2.0763e-06,  5.3853e-04,\n",
            "         -2.0982e-40,  5.1340e-05,  2.8537e-03,  6.5580e-08,  3.8495e-03,\n",
            "          9.7204e-05,  2.1208e-04,  3.4928e-06,  2.7584e-04,  1.1974e-17,\n",
            "          4.2425e-04, -4.9946e-03,  1.0017e-04,  1.4705e-12,  1.2567e-07,\n",
            "         -1.2158e-04,  6.3444e-04,  3.7228e-11,  4.3327e-10,  2.6831e-04,\n",
            "          5.1502e-04,  2.3114e-03,  9.1195e-04, -7.4339e-10,  1.1900e-03,\n",
            "          9.0714e-03,  1.3563e-04, -1.1799e-04, -1.1163e-02],\n",
            "        [ 4.6634e-04,  1.6397e-03,  1.1240e-03,  2.6158e-05, -3.5681e-04,\n",
            "          2.5724e-03,  6.3749e-03,  1.5753e-03,  1.5058e-03,  2.0195e-03,\n",
            "          1.0866e-20,  4.2717e-05,  2.6325e-04,  2.5235e-04,  1.4457e-03,\n",
            "          1.9416e-03,  9.8937e-07,  9.1179e-04,  9.9483e-05, -2.5729e-04,\n",
            "          9.2125e-04,  2.8425e-13,  1.1911e-09,  6.8082e-04,  1.3983e-03,\n",
            "          1.7459e-07,  2.3272e-02,  1.2354e-03,  4.7895e-05,  5.0578e-03,\n",
            "          1.6723e-03, -7.3700e-04,  4.8377e-04,  1.2666e-06, -2.8294e-04,\n",
            "          2.3780e-42, -2.1041e-04,  9.5778e-04,  3.1583e-08, -6.5431e-03,\n",
            "          1.9087e-05, -4.9716e-03,  1.6822e-06,  2.4183e-03,  1.0229e-22,\n",
            "          1.7014e-03,  1.1845e-03,  8.0721e-05,  8.8632e-11,  1.0727e-09,\n",
            "          7.4483e-04,  3.1628e-04, -3.2164e-10,  3.9585e-10,  3.1032e-04,\n",
            "          5.6509e-04,  1.5096e-03,  3.7662e-04,  2.1429e-17,  2.6395e-04,\n",
            "          2.1676e-03,  2.2728e-04,  2.4134e-05,  7.8617e-04],\n",
            "        [ 1.1345e-03,  3.2359e-03,  1.8605e-03,  4.4360e-05,  3.6574e-07,\n",
            "          4.3105e-04,  2.4107e-03,  1.9232e-03,  1.2456e-03,  3.6221e-03,\n",
            "          2.1307e-21, -1.2978e-04,  1.0668e-03, -5.5418e-03, -6.0315e-02,\n",
            "          3.4172e-04,  5.8420e-04, -1.1047e-02, -5.8058e-04, -2.9662e-02,\n",
            "          1.7160e-04,  1.3778e-12,  4.5743e-07, -1.6010e-02, -8.8802e-04,\n",
            "          5.1299e-06, -2.2019e-03, -3.2592e-02,  7.9672e-05, -2.7215e-03,\n",
            "         -3.8556e-02,  1.5604e-03,  3.3649e-04,  6.8843e-06,  7.8335e-05,\n",
            "          5.0396e-41,  5.7114e-05,  1.9418e-02,  3.2690e-07, -2.3451e-03,\n",
            "          1.8968e-04,  1.0626e-03,  1.7417e-05, -7.2778e-04,  2.4169e-19,\n",
            "          3.6981e-04, -1.9011e-02,  2.1390e-04,  9.0513e-11,  3.2138e-10,\n",
            "         -2.2816e-04,  3.9303e-04,  1.0763e-11,  4.5653e-10,  4.2132e-04,\n",
            "          2.8941e-04,  1.7965e-03, -2.6072e-04,  3.2005e-10,  5.1979e-03,\n",
            "         -3.1556e-02,  1.9705e-04,  4.4002e-06,  2.1080e-03]]), 'exp_avg_sq': tensor([[2.4164e-05, 1.5559e-04, 4.9004e-04, 4.2817e-03, 4.2696e-03, 5.6991e-05,\n",
            "         7.0878e-04, 2.2812e-03, 4.1725e-04, 1.0499e-02, 1.2936e-05, 8.0487e-04,\n",
            "         1.0903e-02, 5.0636e-06, 6.3305e-05, 7.6545e-04, 6.0395e-05, 3.6449e-04,\n",
            "         1.1528e-05, 4.7764e-04, 1.1837e-02, 4.2758e-06, 2.2903e-06, 1.3890e-04,\n",
            "         3.8392e-04, 1.6142e-06, 6.0205e-04, 2.6468e-05, 7.2946e-06, 3.0632e-04,\n",
            "         2.9315e-04, 2.2921e-04, 9.0373e-04, 3.9224e-05, 2.0212e-04, 2.8421e-10,\n",
            "         1.9488e-04, 1.4723e-04, 1.0936e-04, 8.0113e-05, 2.1675e-05, 1.5725e-03,\n",
            "         1.4320e-04, 7.7003e-03, 5.7100e-06, 1.0897e-02, 9.5812e-05, 2.5235e-05,\n",
            "         1.6631e-05, 1.4318e-06, 9.2698e-05, 2.4159e-04, 1.5199e-05, 2.6125e-06,\n",
            "         8.6782e-04, 3.5281e-04, 6.5236e-05, 1.3798e-03, 9.2791e-08, 1.5916e-04,\n",
            "         9.3519e-05, 9.0455e-05, 1.1131e-05, 1.2766e-03],\n",
            "        [3.8587e-04, 1.4561e-04, 1.3880e-04, 1.7641e-05, 1.3557e-04, 6.7983e-03,\n",
            "         8.5566e-03, 3.0924e-04, 2.6288e-04, 2.4972e-05, 5.4221e-06, 1.4623e-04,\n",
            "         2.8628e-05, 1.6132e-04, 9.1792e-05, 2.5228e-03, 6.9330e-03, 5.2217e-04,\n",
            "         2.0897e-05, 3.0695e-04, 4.2437e-05, 6.0857e-06, 8.2916e-06, 5.9907e-04,\n",
            "         2.1935e-04, 5.2916e-07, 7.7861e-03, 1.3107e-04, 4.8548e-05, 6.3602e-04,\n",
            "         3.9591e-04, 5.4950e-04, 8.4956e-05, 5.5988e-06, 1.6118e-04, 1.4550e-11,\n",
            "         3.7867e-03, 9.7725e-05, 4.9165e-07, 7.7912e-03, 2.6635e-06, 5.5492e-04,\n",
            "         6.8113e-05, 2.1415e-04, 4.1019e-07, 1.1067e-04, 8.8134e-03, 1.5215e-04,\n",
            "         8.7193e-06, 1.1796e-06, 7.8883e-03, 9.6584e-06, 5.7494e-05, 1.5763e-05,\n",
            "         1.4339e-04, 3.8076e-03, 4.4477e-03, 1.6352e-04, 3.9365e-07, 5.3115e-04,\n",
            "         3.2113e-04, 1.9658e-04, 5.0106e-06, 2.9971e-03],\n",
            "        [8.7349e-04, 2.3135e-04, 2.6037e-04, 8.6410e-06, 7.6225e-04, 7.8016e-04,\n",
            "         8.6167e-04, 1.2492e-03, 3.8084e-04, 5.5150e-04, 7.7308e-06, 3.1419e-04,\n",
            "         1.8014e-03, 5.4168e-06, 3.2804e-05, 1.5210e-02, 1.8171e-04, 1.1814e-02,\n",
            "         7.8643e-05, 6.6446e-04, 6.4680e-04, 9.3659e-05, 5.1863e-04, 1.1150e-02,\n",
            "         6.9256e-04, 2.6569e-05, 1.5326e-02, 6.4267e-04, 3.4477e-04, 2.5281e-03,\n",
            "         4.6229e-04, 3.1563e-03, 5.0051e-05, 1.5863e-04, 2.2743e-03, 9.8059e-07,\n",
            "         1.2086e-02, 8.6680e-05, 3.5019e-05, 4.5565e-04, 9.2292e-05, 1.5800e-03,\n",
            "         2.9017e-05, 1.3727e-03, 6.8679e-06, 6.3272e-03, 7.8440e-04, 3.1849e-05,\n",
            "         3.4480e-05, 1.5630e-05, 3.4464e-04, 4.5204e-05, 3.0621e-03, 1.6238e-06,\n",
            "         3.5814e-03, 7.5220e-03, 2.9363e-03, 1.3859e-03, 4.6726e-06, 8.8095e-04,\n",
            "         2.9528e-03, 1.9689e-03, 1.8962e-04, 6.4042e-04],\n",
            "        [1.6313e-03, 5.7322e-03, 1.2792e-02, 1.2909e-05, 7.4644e-05, 2.7810e-04,\n",
            "         2.1825e-03, 6.4218e-05, 3.1835e-03, 1.1975e-03, 7.9596e-06, 2.0242e-04,\n",
            "         2.0739e-04, 1.0373e-06, 1.3368e-03, 2.7470e-03, 3.8988e-04, 4.6680e-03,\n",
            "         3.8751e-05, 4.5940e-03, 1.4962e-04, 1.6152e-04, 2.2023e-04, 5.1635e-03,\n",
            "         6.4286e-05, 9.9271e-06, 5.5220e-03, 9.1891e-05, 2.0917e-03, 5.1408e-03,\n",
            "         1.1389e-03, 5.9105e-04, 2.6039e-03, 1.1157e-04, 1.7617e-04, 1.6455e-11,\n",
            "         5.1003e-03, 6.9596e-04, 3.7354e-05, 1.6628e-04, 7.4673e-05, 5.3079e-04,\n",
            "         1.8227e-05, 2.0775e-04, 1.0798e-06, 2.2224e-03, 4.2448e-04, 3.2899e-05,\n",
            "         2.2465e-06, 4.6429e-06, 1.2599e-04, 6.5327e-04, 4.7178e-06, 1.5826e-05,\n",
            "         1.0118e-03, 1.8432e-03, 1.2135e-02, 4.9859e-03, 5.5584e-06, 1.5345e-02,\n",
            "         6.4265e-03, 5.6669e-03, 4.7562e-05, 4.9257e-04],\n",
            "        [3.3014e-04, 4.8402e-05, 4.1317e-05, 6.2709e-06, 9.0085e-04, 2.3317e-04,\n",
            "         1.1321e-03, 4.9914e-03, 1.4513e-04, 4.8733e-05, 1.4850e-05, 3.6200e-03,\n",
            "         1.9137e-03, 1.8203e-05, 3.6546e-03, 4.3683e-04, 1.3802e-04, 6.5039e-04,\n",
            "         6.0821e-04, 1.5325e-03, 2.4236e-04, 7.1910e-06, 2.1294e-04, 3.5259e-04,\n",
            "         4.8553e-03, 3.2577e-05, 3.2449e-04, 7.9946e-03, 6.4820e-07, 1.8158e-04,\n",
            "         9.2142e-03, 2.2787e-04, 8.3153e-05, 9.6754e-05, 7.4774e-03, 9.8169e-07,\n",
            "         3.5174e-04, 8.7753e-03, 3.8230e-05, 5.7265e-03, 3.4879e-05, 5.3198e-03,\n",
            "         4.6136e-04, 5.1934e-03, 4.3138e-06, 2.3609e-04, 1.5536e-02, 2.5896e-05,\n",
            "         1.3583e-03, 3.5339e-07, 3.6742e-04, 7.7368e-06, 3.8906e-05, 9.8683e-06,\n",
            "         1.9202e-03, 1.8554e-04, 2.8577e-04, 1.0176e-04, 9.7532e-07, 1.7562e-05,\n",
            "         1.1038e-03, 7.7931e-06, 1.3094e-05, 7.2228e-04],\n",
            "        [3.1145e-04, 7.3497e-03, 1.5531e-02, 4.4441e-03, 3.8136e-03, 4.9348e-04,\n",
            "         1.8772e-02, 2.0943e-03, 1.2333e-02, 1.1015e-02, 7.4249e-06, 3.2444e-04,\n",
            "         2.4073e-03, 2.9479e-07, 1.8238e-03, 3.6008e-04, 1.9831e-04, 1.9424e-04,\n",
            "         5.2191e-05, 4.7311e-03, 2.9817e-03, 1.9319e-06, 5.5457e-06, 6.3013e-04,\n",
            "         2.3417e-04, 1.7613e-06, 6.3445e-04, 1.6621e-04, 9.7612e-04, 1.3269e-03,\n",
            "         5.1305e-04, 2.3724e-04, 8.8587e-03, 1.1898e-04, 8.9317e-04, 2.6590e-09,\n",
            "         1.3051e-04, 2.7351e-04, 7.1842e-06, 5.0460e-04, 4.7999e-06, 6.8255e-03,\n",
            "         5.3463e-04, 3.9659e-04, 3.3184e-07, 8.5956e-04, 4.3205e-04, 3.6133e-05,\n",
            "         1.8923e-04, 4.9614e-06, 3.3949e-04, 1.0495e-03, 2.0700e-04, 1.1520e-05,\n",
            "         2.8843e-03, 1.8133e-04, 5.6089e-03, 1.8066e-03, 2.0722e-06, 1.1993e-02,\n",
            "         7.4974e-04, 2.7766e-03, 4.6744e-05, 1.6356e-04],\n",
            "        [2.6879e-05, 6.1430e-04, 8.0586e-04, 6.8625e-06, 6.3279e-03, 4.8947e-04,\n",
            "         1.9013e-02, 1.2145e-02, 1.2341e-03, 1.8458e-03, 5.7258e-05, 1.1582e-04,\n",
            "         1.4309e-02, 6.4429e-07, 4.7125e-05, 7.6980e-03, 3.2862e-05, 2.4731e-04,\n",
            "         4.6082e-05, 3.2475e-04, 1.9050e-03, 4.7876e-06, 2.5992e-06, 2.3457e-05,\n",
            "         1.0385e-03, 4.0828e-06, 4.9824e-04, 4.5297e-04, 1.2199e-05, 1.3741e-04,\n",
            "         1.2760e-04, 1.6559e-04, 2.2031e-03, 2.0861e-06, 2.2734e-03, 7.5066e-11,\n",
            "         8.8238e-04, 2.3420e-05, 6.7687e-06, 9.3732e-04, 5.4162e-06, 1.5915e-02,\n",
            "         1.3420e-03, 2.3563e-03, 6.8302e-07, 2.2981e-03, 1.7282e-04, 8.3618e-05,\n",
            "         1.2795e-03, 4.1999e-06, 1.7416e-03, 3.0051e-04, 3.3097e-03, 1.2884e-06,\n",
            "         8.1157e-03, 1.3881e-04, 2.3500e-05, 1.7407e-04, 2.2427e-07, 1.6615e-05,\n",
            "         6.9270e-06, 5.4169e-06, 1.9349e-05, 4.5128e-06],\n",
            "        [5.0843e-03, 1.2056e-05, 7.7608e-05, 4.4238e-07, 3.6010e-05, 7.6961e-04,\n",
            "         4.6192e-04, 1.4441e-04, 7.4425e-05, 1.9038e-03, 5.2849e-06, 4.1401e-03,\n",
            "         3.4912e-04, 6.1149e-06, 1.7145e-03, 1.4852e-03, 1.3541e-03, 8.4019e-03,\n",
            "         9.8086e-05, 1.4835e-02, 1.6850e-03, 1.6450e-04, 6.5570e-04, 1.1556e-02,\n",
            "         9.1652e-04, 1.3033e-05, 1.5697e-03, 1.3320e-03, 2.8942e-04, 8.6521e-05,\n",
            "         2.2637e-03, 7.3743e-04, 2.0854e-04, 1.0903e-03, 5.9329e-04, 3.3587e-09,\n",
            "         1.1817e-03, 2.2900e-03, 8.7853e-05, 1.0963e-03, 3.2603e-04, 3.6227e-05,\n",
            "         1.8476e-04, 9.6693e-04, 6.4800e-06, 2.8987e-04, 3.5510e-03, 4.4714e-05,\n",
            "         2.1768e-06, 1.2286e-05, 3.2108e-03, 1.9310e-04, 4.4242e-05, 2.5936e-06,\n",
            "         3.5847e-05, 2.5237e-03, 1.4915e-03, 1.8955e-04, 1.6115e-05, 4.8602e-04,\n",
            "         1.1438e-02, 1.4020e-04, 2.5649e-04, 6.1717e-03],\n",
            "        [1.0891e-04, 7.6459e-04, 1.2062e-03, 2.6042e-06, 5.1874e-04, 5.0040e-03,\n",
            "         3.8758e-03, 1.7160e-03, 1.0466e-02, 1.2049e-03, 1.4538e-05, 8.4335e-05,\n",
            "         5.5011e-04, 1.5327e-04, 5.6150e-04, 8.3712e-04, 5.7238e-03, 3.1252e-04,\n",
            "         1.4978e-05, 7.8303e-04, 6.0714e-04, 1.3621e-05, 4.1742e-06, 2.5527e-04,\n",
            "         1.1156e-04, 4.3493e-07, 8.8517e-03, 1.2171e-04, 5.6126e-04, 6.3933e-03,\n",
            "         5.8039e-03, 4.5366e-03, 2.9123e-03, 2.5333e-06, 2.8578e-04, 4.6301e-10,\n",
            "         3.8033e-04, 6.2766e-04, 2.9803e-06, 1.1533e-03, 5.8022e-07, 6.4181e-03,\n",
            "         6.5587e-05, 5.5509e-04, 8.7293e-07, 1.4502e-03, 1.2992e-03, 1.5177e-04,\n",
            "         3.4890e-06, 3.8776e-06, 1.9870e-03, 1.1059e-04, 3.4291e-05, 2.2495e-07,\n",
            "         4.5465e-04, 4.1793e-04, 8.5964e-04, 1.3323e-03, 3.5328e-07, 4.8181e-04,\n",
            "         4.1762e-04, 2.4789e-04, 1.1756e-05, 1.2546e-04],\n",
            "        [2.2024e-03, 2.9902e-04, 1.9882e-03, 1.8885e-05, 9.8413e-06, 3.6813e-04,\n",
            "         6.4192e-04, 5.0374e-04, 7.0906e-04, 2.1616e-03, 8.7569e-06, 1.1760e-03,\n",
            "         1.1912e-03, 3.7721e-05, 8.6972e-03, 1.7531e-05, 2.6118e-04, 6.7387e-04,\n",
            "         4.6890e-04, 1.5202e-02, 5.4383e-03, 6.6620e-06, 1.9690e-04, 1.8621e-03,\n",
            "         1.6581e-03, 1.1339e-05, 2.8631e-04, 7.0603e-03, 1.3334e-05, 1.0759e-03,\n",
            "         1.5021e-02, 3.3081e-04, 6.6050e-04, 6.8880e-04, 2.8214e-03, 4.5196e-10,\n",
            "         4.2421e-05, 1.2701e-02, 4.4204e-05, 7.8267e-04, 9.9904e-05, 3.1756e-04,\n",
            "         1.0566e-04, 3.2786e-03, 6.5071e-06, 2.0823e-03, 1.2363e-02, 2.8420e-06,\n",
            "         6.0493e-06, 1.4831e-06, 2.7018e-04, 4.4944e-05, 3.4502e-05, 2.0980e-05,\n",
            "         1.6774e-04, 3.1850e-05, 1.8613e-03, 1.0287e-03, 6.3262e-06, 1.1435e-03,\n",
            "         4.6527e-03, 2.1994e-04, 1.7640e-05, 6.2338e-03]])}, 139900461525608: {'step': 4690, 'exp_avg': tensor([-1.3817e-03, -1.5057e-03,  5.2111e-03,  1.2903e-03,  4.3707e-03,\n",
            "        -8.3946e-05, -1.6424e-03, -1.2887e-03,  5.8877e-04, -5.5585e-03]), 'exp_avg_sq': tensor([1.1082e-04, 9.8747e-05, 2.1626e-04, 2.3502e-04, 1.9139e-04, 2.0084e-04,\n",
            "        1.3883e-04, 1.6299e-04, 2.7077e-04, 2.8351e-04])}}\n",
            "param_groups \t [{'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [139900461526256, 139900461526328, 139900461525392, 139900461526112, 139900461526040, 139900461525248, 139900461525680, 139900461525608]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gjnCMjxF5_R8"
      },
      "source": [
        "#  Try Running the below codes on  Kaggle Kernel\n",
        "\n",
        "[Check for reference](https://www.kaggle.com/u6yuvi/digit-recognizer-pytorch/output?scriptVersionId=16485375)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "98bee7eaf09d225730006f2b24ca5662d28cfb65",
        "colab_type": "text",
        "id": "BSWPI5_K4DCk"
      },
      "source": [
        "# Kaggle- Multilayered Perceptron (MLP) implemention on MNIST dataset\n",
        "Untill now we were using the MNIST dataset that is available in torchvision.dataset.Let us now load the dataset from Kaggle repo and train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4e83a9e422c10eb07cbfb779be01803d2b8a5334",
        "colab_type": "code",
        "id": "DtAM0yxR4DCl",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset ,DataLoader\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "PATH=Path(\"../input/digit-recognizer\")\n",
        "print(os.listdir(\"../input/digit-recognizer\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "661e23266c2c882d34cdae4c9074d26c0d2ac040",
        "colab_type": "text",
        "id": "Gj48dSJg4DCm"
      },
      "source": [
        "## Load Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "72b61aac15c29fc295d77130b07d1110c9cb1825",
        "colab_type": "code",
        "id": "mdn255g54DCm",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(PATH/'train.csv')\n",
        "test=pd.read_csv(PATH/'test.csv')\n",
        "train.shape,test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6d5eb02dbfc5e385ffd113560494e0b2275e5f66",
        "colab_type": "text",
        "id": "Hf9bGVDH4DCn"
      },
      "source": [
        "## Extracting Input and Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "858a074c0e1dea92562d0f1bd93ff5302f861643",
        "colab_type": "code",
        "id": "XF2vEl_t4DCo",
        "colab": {}
      },
      "source": [
        "x=train.drop(\"label\",axis=1)\n",
        "y=np.array(train['label'])\n",
        "x.shape,y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "387109d77b8c6f76d4de868158340faf1a38b2dc",
        "colab_type": "text",
        "id": "TUVHsCvR4DCp"
      },
      "source": [
        "## Normalization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b8ff683f50227c31ee39ec05a7bb8b4e2a8c5f94",
        "colab_type": "code",
        "id": "BFgs691V4DCp",
        "colab": {}
      },
      "source": [
        "#x_train=x/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "614e6245bdf2e3372dca00d5111b3fbe8e993a64",
        "colab_type": "text",
        "id": "R5TxccEk4DCq"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "65e189e8b8c6232146d0dde1fceb773353ad8389",
        "colab_type": "code",
        "id": "iPIQfMjR4DCr",
        "colab": {}
      },
      "source": [
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8f37069db924850a07cd3e98378ae9c61bab1f8f",
        "colab_type": "text",
        "id": "0c7XjTMH4DCs"
      },
      "source": [
        "## Train Test in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "709aaea373c664fad6fd42d8779ae091145b8308",
        "colab_type": "code",
        "id": "Jst9e0mK4DCs",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# create feature and targets tensor for train set.\n",
        "torch_X_train = torch.from_numpy(x_train.values).type(torch.FloatTensor)\n",
        "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
        "\n",
        "# create feature and targets tensor for test set.\n",
        "torch_X_test = torch.from_numpy(x_test.values).type(torch.FloatTensor)\n",
        "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
        "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "80525db377fe319e7a3fc538ef8b76639c28c995",
        "colab_type": "code",
        "id": "Rk2ZdrHj4DCu",
        "colab": {}
      },
      "source": [
        "'''\n",
        "BATCH_SIZE=64\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "454f4fb8e0a416e60aed471a49850c01a64a77e6",
        "colab_type": "text",
        "id": "0ZOWCRtq4DCw"
      },
      "source": [
        "## Train -Test Split -Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d616496f4e453322efe8aecfa71b17fcdddaa8dd",
        "colab_type": "code",
        "id": "ni3rH-Pi4DCw",
        "colab": {}
      },
      "source": [
        "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\n",
        "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
        "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
        "valid_no  = int(0.2 * len(myDataset))\n",
        "# so divide the data into trainset and testset\n",
        "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
        "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
        "batch_size=64\n",
        "train_loader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
        "test_loader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a06249ad57104d74d0258fd5972961f720bdc3cf",
        "colab_type": "text",
        "id": "DhlKN0Y34DCy"
      },
      "source": [
        "trainData = torch.from_numpy(x_train.values)\n",
        "trainLabel=torch.from_numpy(y_train)\n",
        "testData = torch.from_numpy(x_test.values)\n",
        "testLabel = torch.from_numpy(y_test)\n",
        "trainData, testData = trainData.type(torch.FloatTensor), testData.type(torch.LongTensor)\n",
        "trainLabel, testLabel = trainLabel.type(torch.FloatTensor), testLabel.type(torch.LongTensor)\n",
        "trainData.shape,testData.shape\n",
        "trainData = trainData.unsqueeze_(dim=1)\n",
        "testData = testData.unsqueeze_(dim=1)\n",
        "trainData.shape,testData.shape\n",
        "transforms =transforms.Compose(transforms.ToTensor())\n",
        "train_dataset = TensorDataset(trainData,trainLabel)\n",
        "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(testData,testLabel)\n",
        "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "97b2925a24f59b10a16864a76f00e02a4c92b36f",
        "colab_type": "text",
        "id": "_hGrdIVq4DCy"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8cbe1c508bacadbb875014318a35fed17ab6a3a1",
        "colab_type": "code",
        "id": "nW1wypfS4DCy",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Now with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "\n",
        "        # output so no dropout here\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "\n",
        "        return x\n",
        "        \n",
        "model=Network()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
        "criterion=nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2bea512cd5bd9f4f41bd77044f471e644505a5fa",
        "colab_type": "text",
        "id": "wr91w0-X4DCz"
      },
      "source": [
        "## Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2df4882ed86f9b17b4bba52d56adfde46d1f718d",
        "colab_type": "code",
        "id": "9x_1PS6x4DC0",
        "colab": {}
      },
      "source": [
        "epochs=5\n",
        "train_losses,test_losses=[],[]\n",
        "for e in range(epochs):\n",
        "    running_loss=0\n",
        "    for images,labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        log_ps=model(images)\n",
        "        loss=criterion(log_ps,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss=0\n",
        "        accuracy=0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images,labels in test_loader:\n",
        "                log_ps=model(images)\n",
        "                test_loss+=criterion(log_ps,labels)\n",
        "                ps=torch.exp(log_ps)\n",
        "                top_p,top_class=ps.topk(1,dim=1)\n",
        "                equals=top_class==labels.view(*top_class.shape)\n",
        "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
        "        model.train()\n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        test_losses.append(test_loss/len(test_loader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9373aea13cc5891684fb8b801cbcd0ac17eff458",
        "colab_type": "text",
        "id": "_vC0Y7z34DC1"
      },
      "source": [
        "## Save our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bfcc3f17cadca0bf48cec130586b907965905ed6",
        "colab_type": "code",
        "id": "5gmUDHdA4DC2",
        "colab": {}
      },
      "source": [
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f83335753469344d38ac362053a74fad30b0ca3e",
        "colab_type": "code",
        "id": "5xfl0hTJ4DC3",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "70b1a508fd748a8823a9e1af57538e4cacb0621d",
        "colab_type": "text",
        "id": "9zyso_in4DC4"
      },
      "source": [
        "## Load our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "abd854b1c8bfed532cb4e64578c40fd29dea9a36",
        "colab_type": "code",
        "id": "nnS5Suqe4DC4",
        "colab": {}
      },
      "source": [
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7a889737952161eb1834f521476f0f1c8448570a",
        "colab_type": "code",
        "id": "0iHEd3Nk4DC6",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a08eff1adeb3a8f8f7a31356828ee732a557c3d5",
        "colab_type": "code",
        "id": "EOVzZilI4DC7",
        "colab": {}
      },
      "source": [
        "checkpoint = {'input_size': 784,\n",
        "              'output_size': 10,\n",
        "              'hidden_layers': [256,128,64],\n",
        "              'state_dict': model.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b3356c9580d6c01685a52a11f906ee1c9dbe7ef1",
        "colab_type": "text",
        "id": "B-j6vcfk4DC9"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "34abb15aa48ad4f133ee15a2f9a5268b45692c36",
        "colab_type": "code",
        "id": "8oA5JqIJ4DC9",
        "colab": {}
      },
      "source": [
        "test_images = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
        "test_image = test_images.loc[:,test_images.columns != \"label\"].values\n",
        "test_dataset = torch.from_numpy(test_image).type(torch.FloatTensor)/255\n",
        "print(test_dataset.shape)\n",
        "#test_dataset = torch.utils.data.TensorDataset(test_dataset)\n",
        "new_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "790dd7f94c59a6de5441827b999b6cff6f686154",
        "colab_type": "code",
        "id": "dwpwU0h04DC-",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images in new_test_loader:\n",
        "        output = model(images)\n",
        "        ps = torch.exp(output)\n",
        "        top_p, top_class = ps.topk(1, dim = 1)\n",
        "        results += top_class.numpy().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0f9b334b1c25c4bb1a48fda6b64634f1f90b7565",
        "colab_type": "text",
        "id": "4ZwCEHs24DC_"
      },
      "source": [
        "## Check the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "56ffd3051274596232af3ca4d1a9ee7d6322881a",
        "colab_type": "code",
        "id": "iJ2mowPf4DDA",
        "colab": {}
      },
      "source": [
        "predictions = np.array(results).flatten()\n",
        "print(predictions[:5])\n",
        "print(predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f946013a3eab6274d1becd93dfe99aa9f7491cf9",
        "colab_type": "text",
        "id": "dMLPVy7c4DDB"
      },
      "source": [
        "## Submit for Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "655160a6e2d490651c0fe70b8ba7480ed8ba1fcc",
        "colab_type": "code",
        "id": "xFG3HrNH4DDC",
        "colab": {}
      },
      "source": [
        "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
        "                         \"Label\": predictions})\n",
        "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "177c548a264bbaaa76e216eeaf1d747db88b1030",
        "colab_type": "text",
        "id": "psW9Ie4t4DDF"
      },
      "source": [
        "# Reference\n",
        "\n",
        "[Introduction to Pytorch-Udacity](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch)"
      ]
    }
  ]
}